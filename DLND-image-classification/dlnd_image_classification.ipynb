{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 89:\n",
      "Image - Min Value: 12 Max Value: 249\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 4 Name: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAG7JJREFUeJzt3cuvZXd2F/DfPvu87r11bz1tl9122/TLTTqKEoEISIhB\nmDEACWaREDP+CyQk/hGEkJBATJgiUIsgQN0BkZbT3aY7iR27/K6qW/d5XntvBgxIhmulrI6WPp/5\n0tpnv75nj77dNE0NAKhp9qs+AADg6yPoAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAU\nJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQ2/1UfwNflX/+rfzFl5sbp8/DMcrnN\nrGrTfhGeGcbb1K7zi/PU3PHR4/DMs/N9atfd+6+HZ5bzu6ldy8VRau4wjOGZm81latdyEb8/bi6G\n1K6uj9/D/XKX2jWOh9Tc2d074ZnT07PUrj/98KPwzLMXH6Z2vfGNR6m549XD8MxXX9ykdr33k/fD\nM9/6ztupXXfONqm5rlvFh4bT1K7zi0/CM/vhIrXrn/+z/9ClBv8MX/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFlW2v+9Y3c61m3Sx+SqaWa5S7\nvY43oT17lmufevwo3kLXWmtvv/NOeObp81yr2fHJN8Iz6/VxateLF89Tc/Nl/L/x8dGbqV3r9TI8\n84v34y1jrbX29OmL8Mz9e6+kdp2e5a7Zchkv8ZqmXJvfO2+9Gp75tXfj7Yut5RoRW2vtk4/ijZSf\nfvRFatfZ6b3wzBuPc/f91F2n5h6/nnnn5751L6/iObFa9aldL4MvegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQWNlSm6PjXLHKfhsvHljM7qd2LU/jx7ha\nHqV23bv3WmpufbwIz9x9cCe1q01TeKTvN6lVd3OdR+0wJAqMhkNu2XQVHvn2X4kX4bTW2jtvxQuF\nhuRnwmqdmxuGbXhmGnOlNuNR/L6fJwqxWmttGOL3fWutTa/Fy4EWi1wR0auPH4Znzk5z76r1Ovc+\nnc334ZlxzJ3711+Lv0/nc6U2AMDXQNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMLKttet1rkGtdWiC8/M+9z/pczY1OLH11pri2WuMmzWxxuXhmRb23i4\njO/a5drJ2phrvTtaZs5/vGWstdamRLPWyXHuXpymVXxmPuZ2tdxca/FjzD0trc26+HmcxtzvOgy5\nps3TO/F2uO9++7upXV0XvxeHMfcemIbkfTXF42wcc89LN4sf47SPt+u9LL7oAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0BhZUttFotcqU2bxwsm5sm/S/M+\nXkqx2+WWjVO27CQ+NwzJoogpXlCzu73J7eriZT2ttbZexB+ZQ7JA57CPF2d0i9SqNuvju+azeMlM\na60NievcWmvdLH7usyVQy8R5THa4tEOy62TZL8Mz8z5XbtUSJT/DPlfWs9/GC3Raa+34OHE+Vrl7\nuF8kyr4mpTYAwNdA0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0\nAFCYoAeAwsq212Xap1prbbu5Dc9MySa0wxRvDBtmuWan7SFXrbW7iTdQ9fPcMc5n8Yt2fnWd2nXv\nXq7d8NDi53Hfci1eYx9veetmuXuxtUSz1iH3u7bJBsbtLn7uj89yr7jbKXHfd/H2tNZamxa5hr2p\niz9nwxh/v7XW2izTHLiIv9/+n1y74WyZOMYut2szxlszh+R74GXwRQ8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY2fa6jz77X6m57fYyPDPL/l2a\nnYRHuuQVmw65JqmL83jb1dGdXBtXPz8Oz2yu4jOttbY4yrW83R624ZnDmGutmrp4W9v2KtdONu7j\nuxbr3HW+fnE3NTdO8aax1e4itWu1TjxoU+5F0Ccf6i7RXjcNuWu2XKzCM/vEs9Jaa2OyUe56iLdf\nzpKNg7tDvL3udhOfaa2173w3Nfbn+KIHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIWVLbX5n//nv6Xm5vFehNb1ucKYZ0/j/7NOThIH2Fq7s8wViSyGB+GZ\nT748T+3aJwo33v3Wb6d2bfe5co/3f/qz8Mz1/llq17ZtwjOX57kSlzvrO+GZrs+Vj5yt/2pqbruN\nF/ZM/aepXatF/Ldtt/vUrr7lnunVMl7M1K9zJS6HKf6Om/p46U5rrQ1TvGCptdYOY/wYx9yqNk7x\nwp6bq1ypze/87dTYn+OLHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQ\nmKAHgMIEPQAUJugBoLCy7XU//NEHqbmTs+PwzP1HJ6ld29t4a9WjFm9Naq21L7/MNY3Nb+Pn4+o6\nd4xHp/Fd15c/T+26vY43w7XW2tOnn4Vnvrx4ktp1m2iv29/mmhS/8fDN8MzqKN5411prf/fv/CA1\n9+yr5+GZ2+06tev3/sd/DM8MuUesdWO8ha611lar+Ot7eZL7trs9xO/FbpGLl/Ory9RcpitvGnPn\nYz5PtBve5NoNXwZf9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgsLKlNj/5g0Nq7uTsNjxz72Hu/9JiES+KePJkl9p18zRT+dDayRife+3B66ldrzx8Ozzz\n0z/4cWrX+cWL1NzuEL/WF7tk28kiXlBz2BylVr316rfDM996+93UrufnueKdcYqXR724yBXvPPk0\nXoZzu8ld590m90wfHcXP4+n9LrXrMMWP8dByJS43ub6pdn0b33edLOC6dxovJJt38ZmXxRc9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYWXb66ZN\nrrXqeoi3183GXGvV/hBvhOqSDUiX57lKqPX0WXjm5CjXXnd9GT+P90/fSO067HLn8YOPvwrP3G5z\nj9lyHT/G5fwsteve2cPwzO///vupXe+9979Tc5tt/Nk8O72X2jVfHIdnnj27TO06JBoRW2ttl3jF\njWOu1XPs4nNDrjCz7XJlfu3iIt7mt93lns3VEH82+9andr0MvugBoDBBDwCFCXoAKEzQA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAK66YpWTH0l9w/+N2/l/phm/2L8Eym\nZay11raJQrntPlfttNnsU3N9oqVpPetSu476+CVbz3L379nRKjW3PyTav2a5++P2dpnYlftdQx9v\nhnt2HZ9prbWLy/gz1lpr2238Hp7G3LfMehVvGptyJZbt7Oxuaq5fxO/FwyF3zcYxfu7ny8T921q7\nuMi94xan8Wv98NXcuR8T5/H86XVq14/+0/u5F+qf4YseAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCF\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQ2/1UfwNfldB0vpWittfVyHZ45PjlJ7erv3wnPbIeL\n1K7dNlf+spjiv+3RUe7cX33xSXim3+fOx1v3cyU/d84ehmcuu8epXcvEfbVvuSKRn/8yfu4fvZH7\nXReX56m5zOuq73IlP0er+NzmZpvadXqaK1bZ7RMFNcOY2jVfxJ/p+w/iz0prrV1c5kptDov4ffXG\n2/dSu55+9WV45ovj7H3/F+eLHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoLCy7XWL5YepuTvH8fav5SrXhLbZXYZnHjzI7Xr+aW7u6QdPwjO/9dvf\nT+06eeXV8Mzp6rXUrvnu49Rcv4o3a83u5Vq8vvm974ZnHryZOx//5t/+5/DMe3/4y9SuvhtSc10X\n/y7Zba5Suw6bRXhmscg15T19Gm8ObK21fhZvlDvKFW223Ri/7z9/+iy1a5ts2ry4uQ7PfPThn6Z2\n9YnkXK9yLYUvgy96AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4A\nChP0AFBY2VKb73wnVyAw6+P/fZbLdWrXzTa+6+g0XrrTWmt357miiN0n8VKb+fQitevhw9PwzL3j\n+ExrrX3w89vU3GIfLyB55807qV3T7f3wzNH0zdSu3/1H/zA88++W/zK168knv0jNHQ7b8Mx2mytz\nGtsYnun7eMlMa60tdofUXN/Hi3fWx7l31Xa/Cc/cbOIzrbV2O+TOxzTF33G7Xbysp7XWlomCpe0h\n2Sj0EviiB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCF\nCXoAKKxse903XvlrqbntbbzVbGq5hqzjdRcfmsVbtVprrb8/pOZ+/TfjzWu3m4vUrg9+8XF45sGd\nVWrXfsj9xz3cxq/ZzfV5atd0/EV45pMnf5La9fa7fys880/+8T9N7frhD/99au6zz34Znula7r7v\nl/EmtDFXENm6LvEeaK2NU/y3jVN2V3wu0ybXWmu3t7nWu8Mufj72h1x73c32Ojxz/uIqtetl8EUP\nAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAorW2qzXD5I\nzY2Hm/DMNOVKGPrE/6zdFC9TaK21+SJXvPPqW4/CM5ef54oz/uS9eInL4WGf2nX3KF7W01prFxfx\ngprdcJbadTKPF/ZstrnijM8+/zw8873v/2Zq17vfjxfotNba5198GZ6ZzZKlNv0yPDPucyUufb9I\nzc27eMFVttRmtVqHZ6ZkodC9s1xx12EXL6iZpkNq12YXLz979GCb2vUy+KIHgMIEPQAUJugBoDBB\nDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx73W4fb59qrbXNNt4w\ntNvlWqvW8/gxbsd4Q1NrrW0OuUao3SzedjU/fTW169u/8Up45sOf/Sy16/Ymdx7vnsbb/PZjrr2u\ntXir2TDkWgpvbi/CM0+fPkntWvTHqbnt7jQ8c32Ta5ZcLePn/pB8xpbLeEtha611ifa6NuXaHoej\n+DXruty9uFznjnG/j1/r1TIXgct5vOV0fpzLiZfBFz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0BhZdvrLi9z/2GePY03Lu33h9Suk+N4M9zFVa6N\na7/PNUn1XbxJarGI/67WWlstTsIzn77INUKdT5epud959wfhmXFap3ZdvXgRnjk7zT3S0/42PPP5\nk5+mdm1zt2Lb3MSv9eY2dz7GRBPdOOTa6w673PujdZm53PnYbeNtbctVtoUu9/64uoqfj6Pco9mG\nYQjPTMn742XwRQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4ACitbarPdLpJz8VMyDsvUrs0hXoxwvdumds2GXFHE1DJz2V1xr775TmrXkz/6MjX35Yur8Mwr\nfe4xe/H8i/DM2a+dpnYNm+v4TMuVliyXq9Tc4RA/xuUq9y2z7OPP9CF5PhaLZPHOFC9Jmbrcszlb\nxM9jdtc4Zb8/4+/8XbJgacgU78Rf9y+NL3oAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEP\nAIUJegAoTNADQGGCHgAKE/QAUJigB4DCyrbXTV3uP8yYqFDb7nepXYsx3oA0JtuW9odDam65iB9j\nN+Xa/NoYr3danuSa0B48/lZq7r/+6BfhmW/cv5faNW/xpsJXX7uf2vXgKH4ezxZvpnZ9+ezj1NzV\ndaL+a5arDLtNNK8Nh9w7p+9z749xiv+2rs817PXz+PtjtUy2+fW55tGbxP0x6zKdma0dDol39/Cr\n+672RQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4ACitb\narPb5UpcMt0vh0OuvKEbjsMz4+4ktWu/ixektNbaYRcvfZjP44UPrbXWJwp0piF37ter11JzT776\no/DMT372fmrXD94+C8/89avL1K6TF1fhmf/+3o9Tu+bHuaKZ/eZOeGaa1qldXR9/XoZhTO3q+9xr\neJaY64bc+Rj38W/CVcvtmma5UqztTbwcaNbnSm3GMf7emcbc/fEy+KIHgMIEPQAUJugBoDBBDwCF\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx73bDPNWSN+0Tz2rDI7Uo0\nr01j7r/ZNCX/043xdqfhkGuE6rr43DjmmvKGfe4Yt4n7Y7aOt9C11trzRHPg7/34g9Sub79zPzzz\nh+/9PLXrN/7G66m5YbobH0q2183Go/DMcMi1k2Wf6Vni2ez7XKvnbBa/74dD7r3YZvEWutZa2+/3\n8VUt137ZpsS7atJeBwB8DQQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhQl6ACisbHvdfnebmpumeHPSOGxSu3aJBrXDeJ3aNbVca1XLlMN1yf+PXbzdaWjJlsI+\nN/f4cbzl7ezkrdSuFxdfhmc+/Cre4NVaa/dfjzfD9atHqV0fffo8NbdJNMq17iK1a9HFW83G5Nu0\n63OD4yz+vHTpZzN+PoYu10I363ONlLNF/H06tVyjXNfHd3WJxruXxRc9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACisbKnNZnOZmhvGm/jQLFdqcxjiJQd9\ntgBjypW4dIl+iT5ZStHN4udj3i1Su6bkrX/vUbzI5dH9N1K7ptlxeGa1vsrtGhOFQl28CKe11l5c\nrFJzp49/Kzwzdbn7vo3xUqzZLF788heZG8d4gdFinntelv0yPNMlC2P2Q+4ePgzxaz1LlPW01to4\nxM995vheFl/0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhZVtr1suc/9hDofETLKV6HYTb8obxmwDUq5JKtOWt9vl2vyO5vE2tON1vE2utdauruLt\nU621ttl+FZ555bXvpXYtjr8ZnlktPk3tevjg18Mz59cfpXZNU+7cv/X2b4dnDlPigW6tjYlnczzE\n2xdba21/2KXmDkN8bjHLvT+mMX4ep+S53+3iTXmttTbrj8Izy+U6tWsa49d6Nm5Tu14GX/QAUJig\nB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoLCypTbPn12m5g6J\ngomp9aldU4vvGsZkAcY+V2ozDvHyhv0+V+5xfXURnlmvcrfwav0gNbdePgzPPH/6RWrXF8/PwzMP\nz3KFMfM+foyLRfz4WmvteHWSmuvGeFnSNOZKSxYnr4Vn+vkitWtquedlGuPPdJ8stxrH+H01DLl7\ncbXPvePuJM5H9lu37+Pv/KnlzsfL4IseAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdbv9NjV3OMQbhubz3P+laRrCM8Mh13Q1Dl1qbj8m9k2r\n1K7lMn4e54tcI9RykWvxWvTL8MxHT36a2vX86cfhmfnds9Su7Ys/Ds/0i/j921pr77zzN1Nzt4d4\nw952k2vKWxy9Gp7pl7nXaZdsvzwcMs90rs3vzvFxeGYYD6ld58+fpebmiVfVcpFtHIy/d56ff57a\n9TL4ogeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6\nACisbHvdOOba6xaLeCNUN8u1eLUWb06aplzT1TjkWt5apiyvyzXD9Yn6qWG6Su16fp6b+/KLRLPW\n7DK1az6+CM/cW+faye7ejzcO3tzmrvO4jbfQtdbaH3/8X8Iz17uj1K6zr+6HZ2bzXGtjm3LNkpnW\nu+XibmrX8fFpeGaW/Izc7XepuWmI34/XU65hr7V4vlxePU/u+vvJuf/PFz0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxsqU0/y5VZDEO85GDY5YoRZl38\nf1bi8FprrY1Dpp2mtanFC3sSP6u11tp+H78d++x/1TFXnLHZfpXYlSsUOk50nZzeyRXNPH78MDyz\nS3Y5HR/n7sVh8zQ8M+1OUruefZq4zrlumtbPc/fwfB4vtelny9SuF4mHejbLnZBxyt1Yh0P83h+T\npTbjlCtN+1XxRQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFBY2fa6rq1Tc8P+NjEVb5FqrbU2i//P2u2uU6vGlmsM6/t4A1WX/P/YdfFrNo25cz8m\nawD3ifujn3KNcovELbwfb1K7NvtNeGZ3yDV4zbq7qbm+jzevLea5Fst5l3heutx1niffwl3iGLsu\n1ww3n8d/W+L11lprrZtyrXfbLv5MH6Zcs2Q3Jq71lMyJl8AXPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypTUuWuLSWKVTI7Vou4yUd212uSGTY58os\npi7+X3DW526rLlMONMsVYMySc8M+XpwxHTJFSa3NV/Frdnr3QWrX3bvx8pfZ/Cy162h1LzU3TLvw\nzNjlrnPqiU6WsYxDsvRoHn9e+nn8ndNaa7NZ/IzMMsVArbWWLKqaEq+4KfW+b204xN9xs06pDQDw\nNRD0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwbpqy\nLW8AwF92vugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugB\noDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQ2P8FZ5IT0YiHhf8AAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07386336d8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 89\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    return x / 255\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    one_hot = np.zeros((len(x), 10), np.int_)\n",
    "    for i, label in enumerate(x):\n",
    "        one_hot[i][label] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    "If you're finding it hard to dedicate enough time for this course a week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) to build each layer, except \"Convolutional & Max Pooling\" layer.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    "If you would like to get the most of this course, try to solve all the problems without TF Layers.  Let's begin!\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, *image_shape], \"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "Note: You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.  You're free to use any TensorFlow package for all the other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for convolution\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # used to rule out errors in my network\n",
    "    #conv_layer = tf.layers.conv2d(x_tensor, conv_num_outputs, conv_ksize, conv_strides, \"SAME\")\n",
    "    #conv_layer = tf.layers.max_pooling2d(conv_layer, pool_ksize, pool_strides, \"SAME\")\n",
    "    #return conv_layer\n",
    "\n",
    "    color_channels = x_tensor.get_shape().as_list()[-1]\n",
    "\n",
    "    # before setting stddev=0.1, my training validation accuracy never get over 0.1,\n",
    "    # after reading some source code of TensorFlow, I found a keyword \"stddev\", then search it in Slack,\n",
    "    # gotcha! accuracy get to 0.2 !\n",
    "    weights = tf.Variable(tf.truncated_normal([*conv_ksize, color_channels, conv_num_outputs], stddev=0.1))\n",
    "    # but it stops at 0.2, and that's because I add extra `[]` in `tf.zeros` param!\n",
    "    biases = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights, strides=[1, *conv_strides, 1], padding=\"SAME\")\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, biases)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "\n",
    "    conv_layer = tf.nn.max_pool(conv_layer,\n",
    "                                ksize=[1, *pool_ksize, 1],\n",
    "                                strides=[1, *pool_strides, 1],\n",
    "                                padding='SAME')\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # use contrib layer instead\n",
    "    size = 1\n",
    "    for x in x_tensor.get_shape().as_list():\n",
    "       if (x is not None):\n",
    "           size = size * x\n",
    "    return tf.reshape(x_tensor, [-1, size])\n",
    "\n",
    "    # return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # use contrib layer instead\n",
    "    input_size = x_tensor.get_shape().as_list()[1]\n",
    "    # also stddev saves me!\n",
    "    weights = tf.Variable(tf.truncated_normal([input_size, num_outputs], stddev=0.1))\n",
    "    biases = tf.Variable(tf.zeros(num_outputs))\n",
    "    fully_connected = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    fully_connected = tf.nn.relu(fully_connected)\n",
    "    return fully_connected\n",
    "\n",
    "    # return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.\n",
    "\n",
    "Note: Activation, softmax, or cross entropy shouldn't be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # use contrib layer instead\n",
    "    input_size = x_tensor.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal([input_size, num_outputs], stddev=0.1))\n",
    "    biases = tf.Variable(tf.zeros(num_outputs))\n",
    "    out = tf.add(tf.matmul(x_tensor, weights), biases)\n",
    "    return out\n",
    "\n",
    "    # return tf.contrib.layers.fully_connected(x_tensor, num_outputs, None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    # After exploring around, I find out such a good architecture, it get 0.4 at the third epoch\n",
    "    conv1 = conv2d_maxpool(x, 32, (8, 8), (2, 2), (4, 4), (2, 2))\n",
    "    conv2 = conv2d_maxpool(conv1, 64, (4, 4), (2, 2), (2, 2), (2, 2))\n",
    "\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv2)\n",
    "\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc1 = fully_conn(flat, 128)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fc1, 10)\n",
    "\n",
    "\n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, {x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    global losses\n",
    "    loss = session.run(cost, {x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, {x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    print('Loss: {:>10.6f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "# Focusing on training loss, it still decrease at 500 epoch\n",
    "# But the test accuracy decrease from 66.12% to 64.87%, why?\n",
    "\n",
    "# AWS is awesome! In my MacBook Pro (15-inch, 2016), it takes 6s for one epoch, \n",
    "# AWS only need less then 1s!\n",
    "epochs = 500\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:   2.136392 Validation Accuracy: 0.304600\n",
      "time:  1.0282690525054932\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:   1.919149 Validation Accuracy: 0.368000\n",
      "time:  1.001079797744751\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:   1.719495 Validation Accuracy: 0.392400\n",
      "time:  1.0399303436279297\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:   1.609898 Validation Accuracy: 0.408000\n",
      "time:  0.9794013500213623\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:   1.510165 Validation Accuracy: 0.440400\n",
      "time:  0.9845860004425049\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:   1.411475 Validation Accuracy: 0.448200\n",
      "time:  1.0000159740447998\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:   1.327960 Validation Accuracy: 0.460200\n",
      "time:  0.9860332012176514\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:   1.197607 Validation Accuracy: 0.474200\n",
      "time:  0.9918034076690674\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:   1.108681 Validation Accuracy: 0.477000\n",
      "time:  1.0500187873840332\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:   1.058357 Validation Accuracy: 0.485600\n",
      "time:  0.9769001007080078\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:   1.086519 Validation Accuracy: 0.490800\n",
      "time:  0.9768154621124268\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:   0.980982 Validation Accuracy: 0.506200\n",
      "time:  0.9787418842315674\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:   0.889150 Validation Accuracy: 0.512000\n",
      "time:  0.9863882064819336\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:   0.827235 Validation Accuracy: 0.518600\n",
      "time:  0.9798510074615479\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:   0.825838 Validation Accuracy: 0.506200\n",
      "time:  0.9904844760894775\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:   0.739205 Validation Accuracy: 0.522200\n",
      "time:  0.9783916473388672\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:   0.679871 Validation Accuracy: 0.530000\n",
      "time:  0.9789574146270752\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:   0.649936 Validation Accuracy: 0.535800\n",
      "time:  0.9823975563049316\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:   0.603509 Validation Accuracy: 0.542200\n",
      "time:  0.9843301773071289\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:   0.543639 Validation Accuracy: 0.538600\n",
      "time:  0.9857075214385986\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:   0.530588 Validation Accuracy: 0.531000\n",
      "time:  1.050337314605713\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:   0.517036 Validation Accuracy: 0.534800\n",
      "time:  0.9783504009246826\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:   0.466063 Validation Accuracy: 0.529600\n",
      "time:  0.9806973934173584\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:   0.441046 Validation Accuracy: 0.538000\n",
      "time:  0.9794182777404785\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:   0.418516 Validation Accuracy: 0.539400\n",
      "time:  0.9884545803070068\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:   0.408310 Validation Accuracy: 0.543000\n",
      "time:  0.9984035491943359\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:   0.399114 Validation Accuracy: 0.551400\n",
      "time:  1.0652222633361816\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:   0.397690 Validation Accuracy: 0.529600\n",
      "time:  0.9877479076385498\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:   0.376459 Validation Accuracy: 0.528200\n",
      "time:  0.9765188694000244\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:   0.409215 Validation Accuracy: 0.551200\n",
      "time:  0.9780535697937012\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:   0.382133 Validation Accuracy: 0.557600\n",
      "time:  0.9814789295196533\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:   0.336787 Validation Accuracy: 0.564000\n",
      "time:  0.9874882698059082\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:   0.405921 Validation Accuracy: 0.544800\n",
      "time:  0.9766263961791992\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:   0.354272 Validation Accuracy: 0.553600\n",
      "time:  0.9826030731201172\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:   0.320027 Validation Accuracy: 0.559800\n",
      "time:  0.9774265289306641\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:   0.274868 Validation Accuracy: 0.556600\n",
      "time:  0.9777438640594482\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:   0.287774 Validation Accuracy: 0.558200\n",
      "time:  0.9823493957519531\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:   0.240179 Validation Accuracy: 0.553400\n",
      "time:  0.9875171184539795\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:   0.241121 Validation Accuracy: 0.563000\n",
      "time:  1.0054659843444824\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:   0.246692 Validation Accuracy: 0.543000\n",
      "time:  1.0404317378997803\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:   0.217738 Validation Accuracy: 0.543800\n",
      "time:  0.9765088558197021\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:   0.176800 Validation Accuracy: 0.556800\n",
      "time:  0.9784688949584961\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:   0.200568 Validation Accuracy: 0.573000\n",
      "time:  0.9815950393676758\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:   0.175003 Validation Accuracy: 0.547800\n",
      "time:  0.9855763912200928\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:   0.159487 Validation Accuracy: 0.573200\n",
      "time:  0.9754939079284668\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:   0.166794 Validation Accuracy: 0.547200\n",
      "time:  1.0285975933074951\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:   0.184553 Validation Accuracy: 0.553600\n",
      "time:  0.9849576950073242\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:   0.166223 Validation Accuracy: 0.541600\n",
      "time:  0.9823324680328369\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:   0.161866 Validation Accuracy: 0.533800\n",
      "time:  0.9822559356689453\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:   0.140144 Validation Accuracy: 0.546400\n",
      "time:  0.9853711128234863\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:   0.152506 Validation Accuracy: 0.553800\n",
      "time:  0.9940910339355469\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:   0.137391 Validation Accuracy: 0.539000\n",
      "time:  1.0427281856536865\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:   0.138063 Validation Accuracy: 0.540800\n",
      "time:  0.9770371913909912\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:   0.120318 Validation Accuracy: 0.558400\n",
      "time:  0.9776761531829834\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:   0.125832 Validation Accuracy: 0.552800\n",
      "time:  0.9814648628234863\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:   0.112407 Validation Accuracy: 0.567400\n",
      "time:  0.9882934093475342\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:   0.122524 Validation Accuracy: 0.575000\n",
      "time:  0.9796035289764404\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:   0.100830 Validation Accuracy: 0.567200\n",
      "time:  0.9901187419891357\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:   0.090137 Validation Accuracy: 0.567400\n",
      "time:  0.9829866886138916\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:   0.096624 Validation Accuracy: 0.568800\n",
      "time:  0.9762692451477051\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:   0.085333 Validation Accuracy: 0.566600\n",
      "time:  0.9829120635986328\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:   0.112335 Validation Accuracy: 0.567600\n",
      "time:  0.9827451705932617\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:   0.082341 Validation Accuracy: 0.558000\n",
      "time:  0.9848384857177734\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:   0.083428 Validation Accuracy: 0.565600\n",
      "time:  0.9760406017303467\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:   0.068947 Validation Accuracy: 0.569200\n",
      "time:  0.9908366203308105\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:   0.066306 Validation Accuracy: 0.576600\n",
      "time:  0.9774444103240967\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:   0.076067 Validation Accuracy: 0.560600\n",
      "time:  0.9994733333587646\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:   0.052261 Validation Accuracy: 0.563000\n",
      "time:  0.9913270473480225\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:   0.063201 Validation Accuracy: 0.553800\n",
      "time:  0.9877164363861084\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:   0.053502 Validation Accuracy: 0.547000\n",
      "time:  0.9778306484222412\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:   0.061333 Validation Accuracy: 0.543600\n",
      "time:  0.9829800128936768\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:   0.049430 Validation Accuracy: 0.564400\n",
      "time:  0.9820778369903564\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:   0.050466 Validation Accuracy: 0.564800\n",
      "time:  0.9864990711212158\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:   0.061613 Validation Accuracy: 0.568200\n",
      "time:  1.0098626613616943\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:   0.062264 Validation Accuracy: 0.554400\n",
      "time:  1.0705132484436035\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:   0.064260 Validation Accuracy: 0.540400\n",
      "time:  0.972287654876709\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:   0.052578 Validation Accuracy: 0.558400\n",
      "time:  0.9828286170959473\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:   0.038908 Validation Accuracy: 0.568400\n",
      "time:  0.9846701622009277\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:   0.030924 Validation Accuracy: 0.564800\n",
      "time:  1.0018389225006104\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:   0.048659 Validation Accuracy: 0.565800\n",
      "time:  1.010009527206421\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:   0.048151 Validation Accuracy: 0.562200\n",
      "time:  0.9993712902069092\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:   0.047002 Validation Accuracy: 0.565200\n",
      "time:  0.9792962074279785\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:   0.077947 Validation Accuracy: 0.553800\n",
      "time:  0.9806203842163086\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:   0.069136 Validation Accuracy: 0.550800\n",
      "time:  0.9782049655914307\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:   0.061872 Validation Accuracy: 0.554400\n",
      "time:  0.9888124465942383\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:   0.035050 Validation Accuracy: 0.562200\n",
      "time:  0.9846506118774414\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:   0.034506 Validation Accuracy: 0.562400\n",
      "time:  0.9914202690124512\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:   0.039422 Validation Accuracy: 0.568000\n",
      "time:  0.989044189453125\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:   0.024158 Validation Accuracy: 0.572600\n",
      "time:  0.9942135810852051\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:   0.038500 Validation Accuracy: 0.566400\n",
      "time:  0.9859344959259033\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:   0.034642 Validation Accuracy: 0.563600\n",
      "time:  0.9967074394226074\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:   0.032459 Validation Accuracy: 0.565800\n",
      "time:  1.0426480770111084\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:   0.039768 Validation Accuracy: 0.549800\n",
      "time:  0.9918990135192871\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:   0.050005 Validation Accuracy: 0.550400\n",
      "time:  0.979445219039917\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:   0.047106 Validation Accuracy: 0.567800\n",
      "time:  0.9808309078216553\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:   0.030503 Validation Accuracy: 0.572200\n",
      "time:  0.9832046031951904\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:   0.022783 Validation Accuracy: 0.572200\n",
      "time:  0.9774165153503418\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:   0.034948 Validation Accuracy: 0.566000\n",
      "time:  0.9771089553833008\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:   0.032896 Validation Accuracy: 0.569600\n",
      "time:  0.977942705154419\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:   0.014860 Validation Accuracy: 0.555200\n",
      "time:  0.9778480529785156\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:   0.041170 Validation Accuracy: 0.552600\n",
      "time:  0.982619047164917\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:   0.030064 Validation Accuracy: 0.554600\n",
      "time:  0.9871032238006592\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:   0.017660 Validation Accuracy: 0.567400\n",
      "time:  1.00834321975708\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:   0.017483 Validation Accuracy: 0.561000\n",
      "time:  1.0525784492492676\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:   0.015124 Validation Accuracy: 0.563600\n",
      "time:  0.9773299694061279\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:   0.017083 Validation Accuracy: 0.567400\n",
      "time:  0.9773421287536621\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:   0.024510 Validation Accuracy: 0.560800\n",
      "time:  0.9829344749450684\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:   0.017495 Validation Accuracy: 0.568200\n",
      "time:  0.9854423999786377\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:   0.016825 Validation Accuracy: 0.565800\n",
      "time:  1.0118613243103027\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:   0.013855 Validation Accuracy: 0.563400\n",
      "time:  0.9810876846313477\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:   0.016744 Validation Accuracy: 0.556200\n",
      "time:  0.9781255722045898\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:   0.021569 Validation Accuracy: 0.563400\n",
      "time:  0.9801638126373291\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:   0.022321 Validation Accuracy: 0.556800\n",
      "time:  0.9902079105377197\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:   0.022667 Validation Accuracy: 0.560600\n",
      "time:  0.9897701740264893\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:   0.020317 Validation Accuracy: 0.562600\n",
      "time:  1.0056941509246826\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:   0.020563 Validation Accuracy: 0.564800\n",
      "time:  0.9806430339813232\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:   0.012968 Validation Accuracy: 0.558600\n",
      "time:  0.9811193943023682\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:   0.014154 Validation Accuracy: 0.547600\n",
      "time:  0.9844183921813965\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:   0.015588 Validation Accuracy: 0.562600\n",
      "time:  0.9822876453399658\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:   0.011078 Validation Accuracy: 0.557600\n",
      "time:  0.9860780239105225\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:   0.015525 Validation Accuracy: 0.560000\n",
      "time:  0.9990754127502441\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:   0.019216 Validation Accuracy: 0.552200\n",
      "time:  0.9988760948181152\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:   0.012253 Validation Accuracy: 0.560400\n",
      "time:  0.9777016639709473\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:   0.013906 Validation Accuracy: 0.552000\n",
      "time:  0.9767935276031494\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:   0.014771 Validation Accuracy: 0.550000\n",
      "time:  0.9830965995788574\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:   0.009604 Validation Accuracy: 0.550600\n",
      "time:  0.9858841896057129\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:   0.013647 Validation Accuracy: 0.553200\n",
      "time:  1.0006253719329834\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:   0.014519 Validation Accuracy: 0.556000\n",
      "time:  1.0261032581329346\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:   0.010199 Validation Accuracy: 0.559000\n",
      "time:  0.9809436798095703\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:   0.025646 Validation Accuracy: 0.556800\n",
      "time:  0.9765264987945557\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:   0.014831 Validation Accuracy: 0.562200\n",
      "time:  0.9821975231170654\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:   0.017326 Validation Accuracy: 0.562600\n",
      "time:  0.9885072708129883\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:   0.012249 Validation Accuracy: 0.555000\n",
      "time:  0.9831879138946533\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:   0.009467 Validation Accuracy: 0.548200\n",
      "time:  0.9751999378204346\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:   0.015936 Validation Accuracy: 0.545200\n",
      "time:  0.9807486534118652\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:   0.013735 Validation Accuracy: 0.553000\n",
      "time:  0.9770395755767822\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:   0.013310 Validation Accuracy: 0.553000\n",
      "time:  0.9814083576202393\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:   0.018443 Validation Accuracy: 0.559600\n",
      "time:  0.9856917858123779\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:   0.012931 Validation Accuracy: 0.552800\n",
      "time:  1.0586118698120117\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:   0.008005 Validation Accuracy: 0.558000\n",
      "time:  1.0380494594573975\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:   0.011558 Validation Accuracy: 0.555200\n",
      "time:  0.9784059524536133\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:   0.015474 Validation Accuracy: 0.562200\n",
      "time:  0.981696367263794\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:   0.004742 Validation Accuracy: 0.557200\n",
      "time:  0.9850103855133057\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:   0.016099 Validation Accuracy: 0.555000\n",
      "time:  0.9926328659057617\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:   0.007930 Validation Accuracy: 0.549400\n",
      "time:  1.0481162071228027\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:   0.007607 Validation Accuracy: 0.555000\n",
      "time:  1.0346965789794922\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:   0.005423 Validation Accuracy: 0.555000\n",
      "time:  0.9831485748291016\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:   0.003816 Validation Accuracy: 0.551200\n",
      "time:  0.9754166603088379\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:   0.004899 Validation Accuracy: 0.541200\n",
      "time:  0.9813635349273682\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:   0.005356 Validation Accuracy: 0.560000\n",
      "time:  0.9881064891815186\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:   0.003545 Validation Accuracy: 0.552400\n",
      "time:  0.9805822372436523\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:   0.002775 Validation Accuracy: 0.559600\n",
      "time:  0.9792957305908203\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:   0.005027 Validation Accuracy: 0.554400\n",
      "time:  0.9785666465759277\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:   0.005621 Validation Accuracy: 0.553600\n",
      "time:  0.9806745052337646\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:   0.004203 Validation Accuracy: 0.543800\n",
      "time:  0.9832077026367188\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:   0.004144 Validation Accuracy: 0.547600\n",
      "time:  0.9857733249664307\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:   0.003303 Validation Accuracy: 0.550800\n",
      "time:  0.9822444915771484\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:   0.005675 Validation Accuracy: 0.552000\n",
      "time:  0.9786384105682373\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:   0.002199 Validation Accuracy: 0.554800\n",
      "time:  0.9782474040985107\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:   0.002274 Validation Accuracy: 0.547600\n",
      "time:  0.976273775100708\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:   0.003812 Validation Accuracy: 0.554400\n",
      "time:  0.9871826171875\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:   0.006812 Validation Accuracy: 0.541000\n",
      "time:  1.0037100315093994\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:   0.002971 Validation Accuracy: 0.558000\n",
      "time:  1.0529825687408447\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:   0.004067 Validation Accuracy: 0.553800\n",
      "time:  0.9790341854095459\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:   0.004237 Validation Accuracy: 0.550400\n",
      "time:  0.9771823883056641\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:   0.009042 Validation Accuracy: 0.532400\n",
      "time:  0.9823706150054932\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:   0.004628 Validation Accuracy: 0.549600\n",
      "time:  0.983799934387207\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:   0.003761 Validation Accuracy: 0.543800\n",
      "time:  1.001645565032959\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:   0.002877 Validation Accuracy: 0.554000\n",
      "time:  1.0649254322052002\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:   0.005151 Validation Accuracy: 0.546000\n",
      "time:  0.9806191921234131\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:   0.005121 Validation Accuracy: 0.549200\n",
      "time:  0.9775967597961426\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:   0.005353 Validation Accuracy: 0.557000\n",
      "time:  0.9811089038848877\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:   0.005302 Validation Accuracy: 0.550000\n",
      "time:  0.9845461845397949\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:   0.002078 Validation Accuracy: 0.547000\n",
      "time:  1.0052049160003662\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:   0.002315 Validation Accuracy: 0.549000\n",
      "time:  1.0632805824279785\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:   0.001961 Validation Accuracy: 0.560800\n",
      "time:  0.9841599464416504\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:   0.003579 Validation Accuracy: 0.551000\n",
      "time:  0.9824280738830566\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:   0.002447 Validation Accuracy: 0.556800\n",
      "time:  0.9792969226837158\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:   0.001698 Validation Accuracy: 0.548400\n",
      "time:  0.9832980632781982\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:   0.002300 Validation Accuracy: 0.550000\n",
      "time:  0.9897243976593018\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:   0.001022 Validation Accuracy: 0.561200\n",
      "time:  0.9809873104095459\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:   0.001761 Validation Accuracy: 0.555600\n",
      "time:  0.9772634506225586\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:   0.001030 Validation Accuracy: 0.555000\n",
      "time:  0.9818732738494873\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:   0.001212 Validation Accuracy: 0.555400\n",
      "time:  0.9801783561706543\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:   0.001866 Validation Accuracy: 0.558800\n",
      "time:  0.9846663475036621\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:   0.001833 Validation Accuracy: 0.555800\n",
      "time:  0.9857726097106934\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:   0.004098 Validation Accuracy: 0.543400\n",
      "time:  0.9745481014251709\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:   0.002071 Validation Accuracy: 0.552400\n",
      "time:  0.9909496307373047\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:   0.001346 Validation Accuracy: 0.550800\n",
      "time:  0.9795410633087158\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:   0.002700 Validation Accuracy: 0.546200\n",
      "time:  0.9792759418487549\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:   0.001397 Validation Accuracy: 0.553000\n",
      "time:  0.9848966598510742\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:   0.001665 Validation Accuracy: 0.554800\n",
      "time:  0.9799206256866455\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:   0.004899 Validation Accuracy: 0.546000\n",
      "time:  0.983534574508667\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:   0.001747 Validation Accuracy: 0.543400\n",
      "time:  0.988806962966919\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:   0.001598 Validation Accuracy: 0.550600\n",
      "time:  0.9857673645019531\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:   0.002631 Validation Accuracy: 0.546600\n",
      "time:  0.9813458919525146\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:   0.001032 Validation Accuracy: 0.543400\n",
      "time:  0.9815332889556885\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:   0.001889 Validation Accuracy: 0.541600\n",
      "time:  0.9826691150665283\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:   0.007055 Validation Accuracy: 0.533000\n",
      "time:  0.9823589324951172\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:   0.003112 Validation Accuracy: 0.537200\n",
      "time:  0.977691650390625\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:   0.004907 Validation Accuracy: 0.536800\n",
      "time:  0.985774040222168\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:   0.007738 Validation Accuracy: 0.533800\n",
      "time:  0.9823126792907715\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:   0.002629 Validation Accuracy: 0.533600\n",
      "time:  0.9844439029693604\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:   0.000988 Validation Accuracy: 0.539200\n",
      "time:  0.9867570400238037\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:   0.001507 Validation Accuracy: 0.530400\n",
      "time:  0.9843862056732178\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:   0.000824 Validation Accuracy: 0.552600\n",
      "time:  0.9783258438110352\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:   0.001947 Validation Accuracy: 0.543000\n",
      "time:  0.9802236557006836\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:   0.007962 Validation Accuracy: 0.558000\n",
      "time:  0.978644609451294\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:   0.001504 Validation Accuracy: 0.550800\n",
      "time:  0.9865200519561768\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:   0.003836 Validation Accuracy: 0.553600\n",
      "time:  0.9802942276000977\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:   0.002520 Validation Accuracy: 0.556600\n",
      "time:  0.9829034805297852\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:   0.004858 Validation Accuracy: 0.542000\n",
      "time:  0.9798107147216797\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:   0.001878 Validation Accuracy: 0.557000\n",
      "time:  0.9806978702545166\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:   0.001818 Validation Accuracy: 0.545000\n",
      "time:  0.9812264442443848\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:   0.004064 Validation Accuracy: 0.531200\n",
      "time:  0.9878098964691162\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:   0.001666 Validation Accuracy: 0.529600\n",
      "time:  0.9769744873046875\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:   0.001162 Validation Accuracy: 0.532000\n",
      "time:  0.986403226852417\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:   0.002284 Validation Accuracy: 0.537400\n",
      "time:  0.9750125408172607\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:   0.001427 Validation Accuracy: 0.539400\n",
      "time:  0.9792032241821289\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:   0.001263 Validation Accuracy: 0.534000\n",
      "time:  0.9783518314361572\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:   0.001133 Validation Accuracy: 0.529800\n",
      "time:  0.9865090847015381\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:   0.000952 Validation Accuracy: 0.538600\n",
      "time:  0.9809072017669678\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:   0.002443 Validation Accuracy: 0.534800\n",
      "time:  0.982943058013916\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:   0.001900 Validation Accuracy: 0.535800\n",
      "time:  0.9784860610961914\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:   0.001445 Validation Accuracy: 0.544200\n",
      "time:  0.9776110649108887\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:   0.002160 Validation Accuracy: 0.540400\n",
      "time:  0.9792983531951904\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:   0.003361 Validation Accuracy: 0.532600\n",
      "time:  0.9860761165618896\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:   0.000605 Validation Accuracy: 0.543600\n",
      "time:  0.9800057411193848\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:   0.002579 Validation Accuracy: 0.550000\n",
      "time:  0.9817368984222412\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:   0.001933 Validation Accuracy: 0.547600\n",
      "time:  0.9779074192047119\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:   0.003891 Validation Accuracy: 0.549800\n",
      "time:  0.9819579124450684\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:   0.004297 Validation Accuracy: 0.559000\n",
      "time:  0.9792757034301758\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:   0.000571 Validation Accuracy: 0.554200\n",
      "time:  0.9840867519378662\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:   0.001445 Validation Accuracy: 0.555200\n",
      "time:  0.9812159538269043\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:   0.003028 Validation Accuracy: 0.555200\n",
      "time:  0.9805078506469727\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:   0.000845 Validation Accuracy: 0.556400\n",
      "time:  0.9933459758758545\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:   0.001423 Validation Accuracy: 0.552600\n",
      "time:  0.9809811115264893\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:   0.002959 Validation Accuracy: 0.554400\n",
      "time:  0.9838483333587646\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:   0.000507 Validation Accuracy: 0.560600\n",
      "time:  0.984093189239502\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:   0.000478 Validation Accuracy: 0.560400\n",
      "time:  0.9795610904693604\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:   0.000283 Validation Accuracy: 0.560000\n",
      "time:  0.9863102436065674\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:   0.000493 Validation Accuracy: 0.554000\n",
      "time:  0.9776146411895752\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:   0.000555 Validation Accuracy: 0.557000\n",
      "time:  0.9813299179077148\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:   0.000966 Validation Accuracy: 0.561400\n",
      "time:  0.9799385070800781\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:   0.010023 Validation Accuracy: 0.558000\n",
      "time:  0.9873464107513428\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:   0.000441 Validation Accuracy: 0.553000\n",
      "time:  0.9798698425292969\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:   0.001362 Validation Accuracy: 0.549800\n",
      "time:  0.9933087825775146\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:   0.000585 Validation Accuracy: 0.555600\n",
      "time:  0.9765012264251709\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:   0.005105 Validation Accuracy: 0.544000\n",
      "time:  1.0086798667907715\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:   0.000433 Validation Accuracy: 0.548200\n",
      "time:  0.9764254093170166\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:   0.001840 Validation Accuracy: 0.536800\n",
      "time:  0.9855480194091797\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:   0.000500 Validation Accuracy: 0.547000\n",
      "time:  0.9798660278320312\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:   0.000422 Validation Accuracy: 0.551200\n",
      "time:  0.9838593006134033\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:   0.000725 Validation Accuracy: 0.542000\n",
      "time:  0.9826362133026123\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:   0.001003 Validation Accuracy: 0.540200\n",
      "time:  0.9804260730743408\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:   0.001033 Validation Accuracy: 0.532200\n",
      "time:  0.9786171913146973\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:   0.001023 Validation Accuracy: 0.546600\n",
      "time:  0.9979510307312012\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:   0.015495 Validation Accuracy: 0.543600\n",
      "time:  0.9808549880981445\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:   0.000350 Validation Accuracy: 0.531800\n",
      "time:  0.9836342334747314\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:   0.007032 Validation Accuracy: 0.538200\n",
      "time:  0.9743890762329102\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:   0.000637 Validation Accuracy: 0.545400\n",
      "time:  0.9795324802398682\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:   0.000559 Validation Accuracy: 0.539200\n",
      "time:  0.9804356098175049\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:   0.000810 Validation Accuracy: 0.550200\n",
      "time:  0.9842743873596191\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:   0.001366 Validation Accuracy: 0.545200\n",
      "time:  0.9819729328155518\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:   0.000404 Validation Accuracy: 0.544400\n",
      "time:  0.9825179576873779\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:   0.001794 Validation Accuracy: 0.544400\n",
      "time:  0.9789535999298096\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:   0.000608 Validation Accuracy: 0.544000\n",
      "time:  0.9876618385314941\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:   0.000216 Validation Accuracy: 0.544800\n",
      "time:  0.9821732044219971\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:   0.000211 Validation Accuracy: 0.549000\n",
      "time:  0.9820830821990967\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:   0.000217 Validation Accuracy: 0.555800\n",
      "time:  0.9816005229949951\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:   0.000121 Validation Accuracy: 0.545600\n",
      "time:  0.981332540512085\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:   0.000239 Validation Accuracy: 0.557800\n",
      "time:  0.9827077388763428\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:   0.001265 Validation Accuracy: 0.552200\n",
      "time:  0.9796485900878906\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:   0.000227 Validation Accuracy: 0.551600\n",
      "time:  0.9865005016326904\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:   0.000111 Validation Accuracy: 0.558600\n",
      "time:  1.0094208717346191\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:   0.000116 Validation Accuracy: 0.558200\n",
      "time:  1.0029008388519287\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:   0.000160 Validation Accuracy: 0.555000\n",
      "time:  0.9990358352661133\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:   0.000199 Validation Accuracy: 0.555600\n",
      "time:  0.9993877410888672\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:   0.002788 Validation Accuracy: 0.542000\n",
      "time:  1.0033133029937744\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:   0.000333 Validation Accuracy: 0.553200\n",
      "time:  0.9923193454742432\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:   0.000124 Validation Accuracy: 0.555000\n",
      "time:  1.0036046504974365\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:   0.000152 Validation Accuracy: 0.552000\n",
      "time:  0.985633373260498\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:   0.000305 Validation Accuracy: 0.550400\n",
      "time:  0.9834778308868408\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:   0.000674 Validation Accuracy: 0.552600\n",
      "time:  0.9786150455474854\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:   0.000358 Validation Accuracy: 0.552200\n",
      "time:  0.9791421890258789\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:   0.000550 Validation Accuracy: 0.539400\n",
      "time:  0.9781289100646973\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:   0.000289 Validation Accuracy: 0.555600\n",
      "time:  0.9858710765838623\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:   0.000138 Validation Accuracy: 0.551400\n",
      "time:  0.9821681976318359\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:   0.000140 Validation Accuracy: 0.550200\n",
      "time:  0.9791021347045898\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:   0.000141 Validation Accuracy: 0.547400\n",
      "time:  0.9853901863098145\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:   0.000107 Validation Accuracy: 0.549800\n",
      "time:  0.9793877601623535\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:   0.000906 Validation Accuracy: 0.552800\n",
      "time:  0.9782545566558838\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:   0.000183 Validation Accuracy: 0.550000\n",
      "time:  0.9865608215332031\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:   0.000117 Validation Accuracy: 0.551000\n",
      "time:  0.9810535907745361\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:   0.000336 Validation Accuracy: 0.549200\n",
      "time:  0.9835712909698486\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:   0.000707 Validation Accuracy: 0.548800\n",
      "time:  0.9804952144622803\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:   0.000261 Validation Accuracy: 0.538400\n",
      "time:  0.9814579486846924\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:   0.000135 Validation Accuracy: 0.545000\n",
      "time:  0.9816296100616455\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:   0.000104 Validation Accuracy: 0.548000\n",
      "time:  0.9814138412475586\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:   0.000314 Validation Accuracy: 0.551000\n",
      "time:  0.9828810691833496\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:   0.000852 Validation Accuracy: 0.535000\n",
      "time:  0.9830143451690674\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:   0.000172 Validation Accuracy: 0.545600\n",
      "time:  0.9822549819946289\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:   0.000675 Validation Accuracy: 0.542000\n",
      "time:  0.9833550453186035\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:   0.000191 Validation Accuracy: 0.541200\n",
      "time:  0.9769766330718994\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:   0.000636 Validation Accuracy: 0.549800\n",
      "time:  0.9853131771087646\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:   0.000460 Validation Accuracy: 0.548400\n",
      "time:  0.9802086353302002\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:   0.001021 Validation Accuracy: 0.538800\n",
      "time:  0.980231761932373\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:   0.000459 Validation Accuracy: 0.540600\n",
      "time:  0.9854013919830322\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:   0.000170 Validation Accuracy: 0.537400\n",
      "time:  0.9785680770874023\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:   0.000327 Validation Accuracy: 0.528400\n",
      "time:  0.9969959259033203\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:   0.003117 Validation Accuracy: 0.543400\n",
      "time:  0.997431755065918\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:   0.000264 Validation Accuracy: 0.548600\n",
      "time:  0.9818100929260254\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:   0.002469 Validation Accuracy: 0.540400\n",
      "time:  0.9801468849182129\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:   0.000135 Validation Accuracy: 0.539000\n",
      "time:  0.9854552745819092\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:   0.000439 Validation Accuracy: 0.540600\n",
      "time:  0.9839291572570801\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:   0.000340 Validation Accuracy: 0.543000\n",
      "time:  0.9766805171966553\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:   0.001337 Validation Accuracy: 0.532400\n",
      "time:  0.9837319850921631\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:   0.000772 Validation Accuracy: 0.533600\n",
      "time:  0.9835567474365234\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:   0.000774 Validation Accuracy: 0.518600\n",
      "time:  0.9781618118286133\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:   0.000285 Validation Accuracy: 0.546600\n",
      "time:  0.9825317859649658\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:   0.000799 Validation Accuracy: 0.530000\n",
      "time:  0.9849791526794434\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:   0.000551 Validation Accuracy: 0.535600\n",
      "time:  0.9780697822570801\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:   0.000585 Validation Accuracy: 0.536600\n",
      "time:  0.9888613224029541\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:   0.000642 Validation Accuracy: 0.541000\n",
      "time:  0.9789550304412842\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:   0.000135 Validation Accuracy: 0.545400\n",
      "time:  0.9866526126861572\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:   0.000119 Validation Accuracy: 0.538400\n",
      "time:  0.9806559085845947\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:   0.000473 Validation Accuracy: 0.541000\n",
      "time:  0.984938383102417\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:   0.000683 Validation Accuracy: 0.536400\n",
      "time:  0.991063117980957\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:   0.000142 Validation Accuracy: 0.536600\n",
      "time:  1.019984483718872\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:   0.000902 Validation Accuracy: 0.534800\n",
      "time:  0.9788839817047119\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:   0.000438 Validation Accuracy: 0.545800\n",
      "time:  0.9808557033538818\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:   0.000603 Validation Accuracy: 0.540600\n",
      "time:  0.9805729389190674\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:   0.000597 Validation Accuracy: 0.549400\n",
      "time:  0.9872293472290039\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:   0.000488 Validation Accuracy: 0.553200\n",
      "time:  1.0367975234985352\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:   0.000159 Validation Accuracy: 0.544000\n",
      "time:  1.053600788116455\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:   0.000052 Validation Accuracy: 0.543800\n",
      "time:  0.9797275066375732\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:   0.000045 Validation Accuracy: 0.550400\n",
      "time:  0.9808764457702637\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:   0.000045 Validation Accuracy: 0.546600\n",
      "time:  0.9799861907958984\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:   0.000588 Validation Accuracy: 0.557600\n",
      "time:  0.9858453273773193\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:   0.000126 Validation Accuracy: 0.552800\n",
      "time:  0.984952449798584\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:   0.000100 Validation Accuracy: 0.549800\n",
      "time:  0.9758200645446777\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:   0.000056 Validation Accuracy: 0.556000\n",
      "time:  0.9817509651184082\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:   0.000148 Validation Accuracy: 0.547000\n",
      "time:  0.9825596809387207\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:   0.000108 Validation Accuracy: 0.548800\n",
      "time:  0.9829850196838379\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:   0.000026 Validation Accuracy: 0.555800\n",
      "time:  0.9842915534973145\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:   0.000066 Validation Accuracy: 0.555600\n",
      "time:  0.9891393184661865\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:   0.000199 Validation Accuracy: 0.564200\n",
      "time:  0.9775450229644775\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:   0.000178 Validation Accuracy: 0.562200\n",
      "time:  0.9807918071746826\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:   0.000116 Validation Accuracy: 0.558400\n",
      "time:  0.9764947891235352\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:   0.000081 Validation Accuracy: 0.556600\n",
      "time:  0.9823637008666992\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:   0.000152 Validation Accuracy: 0.547000\n",
      "time:  0.984553337097168\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:   0.000073 Validation Accuracy: 0.554200\n",
      "time:  1.000410556793213\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:   0.000059 Validation Accuracy: 0.554000\n",
      "time:  1.0212604999542236\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:   0.000048 Validation Accuracy: 0.556600\n",
      "time:  0.9772017002105713\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:   0.000029 Validation Accuracy: 0.559600\n",
      "time:  0.9811828136444092\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:   0.000085 Validation Accuracy: 0.555200\n",
      "time:  0.985325813293457\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:   0.000012 Validation Accuracy: 0.555200\n",
      "time:  0.9848423004150391\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:   0.000132 Validation Accuracy: 0.551400\n",
      "time:  0.9809582233428955\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:   0.000145 Validation Accuracy: 0.551400\n",
      "time:  0.980086088180542\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:   0.000052 Validation Accuracy: 0.546000\n",
      "time:  0.9748682975769043\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:   0.000047 Validation Accuracy: 0.554200\n",
      "time:  0.9817330837249756\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:   0.000249 Validation Accuracy: 0.561000\n",
      "time:  0.9807329177856445\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:   0.000057 Validation Accuracy: 0.561400\n",
      "time:  0.9881701469421387\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:   0.000225 Validation Accuracy: 0.550600\n",
      "time:  0.9803578853607178\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:   0.000017 Validation Accuracy: 0.551200\n",
      "time:  0.9809834957122803\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:   0.004575 Validation Accuracy: 0.542200\n",
      "time:  0.976020097732544\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:   0.000167 Validation Accuracy: 0.557800\n",
      "time:  0.9799225330352783\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:   0.000038 Validation Accuracy: 0.559400\n",
      "time:  0.9807717800140381\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:   0.000039 Validation Accuracy: 0.552800\n",
      "time:  0.9881062507629395\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:   0.000282 Validation Accuracy: 0.548200\n",
      "time:  0.9972937107086182\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:   0.000164 Validation Accuracy: 0.555400\n",
      "time:  0.9833097457885742\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:   0.000206 Validation Accuracy: 0.549200\n",
      "time:  0.9788308143615723\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:   0.000024 Validation Accuracy: 0.555600\n",
      "time:  0.9803366661071777\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:   0.000137 Validation Accuracy: 0.555800\n",
      "time:  0.9889276027679443\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:   0.000869 Validation Accuracy: 0.556000\n",
      "time:  0.9807693958282471\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:   0.000028 Validation Accuracy: 0.557400\n",
      "time:  0.9794411659240723\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:   0.000024 Validation Accuracy: 0.559200\n",
      "time:  0.9813015460968018\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:   0.000095 Validation Accuracy: 0.561200\n",
      "time:  0.9816579818725586\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:   0.000011 Validation Accuracy: 0.552000\n",
      "time:  0.9850096702575684\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:   0.000060 Validation Accuracy: 0.557200\n",
      "time:  0.9831740856170654\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:   0.000031 Validation Accuracy: 0.550800\n",
      "time:  1.0106127262115479\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:   0.000044 Validation Accuracy: 0.550400\n",
      "time:  0.9838559627532959\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:   0.000039 Validation Accuracy: 0.551000\n",
      "time:  0.9810795783996582\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:   0.056205 Validation Accuracy: 0.558400\n",
      "time:  0.9804954528808594\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:   0.000102 Validation Accuracy: 0.558200\n",
      "time:  1.000199317932129\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:   0.000015 Validation Accuracy: 0.553800\n",
      "time:  0.9890778064727783\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:   0.000024 Validation Accuracy: 0.551200\n",
      "time:  0.9997591972351074\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:   0.000022 Validation Accuracy: 0.554600\n",
      "time:  1.013481616973877\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:   0.000031 Validation Accuracy: 0.546200\n",
      "time:  0.9821498394012451\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:   0.000098 Validation Accuracy: 0.557000\n",
      "time:  0.9877667427062988\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:   0.000046 Validation Accuracy: 0.552200\n",
      "time:  0.9950606822967529\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:   0.000033 Validation Accuracy: 0.550400\n",
      "time:  1.0029828548431396\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:   0.000006 Validation Accuracy: 0.558400\n",
      "time:  1.053297519683838\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:   0.000016 Validation Accuracy: 0.553400\n",
      "time:  1.0121562480926514\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:   0.000056 Validation Accuracy: 0.547600\n",
      "time:  0.9788978099822998\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:   0.000012 Validation Accuracy: 0.557000\n",
      "time:  0.9818115234375\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:   0.000032 Validation Accuracy: 0.560200\n",
      "time:  0.981008768081665\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:   0.000032 Validation Accuracy: 0.551400\n",
      "time:  1.0105092525482178\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:   0.000575 Validation Accuracy: 0.552200\n",
      "time:  1.0634093284606934\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:   0.000047 Validation Accuracy: 0.556200\n",
      "time:  1.0172102451324463\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:   0.000007 Validation Accuracy: 0.558600\n",
      "time:  0.9822065830230713\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:   0.000342 Validation Accuracy: 0.551000\n",
      "time:  0.9794690608978271\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:   0.000068 Validation Accuracy: 0.546000\n",
      "time:  0.9854333400726318\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:   0.000008 Validation Accuracy: 0.546000\n",
      "time:  0.9894006252288818\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:   0.000031 Validation Accuracy: 0.540400\n",
      "time:  1.0620803833007812\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:   0.000080 Validation Accuracy: 0.553400\n",
      "time:  1.0198421478271484\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:   0.000060 Validation Accuracy: 0.559800\n",
      "time:  0.9788248538970947\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:   0.000078 Validation Accuracy: 0.547200\n",
      "time:  0.9829492568969727\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:   0.000012 Validation Accuracy: 0.546800\n",
      "time:  0.9823849201202393\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:   0.000012 Validation Accuracy: 0.559800\n",
      "time:  0.9993023872375488\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:   0.000015 Validation Accuracy: 0.549200\n",
      "time:  1.067845344543457\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:   0.000016 Validation Accuracy: 0.552000\n",
      "time:  1.0385606288909912\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:   0.000018 Validation Accuracy: 0.553600\n",
      "time:  0.9794402122497559\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:   0.000015 Validation Accuracy: 0.556200\n",
      "time:  0.9796304702758789\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:   0.000066 Validation Accuracy: 0.542000\n",
      "time:  0.9855279922485352\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:   0.000006 Validation Accuracy: 0.551200\n",
      "time:  1.0041577816009521\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:   0.000022 Validation Accuracy: 0.564000\n",
      "time:  1.0430150032043457\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:   0.000005 Validation Accuracy: 0.558400\n",
      "time:  0.9775679111480713\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:   0.000008 Validation Accuracy: 0.551000\n",
      "time:  0.9831676483154297\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:   0.000026 Validation Accuracy: 0.547800\n",
      "time:  0.9784574508666992\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:   0.000029 Validation Accuracy: 0.548600\n",
      "time:  0.9872121810913086\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:   0.000023 Validation Accuracy: 0.552400\n",
      "time:  0.9800534248352051\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:   0.000008 Validation Accuracy: 0.552200\n",
      "time:  0.9793961048126221\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:   0.000018 Validation Accuracy: 0.544800\n",
      "time:  0.9759359359741211\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:   0.000060 Validation Accuracy: 0.543200\n",
      "time:  0.9810707569122314\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:   0.000043 Validation Accuracy: 0.551000\n",
      "time:  0.9825034141540527\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:   0.000013 Validation Accuracy: 0.542000\n",
      "time:  0.9862301349639893\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:   0.000392 Validation Accuracy: 0.545600\n",
      "time:  0.9747085571289062\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:   0.000488 Validation Accuracy: 0.552200\n",
      "time:  0.9854898452758789\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:   0.001160 Validation Accuracy: 0.548600\n",
      "time:  0.9915452003479004\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:   0.000017 Validation Accuracy: 0.548200\n",
      "time:  0.9841005802154541\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:   0.000059 Validation Accuracy: 0.545600\n",
      "time:  0.9801394939422607\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:   0.000059 Validation Accuracy: 0.557600\n",
      "time:  0.9865496158599854\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:   0.000984 Validation Accuracy: 0.546600\n",
      "time:  1.0069632530212402\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:   0.000155 Validation Accuracy: 0.551400\n",
      "time:  1.0534584522247314\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:   0.000035 Validation Accuracy: 0.552000\n",
      "time:  0.9786980152130127\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:   0.000104 Validation Accuracy: 0.551600\n",
      "time:  0.9821112155914307\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:   0.000069 Validation Accuracy: 0.545000\n",
      "time:  0.981102705001831\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:   0.000071 Validation Accuracy: 0.553400\n",
      "time:  0.9906036853790283\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:   0.000035 Validation Accuracy: 0.553200\n",
      "time:  0.9997692108154297\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:   0.000017 Validation Accuracy: 0.553600\n",
      "time:  1.052541971206665\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:   0.000044 Validation Accuracy: 0.556600\n",
      "time:  0.9799232482910156\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:   0.000031 Validation Accuracy: 0.559200\n",
      "time:  0.9827218055725098\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:   0.000047 Validation Accuracy: 0.550800\n",
      "time:  0.9823634624481201\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:   0.000115 Validation Accuracy: 0.553400\n",
      "time:  0.9953711032867432\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:   0.000239 Validation Accuracy: 0.552400\n",
      "time:  1.005056619644165\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:   0.000057 Validation Accuracy: 0.554200\n",
      "time:  1.054448127746582\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:   0.000038 Validation Accuracy: 0.551000\n",
      "time:  0.9766499996185303\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:   0.000446 Validation Accuracy: 0.555600\n",
      "time:  0.9790513515472412\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:   0.000056 Validation Accuracy: 0.548800\n",
      "time:  0.9818964004516602\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:   0.000016 Validation Accuracy: 0.552200\n",
      "time:  0.9877328872680664\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:   0.000069 Validation Accuracy: 0.550000\n",
      "time:  0.9847366809844971\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:   0.000012 Validation Accuracy: 0.543000\n",
      "time:  0.9847843647003174\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:   0.000010 Validation Accuracy: 0.550400\n",
      "time:  0.980374813079834\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:   0.000090 Validation Accuracy: 0.551400\n",
      "time:  0.9814558029174805\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:   0.000031 Validation Accuracy: 0.548600\n",
      "time:  0.9784409999847412\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:   0.000059 Validation Accuracy: 0.546600\n",
      "time:  0.9863059520721436\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:   0.000008 Validation Accuracy: 0.551600\n",
      "time:  0.9888148307800293\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:   0.000006 Validation Accuracy: 0.547600\n",
      "time:  0.9781439304351807\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:   0.000010 Validation Accuracy: 0.540200\n",
      "time:  1.007547378540039\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:   0.000074 Validation Accuracy: 0.536600\n",
      "time:  0.9760794639587402\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:   0.000015 Validation Accuracy: 0.547600\n",
      "time:  0.9772841930389404\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:   0.000007 Validation Accuracy: 0.550600\n",
      "time:  0.9839489459991455\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:   0.000001 Validation Accuracy: 0.554800\n",
      "time:  0.9881947040557861\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:   0.000004 Validation Accuracy: 0.557200\n",
      "time:  1.001363754272461\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:   0.000027 Validation Accuracy: 0.545600\n",
      "time:  1.0387070178985596\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:   0.000030 Validation Accuracy: 0.552600\n",
      "time:  0.9775207042694092\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:   0.000049 Validation Accuracy: 0.552800\n",
      "time:  0.9777140617370605\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:   0.000008 Validation Accuracy: 0.554600\n",
      "time:  0.9820253849029541\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:   0.000011 Validation Accuracy: 0.543800\n",
      "time:  0.9892621040344238\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:   0.000033 Validation Accuracy: 0.548000\n",
      "time:  0.9820606708526611\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:   0.000599 Validation Accuracy: 0.536400\n",
      "time:  0.9756200313568115\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:   0.000018 Validation Accuracy: 0.549400\n",
      "time:  0.9857051372528076\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:   0.000368 Validation Accuracy: 0.534000\n",
      "time:  0.9815292358398438\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:   0.000371 Validation Accuracy: 0.541400\n",
      "time:  0.988572359085083\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:   0.000784 Validation Accuracy: 0.543600\n",
      "time:  0.976557731628418\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:   0.000051 Validation Accuracy: 0.539600\n",
      "time:  0.9914963245391846\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:   0.000038 Validation Accuracy: 0.541400\n",
      "time:  0.9751954078674316\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:   0.000065 Validation Accuracy: 0.546200\n",
      "time:  0.9854066371917725\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:   0.000193 Validation Accuracy: 0.549800\n",
      "time:  0.9832117557525635\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:   0.000015 Validation Accuracy: 0.552600\n",
      "time:  0.990455150604248\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:   0.000035 Validation Accuracy: 0.553200\n",
      "time:  0.9803581237792969\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:   0.000018 Validation Accuracy: 0.546200\n",
      "time:  0.9826469421386719\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:   0.000257 Validation Accuracy: 0.548400\n",
      "time:  0.9743092060089111\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:   0.000075 Validation Accuracy: 0.543800\n",
      "time:  0.981295108795166\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:   0.000027 Validation Accuracy: 0.555600\n",
      "time:  0.9833338260650635\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:   0.000157 Validation Accuracy: 0.559000\n",
      "time:  1.0031030178070068\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:   0.000009 Validation Accuracy: 0.556800\n",
      "time:  1.0538549423217773\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:   0.000037 Validation Accuracy: 0.552800\n",
      "time:  0.9794070720672607\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:   0.000039 Validation Accuracy: 0.551800\n",
      "time:  0.9794614315032959\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:   0.000003 Validation Accuracy: 0.548200\n",
      "time:  0.9888513088226318\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:   0.000010 Validation Accuracy: 0.556000\n",
      "time:  0.9830217361450195\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:   0.000025 Validation Accuracy: 0.554400\n",
      "time:  1.0089983940124512\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:   0.000013 Validation Accuracy: 0.555000\n",
      "time:  1.0625193119049072\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:   0.000029 Validation Accuracy: 0.560400\n",
      "time:  0.9822449684143066\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:   0.000015 Validation Accuracy: 0.546200\n",
      "time:  0.9754936695098877\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:   0.000007 Validation Accuracy: 0.545400\n",
      "time:  0.9819526672363281\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:   0.001557 Validation Accuracy: 0.545000\n",
      "time:  0.9818675518035889\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:   0.000467 Validation Accuracy: 0.542000\n",
      "time:  0.9851648807525635\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:   0.000009 Validation Accuracy: 0.551800\n",
      "time:  0.9888079166412354\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "        end = time.time()\n",
    "        print(\"time: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:   2.104468 Validation Accuracy: 0.297200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:   1.932559 Validation Accuracy: 0.332600\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:   1.613792 Validation Accuracy: 0.353800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:   1.641750 Validation Accuracy: 0.415400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:   1.651706 Validation Accuracy: 0.434400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:   1.717466 Validation Accuracy: 0.447800\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:   1.706840 Validation Accuracy: 0.442800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:   1.331562 Validation Accuracy: 0.432800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:   1.496599 Validation Accuracy: 0.473000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:   1.549848 Validation Accuracy: 0.483000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:   1.512577 Validation Accuracy: 0.476200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:   1.499866 Validation Accuracy: 0.488800\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:   1.146064 Validation Accuracy: 0.473400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:   1.357255 Validation Accuracy: 0.484200\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:   1.439000 Validation Accuracy: 0.515800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:   1.351116 Validation Accuracy: 0.518800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:   1.336265 Validation Accuracy: 0.506200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:   1.010482 Validation Accuracy: 0.511200\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:   1.231237 Validation Accuracy: 0.521800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:   1.300049 Validation Accuracy: 0.533200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:   1.216011 Validation Accuracy: 0.545600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:   1.166394 Validation Accuracy: 0.546200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:   0.914078 Validation Accuracy: 0.522000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:   1.132221 Validation Accuracy: 0.555400\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:   1.203538 Validation Accuracy: 0.551000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:   1.117556 Validation Accuracy: 0.557000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:   1.075425 Validation Accuracy: 0.552600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:   0.868679 Validation Accuracy: 0.533000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:   1.104095 Validation Accuracy: 0.569600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:   1.123829 Validation Accuracy: 0.577000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:   1.122098 Validation Accuracy: 0.554000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:   1.043710 Validation Accuracy: 0.560400\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:   0.788429 Validation Accuracy: 0.561800\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:   0.981625 Validation Accuracy: 0.581400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:   1.062575 Validation Accuracy: 0.583400\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:   1.003067 Validation Accuracy: 0.586800\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:   0.951231 Validation Accuracy: 0.577800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:   0.764467 Validation Accuracy: 0.557000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:   0.917527 Validation Accuracy: 0.588800\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:   0.954183 Validation Accuracy: 0.590800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:   0.898979 Validation Accuracy: 0.591600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:   0.918586 Validation Accuracy: 0.567800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:   0.681646 Validation Accuracy: 0.588200\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:   0.851200 Validation Accuracy: 0.594200\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:   0.962757 Validation Accuracy: 0.582400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:   0.856155 Validation Accuracy: 0.594200\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:   0.895993 Validation Accuracy: 0.581400\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:   0.642464 Validation Accuracy: 0.607000\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:   0.775417 Validation Accuracy: 0.599800\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:   0.899761 Validation Accuracy: 0.597600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:   0.788650 Validation Accuracy: 0.609200\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:   0.830931 Validation Accuracy: 0.578800\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:   0.576925 Validation Accuracy: 0.615400\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:   0.728021 Validation Accuracy: 0.610200\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:   0.782382 Validation Accuracy: 0.617000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:   0.736563 Validation Accuracy: 0.598400\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:   0.769161 Validation Accuracy: 0.600800\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:   0.572217 Validation Accuracy: 0.608800\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:   0.688006 Validation Accuracy: 0.617000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:   0.787366 Validation Accuracy: 0.617600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:   0.686197 Validation Accuracy: 0.610800\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:   0.761054 Validation Accuracy: 0.604400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:   0.540247 Validation Accuracy: 0.617800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:   0.658165 Validation Accuracy: 0.613600\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:   0.773975 Validation Accuracy: 0.611400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:   0.655786 Validation Accuracy: 0.595600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:   0.669865 Validation Accuracy: 0.625600\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:   0.528622 Validation Accuracy: 0.625000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:   0.598038 Validation Accuracy: 0.625200\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:   0.665909 Validation Accuracy: 0.639400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:   0.645968 Validation Accuracy: 0.621600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:   0.609569 Validation Accuracy: 0.627200\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:   0.452440 Validation Accuracy: 0.639000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:   0.577443 Validation Accuracy: 0.610200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:   0.640327 Validation Accuracy: 0.631600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:   0.560593 Validation Accuracy: 0.622800\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:   0.570036 Validation Accuracy: 0.630800\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:   0.476028 Validation Accuracy: 0.633200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:   0.540409 Validation Accuracy: 0.621400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:   0.601379 Validation Accuracy: 0.642000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:   0.521736 Validation Accuracy: 0.614200\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:   0.517347 Validation Accuracy: 0.636800\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:   0.420021 Validation Accuracy: 0.645200\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:   0.477205 Validation Accuracy: 0.631600\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:   0.605469 Validation Accuracy: 0.646000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:   0.475569 Validation Accuracy: 0.635600\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:   0.513784 Validation Accuracy: 0.644000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:   0.386926 Validation Accuracy: 0.651200\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:   0.486698 Validation Accuracy: 0.626200\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:   0.514552 Validation Accuracy: 0.647800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:   0.451394 Validation Accuracy: 0.641400\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:   0.508023 Validation Accuracy: 0.642200\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:   0.351349 Validation Accuracy: 0.649000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:   0.425331 Validation Accuracy: 0.637600\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:   0.519318 Validation Accuracy: 0.649000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:   0.427714 Validation Accuracy: 0.647000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:   0.489225 Validation Accuracy: 0.638200\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:   0.298287 Validation Accuracy: 0.647000\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:   0.436584 Validation Accuracy: 0.643000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:   0.496221 Validation Accuracy: 0.651200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:   0.398818 Validation Accuracy: 0.649400\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:   0.452618 Validation Accuracy: 0.648200\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:   0.353239 Validation Accuracy: 0.650200\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:   0.402026 Validation Accuracy: 0.644000\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:   0.442581 Validation Accuracy: 0.661400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:   0.408219 Validation Accuracy: 0.629600\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:   0.423974 Validation Accuracy: 0.651000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:   0.296452 Validation Accuracy: 0.648800\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:   0.367545 Validation Accuracy: 0.644000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:   0.470931 Validation Accuracy: 0.653800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:   0.380844 Validation Accuracy: 0.629200\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:   0.395600 Validation Accuracy: 0.662800\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:   0.314069 Validation Accuracy: 0.648600\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:   0.357795 Validation Accuracy: 0.644800\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:   0.407930 Validation Accuracy: 0.653800\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:   0.344632 Validation Accuracy: 0.640200\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:   0.422039 Validation Accuracy: 0.649400\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:   0.329461 Validation Accuracy: 0.648000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:   0.349149 Validation Accuracy: 0.654000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:   0.397927 Validation Accuracy: 0.654000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:   0.360272 Validation Accuracy: 0.634200\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:   0.423982 Validation Accuracy: 0.644400\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:   0.259358 Validation Accuracy: 0.641000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:   0.322150 Validation Accuracy: 0.656800\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:   0.378658 Validation Accuracy: 0.653200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:   0.393186 Validation Accuracy: 0.650000\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:   0.374262 Validation Accuracy: 0.644200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:   0.304009 Validation Accuracy: 0.629600\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:   0.313829 Validation Accuracy: 0.657000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:   0.356299 Validation Accuracy: 0.655400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:   0.317782 Validation Accuracy: 0.646000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:   0.350329 Validation Accuracy: 0.652600\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:   0.287562 Validation Accuracy: 0.651000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:   0.322732 Validation Accuracy: 0.653800\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:   0.341683 Validation Accuracy: 0.646200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:   0.336219 Validation Accuracy: 0.652400\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:   0.350351 Validation Accuracy: 0.652400\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:   0.282248 Validation Accuracy: 0.645200\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:   0.308965 Validation Accuracy: 0.657400\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:   0.311536 Validation Accuracy: 0.654400\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:   0.363033 Validation Accuracy: 0.648400\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:   0.362265 Validation Accuracy: 0.655000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:   0.246633 Validation Accuracy: 0.645800\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:   0.299498 Validation Accuracy: 0.662200\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:   0.312995 Validation Accuracy: 0.652600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:   0.308738 Validation Accuracy: 0.651800\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:   0.301599 Validation Accuracy: 0.666200\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:   0.242957 Validation Accuracy: 0.649200\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:   0.262356 Validation Accuracy: 0.670400\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:   0.284453 Validation Accuracy: 0.668200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:   0.299206 Validation Accuracy: 0.652200\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:   0.314482 Validation Accuracy: 0.663200\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:   0.231666 Validation Accuracy: 0.664200\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:   0.280135 Validation Accuracy: 0.667000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:   0.270137 Validation Accuracy: 0.659600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:   0.318592 Validation Accuracy: 0.657000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:   0.291330 Validation Accuracy: 0.664600\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:   0.214217 Validation Accuracy: 0.666400\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:   0.259391 Validation Accuracy: 0.669800\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:   0.248018 Validation Accuracy: 0.668800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:   0.293159 Validation Accuracy: 0.658200\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:   0.276979 Validation Accuracy: 0.664600\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:   0.205190 Validation Accuracy: 0.654800\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:   0.232493 Validation Accuracy: 0.672400\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:   0.248674 Validation Accuracy: 0.670800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:   0.302614 Validation Accuracy: 0.654400\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:   0.262599 Validation Accuracy: 0.674200\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:   0.196459 Validation Accuracy: 0.659200\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:   0.237556 Validation Accuracy: 0.664000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:   0.274099 Validation Accuracy: 0.658400\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:   0.254273 Validation Accuracy: 0.652200\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:   0.264761 Validation Accuracy: 0.668000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:   0.164854 Validation Accuracy: 0.651600\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:   0.220298 Validation Accuracy: 0.671600\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:   0.236129 Validation Accuracy: 0.676800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:   0.279857 Validation Accuracy: 0.650000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:   0.276543 Validation Accuracy: 0.660600\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:   0.174614 Validation Accuracy: 0.661600\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:   0.233545 Validation Accuracy: 0.672200\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:   0.222602 Validation Accuracy: 0.671000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:   0.245555 Validation Accuracy: 0.631200\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:   0.264419 Validation Accuracy: 0.665400\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:   0.158331 Validation Accuracy: 0.665000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:   0.263038 Validation Accuracy: 0.668200\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:   0.217419 Validation Accuracy: 0.664800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:   0.256577 Validation Accuracy: 0.643000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:   0.267559 Validation Accuracy: 0.669200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:   0.171898 Validation Accuracy: 0.648800\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:   0.230930 Validation Accuracy: 0.666000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:   0.193167 Validation Accuracy: 0.674800\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:   0.255964 Validation Accuracy: 0.649400\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:   0.257790 Validation Accuracy: 0.667000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:   0.173738 Validation Accuracy: 0.651400\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:   0.237273 Validation Accuracy: 0.658800\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:   0.202697 Validation Accuracy: 0.669000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:   0.218982 Validation Accuracy: 0.658400\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:   0.254258 Validation Accuracy: 0.675200\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:   0.163931 Validation Accuracy: 0.651800\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:   0.238050 Validation Accuracy: 0.661000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:   0.193780 Validation Accuracy: 0.661600\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:   0.198781 Validation Accuracy: 0.660800\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:   0.260111 Validation Accuracy: 0.671400\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:   0.159589 Validation Accuracy: 0.647600\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:   0.209041 Validation Accuracy: 0.666600\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:   0.197469 Validation Accuracy: 0.675000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:   0.216551 Validation Accuracy: 0.663800\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:   0.249745 Validation Accuracy: 0.669400\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:   0.127245 Validation Accuracy: 0.661200\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:   0.223760 Validation Accuracy: 0.660600\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:   0.179420 Validation Accuracy: 0.675600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:   0.200161 Validation Accuracy: 0.670600\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:   0.274688 Validation Accuracy: 0.663400\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:   0.136280 Validation Accuracy: 0.646800\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:   0.245793 Validation Accuracy: 0.655000\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:   0.213313 Validation Accuracy: 0.662000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:   0.238779 Validation Accuracy: 0.662000\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:   0.250899 Validation Accuracy: 0.663400\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:   0.151562 Validation Accuracy: 0.642200\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:   0.213794 Validation Accuracy: 0.668400\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:   0.171716 Validation Accuracy: 0.669800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:   0.196317 Validation Accuracy: 0.669800\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:   0.233437 Validation Accuracy: 0.673600\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:   0.141715 Validation Accuracy: 0.643200\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:   0.201031 Validation Accuracy: 0.661200\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:   0.171960 Validation Accuracy: 0.673200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:   0.189048 Validation Accuracy: 0.661200\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:   0.235756 Validation Accuracy: 0.670000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:   0.142644 Validation Accuracy: 0.660800\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:   0.214533 Validation Accuracy: 0.670600\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:   0.163734 Validation Accuracy: 0.661800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:   0.166013 Validation Accuracy: 0.670400\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:   0.259692 Validation Accuracy: 0.655200\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:   0.131052 Validation Accuracy: 0.656000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:   0.210686 Validation Accuracy: 0.670800\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:   0.167620 Validation Accuracy: 0.665600\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:   0.177086 Validation Accuracy: 0.668800\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:   0.224792 Validation Accuracy: 0.667000\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:   0.131462 Validation Accuracy: 0.644400\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:   0.189371 Validation Accuracy: 0.675200\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:   0.151509 Validation Accuracy: 0.670600\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:   0.193636 Validation Accuracy: 0.667600\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:   0.221101 Validation Accuracy: 0.657800\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:   0.111559 Validation Accuracy: 0.653000\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:   0.198224 Validation Accuracy: 0.664000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:   0.180645 Validation Accuracy: 0.653400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:   0.195148 Validation Accuracy: 0.666000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:   0.241641 Validation Accuracy: 0.649200\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:   0.123633 Validation Accuracy: 0.659800\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:   0.151230 Validation Accuracy: 0.667600\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:   0.149310 Validation Accuracy: 0.670600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:   0.168052 Validation Accuracy: 0.670000\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:   0.238581 Validation Accuracy: 0.651000\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:   0.130559 Validation Accuracy: 0.653600\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:   0.155892 Validation Accuracy: 0.664600\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:   0.157199 Validation Accuracy: 0.671200\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:   0.155478 Validation Accuracy: 0.672800\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:   0.212167 Validation Accuracy: 0.654400\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:   0.099590 Validation Accuracy: 0.665000\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:   0.147400 Validation Accuracy: 0.659000\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:   0.153487 Validation Accuracy: 0.670400\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:   0.175690 Validation Accuracy: 0.675000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:   0.213183 Validation Accuracy: 0.647000\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:   0.103152 Validation Accuracy: 0.665400\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:   0.141123 Validation Accuracy: 0.664400\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:   0.155663 Validation Accuracy: 0.673200\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:   0.190921 Validation Accuracy: 0.677600\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:   0.170779 Validation Accuracy: 0.657400\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:   0.098172 Validation Accuracy: 0.665200\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:   0.122653 Validation Accuracy: 0.659800\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:   0.138546 Validation Accuracy: 0.660000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:   0.203023 Validation Accuracy: 0.665000\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:   0.204671 Validation Accuracy: 0.648000\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:   0.098490 Validation Accuracy: 0.668400\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:   0.127236 Validation Accuracy: 0.672200\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:   0.153129 Validation Accuracy: 0.659200\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:   0.148423 Validation Accuracy: 0.676200\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:   0.163999 Validation Accuracy: 0.650200\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:   0.088297 Validation Accuracy: 0.666200\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:   0.141534 Validation Accuracy: 0.657200\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:   0.144324 Validation Accuracy: 0.671600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:   0.174882 Validation Accuracy: 0.673600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:   0.193378 Validation Accuracy: 0.647800\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:   0.089829 Validation Accuracy: 0.671800\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:   0.138722 Validation Accuracy: 0.665600\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:   0.123134 Validation Accuracy: 0.674600\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:   0.165838 Validation Accuracy: 0.669000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:   0.170740 Validation Accuracy: 0.657200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:   0.078539 Validation Accuracy: 0.666000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:   0.148195 Validation Accuracy: 0.669200\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:   0.150357 Validation Accuracy: 0.672200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:   0.141106 Validation Accuracy: 0.669000\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:   0.156242 Validation Accuracy: 0.654600\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:   0.095050 Validation Accuracy: 0.672600\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:   0.100804 Validation Accuracy: 0.666600\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:   0.132673 Validation Accuracy: 0.667400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:   0.157765 Validation Accuracy: 0.671000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:   0.145726 Validation Accuracy: 0.656200\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:   0.081672 Validation Accuracy: 0.669400\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:   0.131535 Validation Accuracy: 0.661200\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:   0.146354 Validation Accuracy: 0.665000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:   0.148310 Validation Accuracy: 0.670600\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:   0.167081 Validation Accuracy: 0.661600\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:   0.069508 Validation Accuracy: 0.664000\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:   0.102312 Validation Accuracy: 0.670600\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:   0.118982 Validation Accuracy: 0.673600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:   0.146435 Validation Accuracy: 0.668200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:   0.163276 Validation Accuracy: 0.645800\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:   0.078398 Validation Accuracy: 0.667000\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:   0.092010 Validation Accuracy: 0.666800\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:   0.132096 Validation Accuracy: 0.666800\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:   0.151685 Validation Accuracy: 0.668400\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:   0.166640 Validation Accuracy: 0.649600\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:   0.067590 Validation Accuracy: 0.661400\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:   0.106492 Validation Accuracy: 0.664400\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:   0.120386 Validation Accuracy: 0.665000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:   0.151109 Validation Accuracy: 0.672200\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:   0.173249 Validation Accuracy: 0.644800\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:   0.071910 Validation Accuracy: 0.669000\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:   0.113433 Validation Accuracy: 0.665000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:   0.127604 Validation Accuracy: 0.662000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:   0.143626 Validation Accuracy: 0.668600\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:   0.153140 Validation Accuracy: 0.653600\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:   0.054706 Validation Accuracy: 0.666600\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:   0.090109 Validation Accuracy: 0.658000\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:   0.120875 Validation Accuracy: 0.671400\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:   0.132969 Validation Accuracy: 0.671800\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:   0.130412 Validation Accuracy: 0.661000\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:   0.058794 Validation Accuracy: 0.665200\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:   0.083209 Validation Accuracy: 0.666400\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:   0.103077 Validation Accuracy: 0.677200\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:   0.147996 Validation Accuracy: 0.668600\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:   0.171244 Validation Accuracy: 0.655000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:   0.056084 Validation Accuracy: 0.666800\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:   0.081961 Validation Accuracy: 0.664200\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:   0.111976 Validation Accuracy: 0.662000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:   0.123469 Validation Accuracy: 0.664800\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:   0.146656 Validation Accuracy: 0.659000\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:   0.076104 Validation Accuracy: 0.664800\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:   0.089285 Validation Accuracy: 0.655400\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:   0.112684 Validation Accuracy: 0.671000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:   0.118030 Validation Accuracy: 0.661200\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:   0.126901 Validation Accuracy: 0.663400\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:   0.074891 Validation Accuracy: 0.671800\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:   0.093238 Validation Accuracy: 0.656600\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:   0.118787 Validation Accuracy: 0.668000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:   0.117865 Validation Accuracy: 0.670800\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:   0.131987 Validation Accuracy: 0.658400\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:   0.064546 Validation Accuracy: 0.655200\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:   0.086042 Validation Accuracy: 0.665800\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:   0.103702 Validation Accuracy: 0.668200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:   0.116007 Validation Accuracy: 0.670400\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:   0.129164 Validation Accuracy: 0.669400\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:   0.069552 Validation Accuracy: 0.659800\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:   0.090663 Validation Accuracy: 0.662400\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:   0.093775 Validation Accuracy: 0.668400\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:   0.114144 Validation Accuracy: 0.674000\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:   0.120796 Validation Accuracy: 0.657000\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:   0.075448 Validation Accuracy: 0.661800\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:   0.086832 Validation Accuracy: 0.662000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:   0.099675 Validation Accuracy: 0.670800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:   0.099998 Validation Accuracy: 0.671200\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:   0.118731 Validation Accuracy: 0.656400\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:   0.093222 Validation Accuracy: 0.653400\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:   0.066210 Validation Accuracy: 0.661800\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:   0.096925 Validation Accuracy: 0.668600\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:   0.118521 Validation Accuracy: 0.672800\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:   0.125496 Validation Accuracy: 0.653000\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:   0.069262 Validation Accuracy: 0.659400\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:   0.070704 Validation Accuracy: 0.669400\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:   0.100825 Validation Accuracy: 0.674600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:   0.110706 Validation Accuracy: 0.669400\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:   0.129409 Validation Accuracy: 0.654200\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:   0.066748 Validation Accuracy: 0.658400\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:   0.086730 Validation Accuracy: 0.669800\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:   0.098612 Validation Accuracy: 0.676800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:   0.121497 Validation Accuracy: 0.666200\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:   0.120238 Validation Accuracy: 0.662800\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:   0.097189 Validation Accuracy: 0.654200\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:   0.078891 Validation Accuracy: 0.659800\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:   0.112307 Validation Accuracy: 0.667800\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:   0.108968 Validation Accuracy: 0.670000\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:   0.110336 Validation Accuracy: 0.654200\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:   0.082981 Validation Accuracy: 0.659600\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:   0.072546 Validation Accuracy: 0.663200\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:   0.106032 Validation Accuracy: 0.668000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:   0.135159 Validation Accuracy: 0.662200\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:   0.111276 Validation Accuracy: 0.657400\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:   0.078926 Validation Accuracy: 0.660200\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:   0.054820 Validation Accuracy: 0.654600\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:   0.095196 Validation Accuracy: 0.676800\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:   0.113015 Validation Accuracy: 0.668800\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:   0.103783 Validation Accuracy: 0.652800\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:   0.106110 Validation Accuracy: 0.659600\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:   0.104202 Validation Accuracy: 0.645800\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:   0.108422 Validation Accuracy: 0.667800\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:   0.106759 Validation Accuracy: 0.667200\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:   0.105549 Validation Accuracy: 0.648400\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:   0.070808 Validation Accuracy: 0.653800\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:   0.101445 Validation Accuracy: 0.654200\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:   0.114638 Validation Accuracy: 0.667000\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:   0.132308 Validation Accuracy: 0.662000\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:   0.119769 Validation Accuracy: 0.655400\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:   0.054027 Validation Accuracy: 0.665800\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:   0.082929 Validation Accuracy: 0.652400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:   0.108413 Validation Accuracy: 0.674000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:   0.104105 Validation Accuracy: 0.665000\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:   0.127022 Validation Accuracy: 0.633600\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:   0.070479 Validation Accuracy: 0.676000\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:   0.088789 Validation Accuracy: 0.659800\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:   0.102318 Validation Accuracy: 0.672400\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:   0.144307 Validation Accuracy: 0.652600\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:   0.103273 Validation Accuracy: 0.654400\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:   0.068760 Validation Accuracy: 0.652600\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:   0.111451 Validation Accuracy: 0.659600\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:   0.120577 Validation Accuracy: 0.657200\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:   0.124919 Validation Accuracy: 0.646400\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:   0.119571 Validation Accuracy: 0.645200\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:   0.065981 Validation Accuracy: 0.655600\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:   0.083770 Validation Accuracy: 0.646600\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:   0.130091 Validation Accuracy: 0.657600\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:   0.118824 Validation Accuracy: 0.647600\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:   0.105636 Validation Accuracy: 0.650400\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:   0.056641 Validation Accuracy: 0.660200\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:   0.074697 Validation Accuracy: 0.657600\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:   0.121732 Validation Accuracy: 0.671200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:   0.109841 Validation Accuracy: 0.639000\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:   0.111449 Validation Accuracy: 0.647600\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:   0.045167 Validation Accuracy: 0.664000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:   0.082671 Validation Accuracy: 0.648800\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:   0.106343 Validation Accuracy: 0.672400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:   0.096172 Validation Accuracy: 0.656200\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:   0.120677 Validation Accuracy: 0.664600\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:   0.049014 Validation Accuracy: 0.657000\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:   0.078442 Validation Accuracy: 0.651600\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:   0.096257 Validation Accuracy: 0.672000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:   0.107710 Validation Accuracy: 0.648800\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:   0.106521 Validation Accuracy: 0.653000\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:   0.047395 Validation Accuracy: 0.666000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:   0.064691 Validation Accuracy: 0.653800\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:   0.098984 Validation Accuracy: 0.660400\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:   0.125187 Validation Accuracy: 0.647000\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:   0.095113 Validation Accuracy: 0.661400\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:   0.052241 Validation Accuracy: 0.664600\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:   0.062732 Validation Accuracy: 0.647200\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:   0.102881 Validation Accuracy: 0.666600\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:   0.141090 Validation Accuracy: 0.633800\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:   0.082118 Validation Accuracy: 0.660000\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:   0.039725 Validation Accuracy: 0.669200\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:   0.069324 Validation Accuracy: 0.659400\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:   0.088101 Validation Accuracy: 0.664200\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:   0.100150 Validation Accuracy: 0.645000\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:   0.097568 Validation Accuracy: 0.663000\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:   0.046684 Validation Accuracy: 0.663600\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:   0.052065 Validation Accuracy: 0.657400\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:   0.088539 Validation Accuracy: 0.661800\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:   0.093463 Validation Accuracy: 0.663400\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:   0.094712 Validation Accuracy: 0.661800\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:   0.039133 Validation Accuracy: 0.661000\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:   0.040098 Validation Accuracy: 0.653200\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:   0.089288 Validation Accuracy: 0.661800\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:   0.112946 Validation Accuracy: 0.658000\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:   0.084292 Validation Accuracy: 0.657400\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:   0.045436 Validation Accuracy: 0.660400\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:   0.048944 Validation Accuracy: 0.655200\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:   0.099316 Validation Accuracy: 0.655400\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:   0.106276 Validation Accuracy: 0.652200\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:   0.098849 Validation Accuracy: 0.662600\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:   0.038974 Validation Accuracy: 0.660200\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:   0.051095 Validation Accuracy: 0.647200\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:   0.081118 Validation Accuracy: 0.662000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:   0.128756 Validation Accuracy: 0.648600\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:   0.125755 Validation Accuracy: 0.654600\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:   0.037300 Validation Accuracy: 0.658400\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:   0.064047 Validation Accuracy: 0.650200\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:   0.088875 Validation Accuracy: 0.651000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:   0.101358 Validation Accuracy: 0.647600\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:   0.090245 Validation Accuracy: 0.669600\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:   0.029868 Validation Accuracy: 0.660600\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:   0.046797 Validation Accuracy: 0.647200\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:   0.086956 Validation Accuracy: 0.653000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:   0.089772 Validation Accuracy: 0.650200\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:   0.115270 Validation Accuracy: 0.650600\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:   0.045190 Validation Accuracy: 0.659000\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:   0.041689 Validation Accuracy: 0.652400\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:   0.082364 Validation Accuracy: 0.654600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:   0.100155 Validation Accuracy: 0.656400\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:   0.103719 Validation Accuracy: 0.651600\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:   0.035496 Validation Accuracy: 0.663000\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:   0.041970 Validation Accuracy: 0.648600\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:   0.092272 Validation Accuracy: 0.637600\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:   0.105366 Validation Accuracy: 0.653600\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:   0.102687 Validation Accuracy: 0.653400\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:   0.047426 Validation Accuracy: 0.659200\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:   0.058867 Validation Accuracy: 0.642600\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:   0.089755 Validation Accuracy: 0.648600\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:   0.102338 Validation Accuracy: 0.654200\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:   0.094329 Validation Accuracy: 0.651200\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:   0.035544 Validation Accuracy: 0.664000\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:   0.052965 Validation Accuracy: 0.655000\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:   0.073518 Validation Accuracy: 0.660800\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:   0.098526 Validation Accuracy: 0.657800\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:   0.083245 Validation Accuracy: 0.647000\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:   0.040808 Validation Accuracy: 0.660600\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:   0.048292 Validation Accuracy: 0.630200\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:   0.072450 Validation Accuracy: 0.644200\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:   0.096179 Validation Accuracy: 0.653400\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:   0.087728 Validation Accuracy: 0.658200\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:   0.026966 Validation Accuracy: 0.663200\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:   0.047010 Validation Accuracy: 0.636400\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:   0.072775 Validation Accuracy: 0.657600\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:   0.093955 Validation Accuracy: 0.654400\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:   0.097178 Validation Accuracy: 0.664000\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:   0.027292 Validation Accuracy: 0.661000\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:   0.065217 Validation Accuracy: 0.641000\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:   0.081773 Validation Accuracy: 0.652800\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:   0.095192 Validation Accuracy: 0.654000\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:   0.091757 Validation Accuracy: 0.657400\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:   0.027823 Validation Accuracy: 0.662400\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:   0.057577 Validation Accuracy: 0.638400\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:   0.069022 Validation Accuracy: 0.655800\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:   0.105633 Validation Accuracy: 0.645600\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:   0.094236 Validation Accuracy: 0.655000\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:   0.031686 Validation Accuracy: 0.660800\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:   0.045514 Validation Accuracy: 0.645400\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:   0.071403 Validation Accuracy: 0.646400\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:   0.101967 Validation Accuracy: 0.650000\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:   0.109082 Validation Accuracy: 0.655000\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:   0.034263 Validation Accuracy: 0.657400\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:   0.059722 Validation Accuracy: 0.649400\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:   0.078786 Validation Accuracy: 0.656600\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:   0.115726 Validation Accuracy: 0.646800\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:   0.105959 Validation Accuracy: 0.661400\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:   0.032169 Validation Accuracy: 0.658800\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:   0.029521 Validation Accuracy: 0.652200\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:   0.082255 Validation Accuracy: 0.656800\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:   0.120255 Validation Accuracy: 0.661000\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:   0.088707 Validation Accuracy: 0.658200\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:   0.040562 Validation Accuracy: 0.657200\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:   0.026283 Validation Accuracy: 0.658200\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:   0.063923 Validation Accuracy: 0.655200\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:   0.100465 Validation Accuracy: 0.652800\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:   0.103868 Validation Accuracy: 0.654800\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:   0.035085 Validation Accuracy: 0.657600\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:   0.029775 Validation Accuracy: 0.660800\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:   0.062782 Validation Accuracy: 0.655200\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:   0.090086 Validation Accuracy: 0.667600\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:   0.072029 Validation Accuracy: 0.661400\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:   0.034009 Validation Accuracy: 0.660000\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:   0.030106 Validation Accuracy: 0.665200\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:   0.069997 Validation Accuracy: 0.651200\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:   0.085359 Validation Accuracy: 0.658200\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:   0.075523 Validation Accuracy: 0.660600\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:   0.039591 Validation Accuracy: 0.662800\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:   0.025481 Validation Accuracy: 0.664800\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:   0.072742 Validation Accuracy: 0.656800\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:   0.087720 Validation Accuracy: 0.657800\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:   0.079353 Validation Accuracy: 0.662400\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:   0.026109 Validation Accuracy: 0.661200\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:   0.025640 Validation Accuracy: 0.663200\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:   0.069443 Validation Accuracy: 0.658600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:   0.073953 Validation Accuracy: 0.667400\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:   0.090203 Validation Accuracy: 0.658000\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:   0.033303 Validation Accuracy: 0.659200\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:   0.032837 Validation Accuracy: 0.654000\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:   0.062267 Validation Accuracy: 0.655400\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:   0.074905 Validation Accuracy: 0.650400\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:   0.075108 Validation Accuracy: 0.659600\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:   0.032709 Validation Accuracy: 0.659200\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:   0.030962 Validation Accuracy: 0.664200\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:   0.076821 Validation Accuracy: 0.655400\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:   0.077887 Validation Accuracy: 0.663400\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:   0.084846 Validation Accuracy: 0.653400\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:   0.026294 Validation Accuracy: 0.664800\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:   0.029373 Validation Accuracy: 0.657600\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:   0.076833 Validation Accuracy: 0.646000\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:   0.080910 Validation Accuracy: 0.653800\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:   0.103927 Validation Accuracy: 0.646400\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:   0.032944 Validation Accuracy: 0.669000\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:   0.029856 Validation Accuracy: 0.661200\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:   0.074003 Validation Accuracy: 0.644600\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:   0.074992 Validation Accuracy: 0.653600\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:   0.080306 Validation Accuracy: 0.655400\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:   0.027050 Validation Accuracy: 0.654800\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:   0.038244 Validation Accuracy: 0.658000\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:   0.058552 Validation Accuracy: 0.656600\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:   0.094868 Validation Accuracy: 0.656000\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:   0.080973 Validation Accuracy: 0.657600\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:   0.027185 Validation Accuracy: 0.663600\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:   0.023196 Validation Accuracy: 0.666600\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:   0.077737 Validation Accuracy: 0.655800\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:   0.064517 Validation Accuracy: 0.659800\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:   0.078515 Validation Accuracy: 0.654000\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:   0.032271 Validation Accuracy: 0.660800\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:   0.034075 Validation Accuracy: 0.660000\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:   0.065216 Validation Accuracy: 0.649200\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:   0.072245 Validation Accuracy: 0.654600\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:   0.073504 Validation Accuracy: 0.656600\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:   0.028250 Validation Accuracy: 0.658400\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:   0.048430 Validation Accuracy: 0.652400\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:   0.060921 Validation Accuracy: 0.654000\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:   0.081355 Validation Accuracy: 0.655800\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:   0.076993 Validation Accuracy: 0.663600\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:   0.029175 Validation Accuracy: 0.666200\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:   0.025924 Validation Accuracy: 0.665200\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:   0.059092 Validation Accuracy: 0.657600\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:   0.099319 Validation Accuracy: 0.660600\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:   0.070288 Validation Accuracy: 0.654000\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:   0.025893 Validation Accuracy: 0.655800\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:   0.024183 Validation Accuracy: 0.664800\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:   0.060221 Validation Accuracy: 0.662200\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:   0.093900 Validation Accuracy: 0.657200\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:   0.090645 Validation Accuracy: 0.663200\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:   0.028592 Validation Accuracy: 0.667400\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:   0.029346 Validation Accuracy: 0.665000\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:   0.057187 Validation Accuracy: 0.652000\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:   0.076348 Validation Accuracy: 0.650600\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:   0.067603 Validation Accuracy: 0.660800\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:   0.040874 Validation Accuracy: 0.654000\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:   0.027859 Validation Accuracy: 0.662800\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:   0.059075 Validation Accuracy: 0.657800\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:   0.090277 Validation Accuracy: 0.654600\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:   0.063415 Validation Accuracy: 0.662800\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:   0.018499 Validation Accuracy: 0.665200\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:   0.028909 Validation Accuracy: 0.663000\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:   0.067439 Validation Accuracy: 0.652000\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:   0.113783 Validation Accuracy: 0.648600\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:   0.064902 Validation Accuracy: 0.664400\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:   0.026298 Validation Accuracy: 0.661600\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:   0.016749 Validation Accuracy: 0.666400\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:   0.052252 Validation Accuracy: 0.661600\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:   0.095786 Validation Accuracy: 0.653600\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:   0.071157 Validation Accuracy: 0.658800\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:   0.014491 Validation Accuracy: 0.664400\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:   0.029336 Validation Accuracy: 0.657600\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:   0.052200 Validation Accuracy: 0.659200\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:   0.073954 Validation Accuracy: 0.655200\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:   0.069959 Validation Accuracy: 0.670000\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:   0.021235 Validation Accuracy: 0.664200\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:   0.024987 Validation Accuracy: 0.662600\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:   0.055093 Validation Accuracy: 0.653800\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:   0.071843 Validation Accuracy: 0.651400\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:   0.069017 Validation Accuracy: 0.660800\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:   0.026099 Validation Accuracy: 0.660200\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:   0.018531 Validation Accuracy: 0.657200\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:   0.049527 Validation Accuracy: 0.659400\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:   0.087939 Validation Accuracy: 0.651800\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss:   0.072181 Validation Accuracy: 0.651200\n",
      "Epoch 130, CIFAR-10 Batch 3:  Loss:   0.024098 Validation Accuracy: 0.661400\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:   0.022670 Validation Accuracy: 0.652200\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:   0.052451 Validation Accuracy: 0.662400\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:   0.074482 Validation Accuracy: 0.666200\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:   0.064644 Validation Accuracy: 0.647600\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:   0.030306 Validation Accuracy: 0.664200\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:   0.017288 Validation Accuracy: 0.654400\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:   0.045525 Validation Accuracy: 0.655200\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:   0.092800 Validation Accuracy: 0.641400\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:   0.075511 Validation Accuracy: 0.652800\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:   0.023016 Validation Accuracy: 0.662800\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:   0.015901 Validation Accuracy: 0.659800\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:   0.045232 Validation Accuracy: 0.656800\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:   0.056930 Validation Accuracy: 0.655600\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:   0.062347 Validation Accuracy: 0.648000\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:   0.017919 Validation Accuracy: 0.665400\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:   0.018250 Validation Accuracy: 0.660000\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:   0.057958 Validation Accuracy: 0.660200\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:   0.078274 Validation Accuracy: 0.646000\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:   0.066611 Validation Accuracy: 0.651600\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:   0.015698 Validation Accuracy: 0.658000\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:   0.019355 Validation Accuracy: 0.654800\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:   0.047933 Validation Accuracy: 0.659200\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:   0.080414 Validation Accuracy: 0.649800\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:   0.063102 Validation Accuracy: 0.645600\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:   0.018568 Validation Accuracy: 0.660000\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:   0.014574 Validation Accuracy: 0.658400\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:   0.058636 Validation Accuracy: 0.652000\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:   0.070494 Validation Accuracy: 0.659400\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:   0.069414 Validation Accuracy: 0.647800\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:   0.021469 Validation Accuracy: 0.663600\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:   0.015363 Validation Accuracy: 0.656400\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:   0.054983 Validation Accuracy: 0.653800\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:   0.080538 Validation Accuracy: 0.650400\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:   0.068099 Validation Accuracy: 0.657200\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:   0.019246 Validation Accuracy: 0.663000\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:   0.022563 Validation Accuracy: 0.657000\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:   0.043263 Validation Accuracy: 0.655800\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:   0.057446 Validation Accuracy: 0.646400\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:   0.055839 Validation Accuracy: 0.645400\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:   0.020317 Validation Accuracy: 0.662800\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:   0.024891 Validation Accuracy: 0.659000\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:   0.049643 Validation Accuracy: 0.651600\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:   0.062023 Validation Accuracy: 0.649600\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:   0.052963 Validation Accuracy: 0.658200\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:   0.022754 Validation Accuracy: 0.661800\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:   0.022388 Validation Accuracy: 0.657200\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:   0.058484 Validation Accuracy: 0.651400\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:   0.075043 Validation Accuracy: 0.650000\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:   0.044613 Validation Accuracy: 0.654000\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:   0.020466 Validation Accuracy: 0.666800\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:   0.011004 Validation Accuracy: 0.657600\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:   0.040885 Validation Accuracy: 0.655600\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:   0.051170 Validation Accuracy: 0.651000\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:   0.062495 Validation Accuracy: 0.658400\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:   0.022041 Validation Accuracy: 0.662800\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:   0.019834 Validation Accuracy: 0.654800\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:   0.040988 Validation Accuracy: 0.649000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:   0.073767 Validation Accuracy: 0.650000\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:   0.038330 Validation Accuracy: 0.661400\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:   0.025175 Validation Accuracy: 0.662000\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:   0.016223 Validation Accuracy: 0.661200\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:   0.044017 Validation Accuracy: 0.642800\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:   0.071262 Validation Accuracy: 0.640800\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:   0.064952 Validation Accuracy: 0.651600\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:   0.027788 Validation Accuracy: 0.661600\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:   0.025673 Validation Accuracy: 0.659600\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:   0.035564 Validation Accuracy: 0.645600\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:   0.067648 Validation Accuracy: 0.652200\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:   0.051813 Validation Accuracy: 0.656800\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:   0.027340 Validation Accuracy: 0.662200\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:   0.018310 Validation Accuracy: 0.655400\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:   0.046952 Validation Accuracy: 0.643200\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:   0.050317 Validation Accuracy: 0.645400\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:   0.043596 Validation Accuracy: 0.652000\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:   0.022955 Validation Accuracy: 0.658000\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:   0.018866 Validation Accuracy: 0.658800\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:   0.049028 Validation Accuracy: 0.656800\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:   0.063267 Validation Accuracy: 0.639000\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:   0.054896 Validation Accuracy: 0.652800\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:   0.029326 Validation Accuracy: 0.650800\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:   0.023650 Validation Accuracy: 0.656000\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:   0.047829 Validation Accuracy: 0.651800\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:   0.072083 Validation Accuracy: 0.645400\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:   0.056827 Validation Accuracy: 0.646200\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:   0.032389 Validation Accuracy: 0.652600\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:   0.028960 Validation Accuracy: 0.654200\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:   0.039099 Validation Accuracy: 0.649000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:   0.061089 Validation Accuracy: 0.632000\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:   0.057641 Validation Accuracy: 0.651200\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:   0.017652 Validation Accuracy: 0.661200\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:   0.021190 Validation Accuracy: 0.655400\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:   0.049910 Validation Accuracy: 0.649000\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:   0.074971 Validation Accuracy: 0.638200\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:   0.042663 Validation Accuracy: 0.642400\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:   0.028241 Validation Accuracy: 0.653600\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:   0.025521 Validation Accuracy: 0.656400\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:   0.060108 Validation Accuracy: 0.647600\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:   0.062639 Validation Accuracy: 0.635400\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:   0.046254 Validation Accuracy: 0.659400\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:   0.030107 Validation Accuracy: 0.657400\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:   0.035513 Validation Accuracy: 0.650800\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:   0.041816 Validation Accuracy: 0.663600\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:   0.092649 Validation Accuracy: 0.632000\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:   0.044955 Validation Accuracy: 0.648800\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:   0.026023 Validation Accuracy: 0.653400\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss:   0.025868 Validation Accuracy: 0.651800\n",
      "Epoch 151, CIFAR-10 Batch 5:  Loss:   0.053188 Validation Accuracy: 0.656800\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:   0.073931 Validation Accuracy: 0.628000\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:   0.056871 Validation Accuracy: 0.654400\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:   0.019414 Validation Accuracy: 0.643400\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:   0.023807 Validation Accuracy: 0.652200\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:   0.039500 Validation Accuracy: 0.658000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:   0.083732 Validation Accuracy: 0.640400\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:   0.042919 Validation Accuracy: 0.647000\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:   0.014610 Validation Accuracy: 0.649400\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:   0.031481 Validation Accuracy: 0.655000\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:   0.052155 Validation Accuracy: 0.653800\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:   0.054541 Validation Accuracy: 0.646200\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:   0.033211 Validation Accuracy: 0.648000\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:   0.019817 Validation Accuracy: 0.647000\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:   0.025995 Validation Accuracy: 0.656600\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:   0.036436 Validation Accuracy: 0.663200\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:   0.060777 Validation Accuracy: 0.638400\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:   0.039441 Validation Accuracy: 0.661600\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:   0.022638 Validation Accuracy: 0.645600\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:   0.035348 Validation Accuracy: 0.654800\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:   0.045202 Validation Accuracy: 0.655000\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:   0.056981 Validation Accuracy: 0.632800\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:   0.037458 Validation Accuracy: 0.650400\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:   0.021951 Validation Accuracy: 0.652200\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:   0.028809 Validation Accuracy: 0.658000\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:   0.052223 Validation Accuracy: 0.651200\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:   0.073509 Validation Accuracy: 0.638600\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:   0.035189 Validation Accuracy: 0.654000\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:   0.018470 Validation Accuracy: 0.655200\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:   0.037165 Validation Accuracy: 0.658000\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:   0.035851 Validation Accuracy: 0.661000\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:   0.053131 Validation Accuracy: 0.641400\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:   0.051482 Validation Accuracy: 0.659200\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:   0.024521 Validation Accuracy: 0.650200\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:   0.025764 Validation Accuracy: 0.651000\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:   0.039103 Validation Accuracy: 0.652400\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:   0.055869 Validation Accuracy: 0.637400\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:   0.050443 Validation Accuracy: 0.655000\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:   0.022158 Validation Accuracy: 0.651800\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:   0.026913 Validation Accuracy: 0.649800\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:   0.040559 Validation Accuracy: 0.658800\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:   0.051705 Validation Accuracy: 0.642600\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:   0.037736 Validation Accuracy: 0.648800\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:   0.017729 Validation Accuracy: 0.655200\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:   0.023811 Validation Accuracy: 0.655000\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:   0.044361 Validation Accuracy: 0.653600\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:   0.065707 Validation Accuracy: 0.639400\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:   0.039773 Validation Accuracy: 0.652800\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:   0.032299 Validation Accuracy: 0.646000\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:   0.019169 Validation Accuracy: 0.654200\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:   0.026948 Validation Accuracy: 0.657800\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:   0.068766 Validation Accuracy: 0.651200\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:   0.031093 Validation Accuracy: 0.658600\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:   0.029588 Validation Accuracy: 0.639000\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:   0.019268 Validation Accuracy: 0.655000\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:   0.025224 Validation Accuracy: 0.661600\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:   0.050336 Validation Accuracy: 0.638400\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:   0.035725 Validation Accuracy: 0.658400\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:   0.015769 Validation Accuracy: 0.645600\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:   0.022645 Validation Accuracy: 0.654400\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:   0.038639 Validation Accuracy: 0.656800\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:   0.062333 Validation Accuracy: 0.651600\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:   0.035752 Validation Accuracy: 0.662000\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:   0.020481 Validation Accuracy: 0.651000\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:   0.016756 Validation Accuracy: 0.652000\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:   0.035885 Validation Accuracy: 0.658200\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:   0.080369 Validation Accuracy: 0.649000\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:   0.049044 Validation Accuracy: 0.650200\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:   0.036586 Validation Accuracy: 0.646800\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:   0.020335 Validation Accuracy: 0.650200\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:   0.031107 Validation Accuracy: 0.656600\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:   0.064637 Validation Accuracy: 0.655000\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:   0.024629 Validation Accuracy: 0.653200\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:   0.024948 Validation Accuracy: 0.648400\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:   0.023893 Validation Accuracy: 0.650000\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:   0.034181 Validation Accuracy: 0.655200\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:   0.055872 Validation Accuracy: 0.653000\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:   0.056121 Validation Accuracy: 0.655400\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:   0.018176 Validation Accuracy: 0.644000\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:   0.021236 Validation Accuracy: 0.644200\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:   0.032522 Validation Accuracy: 0.652600\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:   0.042425 Validation Accuracy: 0.646400\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:   0.042054 Validation Accuracy: 0.657200\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:   0.016873 Validation Accuracy: 0.650000\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:   0.018068 Validation Accuracy: 0.649000\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:   0.031875 Validation Accuracy: 0.651400\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:   0.057980 Validation Accuracy: 0.656200\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:   0.045459 Validation Accuracy: 0.650600\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:   0.020125 Validation Accuracy: 0.656400\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:   0.028080 Validation Accuracy: 0.651400\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:   0.025472 Validation Accuracy: 0.655000\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:   0.057818 Validation Accuracy: 0.649200\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:   0.053766 Validation Accuracy: 0.650000\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:   0.013716 Validation Accuracy: 0.659600\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:   0.019261 Validation Accuracy: 0.644400\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:   0.018419 Validation Accuracy: 0.657600\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:   0.050225 Validation Accuracy: 0.652800\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:   0.040017 Validation Accuracy: 0.656200\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:   0.013725 Validation Accuracy: 0.649600\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:   0.025300 Validation Accuracy: 0.645800\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:   0.029782 Validation Accuracy: 0.656800\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:   0.058322 Validation Accuracy: 0.650600\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:   0.042475 Validation Accuracy: 0.648200\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:   0.020364 Validation Accuracy: 0.651200\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:   0.027898 Validation Accuracy: 0.650000\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:   0.030589 Validation Accuracy: 0.657200\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:   0.049455 Validation Accuracy: 0.648600\n",
      "Epoch 173, CIFAR-10 Batch 2:  Loss:   0.048908 Validation Accuracy: 0.648800\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:   0.020068 Validation Accuracy: 0.648400\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:   0.027561 Validation Accuracy: 0.645600\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:   0.036989 Validation Accuracy: 0.653000\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:   0.056353 Validation Accuracy: 0.651000\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:   0.037075 Validation Accuracy: 0.657400\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:   0.009487 Validation Accuracy: 0.648200\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:   0.021997 Validation Accuracy: 0.643000\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:   0.028954 Validation Accuracy: 0.656800\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:   0.050984 Validation Accuracy: 0.646000\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:   0.034188 Validation Accuracy: 0.657200\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:   0.011065 Validation Accuracy: 0.660000\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:   0.020216 Validation Accuracy: 0.647200\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:   0.022561 Validation Accuracy: 0.660800\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:   0.051888 Validation Accuracy: 0.657400\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:   0.040916 Validation Accuracy: 0.658200\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:   0.015934 Validation Accuracy: 0.653800\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:   0.024649 Validation Accuracy: 0.644400\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:   0.026495 Validation Accuracy: 0.653800\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:   0.054121 Validation Accuracy: 0.656200\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:   0.043385 Validation Accuracy: 0.650800\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:   0.013418 Validation Accuracy: 0.656400\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:   0.022061 Validation Accuracy: 0.649000\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:   0.022714 Validation Accuracy: 0.652400\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:   0.045991 Validation Accuracy: 0.648600\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:   0.046499 Validation Accuracy: 0.652600\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:   0.015610 Validation Accuracy: 0.664200\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:   0.031421 Validation Accuracy: 0.645400\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:   0.024262 Validation Accuracy: 0.653800\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:   0.055468 Validation Accuracy: 0.644400\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:   0.051822 Validation Accuracy: 0.651600\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:   0.013512 Validation Accuracy: 0.658200\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:   0.029126 Validation Accuracy: 0.645600\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:   0.019194 Validation Accuracy: 0.657400\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:   0.044482 Validation Accuracy: 0.646400\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:   0.041435 Validation Accuracy: 0.656200\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:   0.013527 Validation Accuracy: 0.653000\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:   0.024916 Validation Accuracy: 0.645200\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:   0.025304 Validation Accuracy: 0.659600\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:   0.048604 Validation Accuracy: 0.643800\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:   0.056934 Validation Accuracy: 0.648800\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:   0.012760 Validation Accuracy: 0.658800\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:   0.023469 Validation Accuracy: 0.645200\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:   0.016914 Validation Accuracy: 0.654600\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:   0.043492 Validation Accuracy: 0.651200\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:   0.032702 Validation Accuracy: 0.646600\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:   0.010552 Validation Accuracy: 0.655600\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:   0.026000 Validation Accuracy: 0.641000\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:   0.027467 Validation Accuracy: 0.653800\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:   0.035647 Validation Accuracy: 0.647800\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:   0.037407 Validation Accuracy: 0.649400\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:   0.020416 Validation Accuracy: 0.656200\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:   0.049085 Validation Accuracy: 0.645800\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:   0.026019 Validation Accuracy: 0.656400\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:   0.059929 Validation Accuracy: 0.646000\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:   0.040093 Validation Accuracy: 0.638600\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:   0.018797 Validation Accuracy: 0.651000\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:   0.023256 Validation Accuracy: 0.649000\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:   0.032181 Validation Accuracy: 0.650400\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:   0.052835 Validation Accuracy: 0.647200\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:   0.040209 Validation Accuracy: 0.638400\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:   0.008109 Validation Accuracy: 0.658800\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:   0.023419 Validation Accuracy: 0.650400\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:   0.028311 Validation Accuracy: 0.655400\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:   0.049102 Validation Accuracy: 0.641600\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:   0.038834 Validation Accuracy: 0.640400\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:   0.010608 Validation Accuracy: 0.651800\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:   0.033149 Validation Accuracy: 0.649200\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:   0.030129 Validation Accuracy: 0.650200\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:   0.041281 Validation Accuracy: 0.644000\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:   0.037471 Validation Accuracy: 0.636400\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:   0.005976 Validation Accuracy: 0.652600\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:   0.028598 Validation Accuracy: 0.654000\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:   0.031372 Validation Accuracy: 0.649400\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:   0.060549 Validation Accuracy: 0.646600\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:   0.032810 Validation Accuracy: 0.640000\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:   0.010029 Validation Accuracy: 0.652200\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:   0.027903 Validation Accuracy: 0.651000\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:   0.027113 Validation Accuracy: 0.653000\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:   0.060449 Validation Accuracy: 0.646000\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:   0.047207 Validation Accuracy: 0.634600\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:   0.009912 Validation Accuracy: 0.657400\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:   0.011545 Validation Accuracy: 0.650800\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:   0.027945 Validation Accuracy: 0.655600\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:   0.058948 Validation Accuracy: 0.647000\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:   0.029673 Validation Accuracy: 0.646400\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:   0.008494 Validation Accuracy: 0.663000\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:   0.019488 Validation Accuracy: 0.652600\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:   0.030132 Validation Accuracy: 0.651800\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:   0.052798 Validation Accuracy: 0.647400\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:   0.030989 Validation Accuracy: 0.633600\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:   0.006925 Validation Accuracy: 0.654800\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:   0.018389 Validation Accuracy: 0.655600\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:   0.021787 Validation Accuracy: 0.659200\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:   0.053930 Validation Accuracy: 0.644400\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:   0.032331 Validation Accuracy: 0.644400\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:   0.006074 Validation Accuracy: 0.659200\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:   0.012398 Validation Accuracy: 0.657200\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:   0.026328 Validation Accuracy: 0.662200\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:   0.056375 Validation Accuracy: 0.643000\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:   0.033794 Validation Accuracy: 0.641800\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:   0.009353 Validation Accuracy: 0.656800\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:   0.016621 Validation Accuracy: 0.656800\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:   0.029551 Validation Accuracy: 0.653600\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:   0.043081 Validation Accuracy: 0.645200\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:   0.030731 Validation Accuracy: 0.637000\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss:   0.007518 Validation Accuracy: 0.662600\n",
      "Epoch 194, CIFAR-10 Batch 4:  Loss:   0.022255 Validation Accuracy: 0.649800\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:   0.028372 Validation Accuracy: 0.652200\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:   0.040288 Validation Accuracy: 0.636000\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:   0.061263 Validation Accuracy: 0.642400\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:   0.008383 Validation Accuracy: 0.659000\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:   0.016183 Validation Accuracy: 0.650400\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:   0.023534 Validation Accuracy: 0.653400\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:   0.055463 Validation Accuracy: 0.636400\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:   0.039841 Validation Accuracy: 0.640600\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:   0.009116 Validation Accuracy: 0.656600\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:   0.019571 Validation Accuracy: 0.658800\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:   0.022897 Validation Accuracy: 0.658400\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:   0.055114 Validation Accuracy: 0.646400\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:   0.040021 Validation Accuracy: 0.643800\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:   0.005047 Validation Accuracy: 0.654800\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:   0.016049 Validation Accuracy: 0.657400\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:   0.015408 Validation Accuracy: 0.655600\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:   0.061677 Validation Accuracy: 0.642000\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:   0.028705 Validation Accuracy: 0.640200\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:   0.009584 Validation Accuracy: 0.651800\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:   0.018873 Validation Accuracy: 0.645200\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:   0.023798 Validation Accuracy: 0.654200\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:   0.042095 Validation Accuracy: 0.638400\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:   0.044071 Validation Accuracy: 0.650400\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:   0.006892 Validation Accuracy: 0.658000\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:   0.015151 Validation Accuracy: 0.652000\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:   0.021414 Validation Accuracy: 0.658000\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:   0.066918 Validation Accuracy: 0.641200\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:   0.040556 Validation Accuracy: 0.645600\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:   0.006199 Validation Accuracy: 0.654200\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:   0.012589 Validation Accuracy: 0.655400\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:   0.019246 Validation Accuracy: 0.657200\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:   0.055527 Validation Accuracy: 0.644800\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:   0.044873 Validation Accuracy: 0.644400\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:   0.008098 Validation Accuracy: 0.652400\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:   0.015875 Validation Accuracy: 0.660000\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:   0.023066 Validation Accuracy: 0.655800\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:   0.038615 Validation Accuracy: 0.633000\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:   0.084115 Validation Accuracy: 0.620600\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:   0.007097 Validation Accuracy: 0.656000\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:   0.021044 Validation Accuracy: 0.649000\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:   0.018914 Validation Accuracy: 0.660600\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:   0.049748 Validation Accuracy: 0.643400\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:   0.049907 Validation Accuracy: 0.639400\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:   0.008120 Validation Accuracy: 0.645800\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:   0.021588 Validation Accuracy: 0.650000\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:   0.017329 Validation Accuracy: 0.659000\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:   0.045987 Validation Accuracy: 0.645600\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:   0.033485 Validation Accuracy: 0.638600\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:   0.007625 Validation Accuracy: 0.653600\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:   0.019958 Validation Accuracy: 0.652400\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:   0.020212 Validation Accuracy: 0.662400\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:   0.049673 Validation Accuracy: 0.634400\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:   0.032409 Validation Accuracy: 0.645200\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:   0.003390 Validation Accuracy: 0.648200\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:   0.018743 Validation Accuracy: 0.646000\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:   0.015412 Validation Accuracy: 0.651400\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:   0.056162 Validation Accuracy: 0.644800\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:   0.035495 Validation Accuracy: 0.640000\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:   0.003545 Validation Accuracy: 0.650800\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:   0.020003 Validation Accuracy: 0.650600\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:   0.020455 Validation Accuracy: 0.651600\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:   0.049933 Validation Accuracy: 0.636000\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:   0.044210 Validation Accuracy: 0.643800\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:   0.004221 Validation Accuracy: 0.658200\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:   0.017519 Validation Accuracy: 0.642800\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:   0.013015 Validation Accuracy: 0.655200\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:   0.040866 Validation Accuracy: 0.635600\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:   0.029794 Validation Accuracy: 0.647400\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:   0.006317 Validation Accuracy: 0.652600\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:   0.014387 Validation Accuracy: 0.642600\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:   0.031428 Validation Accuracy: 0.651800\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:   0.047676 Validation Accuracy: 0.650600\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:   0.031293 Validation Accuracy: 0.640600\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:   0.008153 Validation Accuracy: 0.647200\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:   0.010518 Validation Accuracy: 0.643600\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:   0.024019 Validation Accuracy: 0.656200\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:   0.037828 Validation Accuracy: 0.644000\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:   0.037599 Validation Accuracy: 0.641400\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:   0.005725 Validation Accuracy: 0.638600\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:   0.011432 Validation Accuracy: 0.638000\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:   0.017833 Validation Accuracy: 0.653000\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:   0.041391 Validation Accuracy: 0.643800\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:   0.037094 Validation Accuracy: 0.649200\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:   0.007328 Validation Accuracy: 0.636600\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:   0.016421 Validation Accuracy: 0.634800\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:   0.025519 Validation Accuracy: 0.655600\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:   0.032228 Validation Accuracy: 0.639600\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:   0.034122 Validation Accuracy: 0.641400\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:   0.007406 Validation Accuracy: 0.643400\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:   0.024844 Validation Accuracy: 0.634200\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:   0.017116 Validation Accuracy: 0.655400\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:   0.032235 Validation Accuracy: 0.641200\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:   0.032024 Validation Accuracy: 0.634400\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:   0.005603 Validation Accuracy: 0.645400\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:   0.017091 Validation Accuracy: 0.635600\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:   0.018925 Validation Accuracy: 0.657800\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:   0.039242 Validation Accuracy: 0.643400\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:   0.045732 Validation Accuracy: 0.638200\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:   0.010908 Validation Accuracy: 0.644800\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:   0.026049 Validation Accuracy: 0.641800\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:   0.022231 Validation Accuracy: 0.646600\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:   0.037435 Validation Accuracy: 0.642000\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:   0.037003 Validation Accuracy: 0.639600\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:   0.009058 Validation Accuracy: 0.639400\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:   0.015041 Validation Accuracy: 0.638400\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss:   0.013838 Validation Accuracy: 0.653000\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:   0.039293 Validation Accuracy: 0.641000\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:   0.034999 Validation Accuracy: 0.638800\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:   0.010481 Validation Accuracy: 0.645000\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:   0.016070 Validation Accuracy: 0.638600\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:   0.014693 Validation Accuracy: 0.647200\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:   0.038730 Validation Accuracy: 0.641400\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:   0.035126 Validation Accuracy: 0.643400\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:   0.010471 Validation Accuracy: 0.652400\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:   0.016705 Validation Accuracy: 0.641200\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:   0.014580 Validation Accuracy: 0.648600\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:   0.027836 Validation Accuracy: 0.646200\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:   0.051615 Validation Accuracy: 0.644600\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:   0.008991 Validation Accuracy: 0.650600\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:   0.014179 Validation Accuracy: 0.637000\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:   0.027749 Validation Accuracy: 0.646400\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:   0.032623 Validation Accuracy: 0.643000\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:   0.042502 Validation Accuracy: 0.651000\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:   0.007953 Validation Accuracy: 0.651200\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:   0.008641 Validation Accuracy: 0.645400\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:   0.014580 Validation Accuracy: 0.642200\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:   0.033034 Validation Accuracy: 0.636800\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:   0.053557 Validation Accuracy: 0.641400\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:   0.009769 Validation Accuracy: 0.647200\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:   0.009439 Validation Accuracy: 0.647800\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:   0.011266 Validation Accuracy: 0.648600\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:   0.031811 Validation Accuracy: 0.647400\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:   0.082994 Validation Accuracy: 0.637200\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:   0.005290 Validation Accuracy: 0.651600\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:   0.024931 Validation Accuracy: 0.636600\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:   0.011097 Validation Accuracy: 0.651200\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:   0.032022 Validation Accuracy: 0.640200\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:   0.059626 Validation Accuracy: 0.641600\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:   0.008050 Validation Accuracy: 0.656600\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:   0.014534 Validation Accuracy: 0.641600\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:   0.017423 Validation Accuracy: 0.653000\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:   0.035416 Validation Accuracy: 0.643600\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:   0.042140 Validation Accuracy: 0.644800\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:   0.015125 Validation Accuracy: 0.653000\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:   0.010086 Validation Accuracy: 0.644600\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:   0.016393 Validation Accuracy: 0.653800\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:   0.043499 Validation Accuracy: 0.643400\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:   0.040841 Validation Accuracy: 0.645400\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:   0.010988 Validation Accuracy: 0.658800\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:   0.019054 Validation Accuracy: 0.631800\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:   0.010676 Validation Accuracy: 0.649400\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:   0.028842 Validation Accuracy: 0.646600\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:   0.047120 Validation Accuracy: 0.643400\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:   0.009540 Validation Accuracy: 0.653800\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:   0.010880 Validation Accuracy: 0.635400\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:   0.019290 Validation Accuracy: 0.646800\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:   0.031852 Validation Accuracy: 0.643800\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:   0.051144 Validation Accuracy: 0.642600\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:   0.015833 Validation Accuracy: 0.654200\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:   0.019264 Validation Accuracy: 0.646200\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:   0.018069 Validation Accuracy: 0.648800\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:   0.037534 Validation Accuracy: 0.648600\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:   0.056008 Validation Accuracy: 0.641000\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:   0.022032 Validation Accuracy: 0.651000\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:   0.007451 Validation Accuracy: 0.648000\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:   0.025569 Validation Accuracy: 0.657800\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:   0.036035 Validation Accuracy: 0.650600\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:   0.045922 Validation Accuracy: 0.645600\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:   0.006016 Validation Accuracy: 0.654200\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:   0.011176 Validation Accuracy: 0.641200\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:   0.010065 Validation Accuracy: 0.650200\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:   0.025908 Validation Accuracy: 0.652000\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:   0.056168 Validation Accuracy: 0.640600\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:   0.008735 Validation Accuracy: 0.658200\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:   0.010257 Validation Accuracy: 0.633200\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:   0.018443 Validation Accuracy: 0.649600\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:   0.042794 Validation Accuracy: 0.646200\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:   0.034919 Validation Accuracy: 0.644800\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:   0.014978 Validation Accuracy: 0.653000\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:   0.009552 Validation Accuracy: 0.639600\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:   0.013862 Validation Accuracy: 0.651200\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:   0.031047 Validation Accuracy: 0.652400\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:   0.036123 Validation Accuracy: 0.647000\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:   0.009566 Validation Accuracy: 0.657400\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:   0.010674 Validation Accuracy: 0.640600\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:   0.012233 Validation Accuracy: 0.651400\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:   0.030265 Validation Accuracy: 0.644800\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:   0.032496 Validation Accuracy: 0.655000\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:   0.011039 Validation Accuracy: 0.657600\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:   0.007570 Validation Accuracy: 0.648800\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:   0.012463 Validation Accuracy: 0.662400\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:   0.030402 Validation Accuracy: 0.644400\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:   0.047510 Validation Accuracy: 0.645000\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:   0.007755 Validation Accuracy: 0.653400\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:   0.011087 Validation Accuracy: 0.637200\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:   0.012988 Validation Accuracy: 0.656800\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:   0.034203 Validation Accuracy: 0.644200\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:   0.041124 Validation Accuracy: 0.649200\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:   0.009518 Validation Accuracy: 0.649800\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:   0.017644 Validation Accuracy: 0.636200\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:   0.011073 Validation Accuracy: 0.658000\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:   0.026316 Validation Accuracy: 0.638600\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:   0.032313 Validation Accuracy: 0.653400\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:   0.021956 Validation Accuracy: 0.646000\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:   0.003789 Validation Accuracy: 0.634400\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:   0.021573 Validation Accuracy: 0.650000\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:   0.026115 Validation Accuracy: 0.647200\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:   0.067836 Validation Accuracy: 0.644000\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:   0.017840 Validation Accuracy: 0.652000\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:   0.011411 Validation Accuracy: 0.640400\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:   0.014663 Validation Accuracy: 0.654600\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:   0.027499 Validation Accuracy: 0.639400\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss:   0.043803 Validation Accuracy: 0.636000\n",
      "Epoch 237, CIFAR-10 Batch 3:  Loss:   0.007137 Validation Accuracy: 0.652400\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:   0.008791 Validation Accuracy: 0.642000\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:   0.017424 Validation Accuracy: 0.653600\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:   0.023046 Validation Accuracy: 0.648800\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:   0.037922 Validation Accuracy: 0.639800\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:   0.005995 Validation Accuracy: 0.650000\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:   0.012164 Validation Accuracy: 0.648000\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:   0.012045 Validation Accuracy: 0.654800\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:   0.021348 Validation Accuracy: 0.647800\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:   0.041365 Validation Accuracy: 0.643200\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:   0.011586 Validation Accuracy: 0.652200\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:   0.008507 Validation Accuracy: 0.640200\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:   0.015727 Validation Accuracy: 0.654000\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:   0.019460 Validation Accuracy: 0.650400\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:   0.027682 Validation Accuracy: 0.648400\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:   0.007100 Validation Accuracy: 0.653600\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:   0.013719 Validation Accuracy: 0.640200\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:   0.011709 Validation Accuracy: 0.656000\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:   0.028398 Validation Accuracy: 0.646600\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:   0.043295 Validation Accuracy: 0.648800\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:   0.009418 Validation Accuracy: 0.653600\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:   0.010562 Validation Accuracy: 0.638200\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:   0.020271 Validation Accuracy: 0.659200\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:   0.025869 Validation Accuracy: 0.643400\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:   0.030277 Validation Accuracy: 0.653000\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:   0.009268 Validation Accuracy: 0.651200\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:   0.012259 Validation Accuracy: 0.643600\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:   0.015274 Validation Accuracy: 0.657200\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:   0.029740 Validation Accuracy: 0.650400\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:   0.030465 Validation Accuracy: 0.648000\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:   0.006443 Validation Accuracy: 0.646800\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:   0.010361 Validation Accuracy: 0.645600\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:   0.013538 Validation Accuracy: 0.650200\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:   0.040512 Validation Accuracy: 0.650200\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:   0.035314 Validation Accuracy: 0.645400\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:   0.008328 Validation Accuracy: 0.657600\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:   0.016915 Validation Accuracy: 0.639800\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:   0.015878 Validation Accuracy: 0.654600\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:   0.030950 Validation Accuracy: 0.643800\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:   0.028636 Validation Accuracy: 0.645000\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:   0.004841 Validation Accuracy: 0.656600\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:   0.020416 Validation Accuracy: 0.634400\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:   0.018211 Validation Accuracy: 0.653200\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:   0.030624 Validation Accuracy: 0.650000\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:   0.028432 Validation Accuracy: 0.645000\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:   0.009816 Validation Accuracy: 0.654600\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:   0.012476 Validation Accuracy: 0.634200\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:   0.017212 Validation Accuracy: 0.646200\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:   0.048468 Validation Accuracy: 0.637400\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:   0.026764 Validation Accuracy: 0.644200\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:   0.011406 Validation Accuracy: 0.649000\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:   0.014821 Validation Accuracy: 0.645800\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:   0.015318 Validation Accuracy: 0.654600\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:   0.032476 Validation Accuracy: 0.651000\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:   0.032863 Validation Accuracy: 0.649000\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:   0.010345 Validation Accuracy: 0.652800\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:   0.016110 Validation Accuracy: 0.644200\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:   0.013845 Validation Accuracy: 0.650600\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:   0.041885 Validation Accuracy: 0.648400\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:   0.024849 Validation Accuracy: 0.647800\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:   0.019410 Validation Accuracy: 0.644600\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:   0.013297 Validation Accuracy: 0.647600\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:   0.028494 Validation Accuracy: 0.661000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:   0.032512 Validation Accuracy: 0.648800\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:   0.028181 Validation Accuracy: 0.648600\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:   0.010705 Validation Accuracy: 0.647600\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:   0.009954 Validation Accuracy: 0.643000\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:   0.015827 Validation Accuracy: 0.657400\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:   0.034735 Validation Accuracy: 0.652400\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:   0.024803 Validation Accuracy: 0.647200\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:   0.006730 Validation Accuracy: 0.644400\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:   0.011778 Validation Accuracy: 0.644200\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:   0.014011 Validation Accuracy: 0.653000\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:   0.040325 Validation Accuracy: 0.648600\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:   0.029454 Validation Accuracy: 0.649600\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:   0.006738 Validation Accuracy: 0.645800\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:   0.016021 Validation Accuracy: 0.644800\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:   0.039851 Validation Accuracy: 0.655000\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:   0.021817 Validation Accuracy: 0.648800\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:   0.016284 Validation Accuracy: 0.652400\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:   0.010870 Validation Accuracy: 0.648200\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:   0.015682 Validation Accuracy: 0.655800\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:   0.014073 Validation Accuracy: 0.652200\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:   0.028246 Validation Accuracy: 0.647800\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:   0.017635 Validation Accuracy: 0.652800\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:   0.016314 Validation Accuracy: 0.644600\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:   0.012667 Validation Accuracy: 0.645600\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:   0.007299 Validation Accuracy: 0.646800\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:   0.020336 Validation Accuracy: 0.651200\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:   0.031626 Validation Accuracy: 0.644200\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:   0.006095 Validation Accuracy: 0.643400\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:   0.010832 Validation Accuracy: 0.645200\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:   0.011809 Validation Accuracy: 0.660200\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:   0.037841 Validation Accuracy: 0.651200\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:   0.028075 Validation Accuracy: 0.652400\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss:   0.004673 Validation Accuracy: 0.645200\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:   0.024559 Validation Accuracy: 0.643000\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:   0.009277 Validation Accuracy: 0.651200\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:   0.039107 Validation Accuracy: 0.646600\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:   0.023270 Validation Accuracy: 0.655400\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:   0.016776 Validation Accuracy: 0.642800\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:   0.014238 Validation Accuracy: 0.639000\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:   0.012014 Validation Accuracy: 0.654200\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:   0.027862 Validation Accuracy: 0.637000\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:   0.030041 Validation Accuracy: 0.647000\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:   0.017290 Validation Accuracy: 0.646000\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss:   0.015858 Validation Accuracy: 0.638600\n",
      "Epoch 258, CIFAR-10 Batch 5:  Loss:   0.011441 Validation Accuracy: 0.650000\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:   0.026468 Validation Accuracy: 0.648000\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:   0.033257 Validation Accuracy: 0.646600\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:   0.007793 Validation Accuracy: 0.652200\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:   0.006284 Validation Accuracy: 0.654000\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:   0.007747 Validation Accuracy: 0.646000\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:   0.041847 Validation Accuracy: 0.643000\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:   0.029391 Validation Accuracy: 0.646000\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:   0.013384 Validation Accuracy: 0.647400\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:   0.010681 Validation Accuracy: 0.641200\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:   0.011432 Validation Accuracy: 0.652200\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:   0.033528 Validation Accuracy: 0.641200\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:   0.029408 Validation Accuracy: 0.651400\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:   0.015342 Validation Accuracy: 0.644000\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:   0.009120 Validation Accuracy: 0.647200\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:   0.018077 Validation Accuracy: 0.647800\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:   0.028633 Validation Accuracy: 0.639800\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:   0.024111 Validation Accuracy: 0.651000\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:   0.008239 Validation Accuracy: 0.649600\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:   0.016348 Validation Accuracy: 0.647600\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:   0.012235 Validation Accuracy: 0.651600\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:   0.037352 Validation Accuracy: 0.646800\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:   0.019104 Validation Accuracy: 0.656200\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:   0.016046 Validation Accuracy: 0.639000\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:   0.014993 Validation Accuracy: 0.639200\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:   0.006001 Validation Accuracy: 0.650400\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:   0.034847 Validation Accuracy: 0.644000\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:   0.027360 Validation Accuracy: 0.641000\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:   0.004266 Validation Accuracy: 0.653400\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:   0.021349 Validation Accuracy: 0.644200\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:   0.022455 Validation Accuracy: 0.638000\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:   0.029725 Validation Accuracy: 0.639600\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:   0.023655 Validation Accuracy: 0.644600\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:   0.005560 Validation Accuracy: 0.643400\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:   0.017452 Validation Accuracy: 0.641000\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:   0.010076 Validation Accuracy: 0.640000\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:   0.027467 Validation Accuracy: 0.629000\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:   0.024908 Validation Accuracy: 0.643000\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:   0.013259 Validation Accuracy: 0.648600\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:   0.015467 Validation Accuracy: 0.644800\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:   0.010347 Validation Accuracy: 0.647000\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:   0.029833 Validation Accuracy: 0.638200\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:   0.018687 Validation Accuracy: 0.640200\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:   0.009806 Validation Accuracy: 0.646200\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:   0.010042 Validation Accuracy: 0.642400\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:   0.006150 Validation Accuracy: 0.646800\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:   0.022404 Validation Accuracy: 0.647800\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:   0.025887 Validation Accuracy: 0.648000\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:   0.020487 Validation Accuracy: 0.647000\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:   0.012263 Validation Accuracy: 0.645800\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:   0.011103 Validation Accuracy: 0.650800\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:   0.025577 Validation Accuracy: 0.630200\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:   0.036995 Validation Accuracy: 0.646800\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:   0.009550 Validation Accuracy: 0.650800\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:   0.017989 Validation Accuracy: 0.639200\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:   0.011123 Validation Accuracy: 0.654000\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:   0.026142 Validation Accuracy: 0.633800\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:   0.035522 Validation Accuracy: 0.641600\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:   0.010355 Validation Accuracy: 0.652400\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:   0.013555 Validation Accuracy: 0.645400\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:   0.008274 Validation Accuracy: 0.646600\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:   0.023784 Validation Accuracy: 0.643200\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:   0.028437 Validation Accuracy: 0.648600\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:   0.007595 Validation Accuracy: 0.646200\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:   0.005954 Validation Accuracy: 0.646800\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:   0.012103 Validation Accuracy: 0.646800\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:   0.019975 Validation Accuracy: 0.643600\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:   0.033887 Validation Accuracy: 0.636800\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:   0.005503 Validation Accuracy: 0.649600\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:   0.011068 Validation Accuracy: 0.645200\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:   0.009741 Validation Accuracy: 0.659400\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:   0.026758 Validation Accuracy: 0.634400\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:   0.030058 Validation Accuracy: 0.646600\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:   0.011382 Validation Accuracy: 0.645000\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:   0.006515 Validation Accuracy: 0.651000\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:   0.026176 Validation Accuracy: 0.638600\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:   0.027223 Validation Accuracy: 0.641400\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:   0.027205 Validation Accuracy: 0.648400\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:   0.005293 Validation Accuracy: 0.647800\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:   0.011502 Validation Accuracy: 0.645400\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:   0.010485 Validation Accuracy: 0.648400\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:   0.030067 Validation Accuracy: 0.637200\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:   0.025447 Validation Accuracy: 0.644800\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:   0.008335 Validation Accuracy: 0.640600\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:   0.008569 Validation Accuracy: 0.646800\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:   0.008503 Validation Accuracy: 0.638000\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:   0.025943 Validation Accuracy: 0.642000\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:   0.042719 Validation Accuracy: 0.641400\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:   0.006632 Validation Accuracy: 0.650000\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:   0.017847 Validation Accuracy: 0.649600\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:   0.010948 Validation Accuracy: 0.652200\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:   0.026594 Validation Accuracy: 0.640000\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:   0.028402 Validation Accuracy: 0.634800\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:   0.013508 Validation Accuracy: 0.646800\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:   0.010194 Validation Accuracy: 0.649600\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:   0.011760 Validation Accuracy: 0.653400\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:   0.036321 Validation Accuracy: 0.637600\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:   0.025754 Validation Accuracy: 0.639400\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:   0.011311 Validation Accuracy: 0.647400\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:   0.014538 Validation Accuracy: 0.650600\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:   0.009871 Validation Accuracy: 0.654800\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:   0.017987 Validation Accuracy: 0.642000\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:   0.034307 Validation Accuracy: 0.643600\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:   0.004576 Validation Accuracy: 0.650000\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:   0.010068 Validation Accuracy: 0.646600\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:   0.007541 Validation Accuracy: 0.642600\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:   0.029537 Validation Accuracy: 0.635000\n",
      "Epoch 280, CIFAR-10 Batch 2:  Loss:   0.029741 Validation Accuracy: 0.646200\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:   0.004193 Validation Accuracy: 0.651600\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:   0.008998 Validation Accuracy: 0.651200\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:   0.013699 Validation Accuracy: 0.655400\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:   0.028679 Validation Accuracy: 0.640600\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:   0.020488 Validation Accuracy: 0.642800\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:   0.004379 Validation Accuracy: 0.651000\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:   0.008196 Validation Accuracy: 0.650600\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:   0.017101 Validation Accuracy: 0.654200\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:   0.024622 Validation Accuracy: 0.634000\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:   0.027355 Validation Accuracy: 0.645400\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:   0.006445 Validation Accuracy: 0.650600\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:   0.010448 Validation Accuracy: 0.645400\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:   0.010578 Validation Accuracy: 0.652400\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:   0.026232 Validation Accuracy: 0.638200\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:   0.018600 Validation Accuracy: 0.644600\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:   0.009459 Validation Accuracy: 0.646400\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:   0.013890 Validation Accuracy: 0.644600\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:   0.008194 Validation Accuracy: 0.642800\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:   0.035561 Validation Accuracy: 0.635000\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:   0.023150 Validation Accuracy: 0.646600\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:   0.009514 Validation Accuracy: 0.656400\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:   0.010920 Validation Accuracy: 0.653600\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:   0.009794 Validation Accuracy: 0.657600\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:   0.023272 Validation Accuracy: 0.644600\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:   0.017617 Validation Accuracy: 0.641000\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:   0.020130 Validation Accuracy: 0.648400\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:   0.013188 Validation Accuracy: 0.645400\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:   0.007889 Validation Accuracy: 0.657400\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:   0.028496 Validation Accuracy: 0.644200\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:   0.028741 Validation Accuracy: 0.634800\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:   0.012167 Validation Accuracy: 0.646600\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:   0.010469 Validation Accuracy: 0.651800\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:   0.012758 Validation Accuracy: 0.649600\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:   0.027039 Validation Accuracy: 0.641600\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:   0.018863 Validation Accuracy: 0.648600\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:   0.005212 Validation Accuracy: 0.654400\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:   0.014663 Validation Accuracy: 0.651600\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:   0.006202 Validation Accuracy: 0.654200\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:   0.021641 Validation Accuracy: 0.646600\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:   0.025642 Validation Accuracy: 0.644000\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:   0.005728 Validation Accuracy: 0.656800\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:   0.015239 Validation Accuracy: 0.645600\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:   0.013197 Validation Accuracy: 0.657600\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:   0.033076 Validation Accuracy: 0.636600\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:   0.024778 Validation Accuracy: 0.650200\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:   0.004567 Validation Accuracy: 0.650200\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:   0.009724 Validation Accuracy: 0.655400\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:   0.014289 Validation Accuracy: 0.643600\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:   0.022329 Validation Accuracy: 0.648600\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:   0.034083 Validation Accuracy: 0.642600\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:   0.020287 Validation Accuracy: 0.655000\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:   0.015341 Validation Accuracy: 0.648600\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:   0.005947 Validation Accuracy: 0.651400\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:   0.029040 Validation Accuracy: 0.639400\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:   0.013428 Validation Accuracy: 0.651400\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:   0.003729 Validation Accuracy: 0.647400\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:   0.009712 Validation Accuracy: 0.652800\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:   0.006325 Validation Accuracy: 0.655000\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:   0.032085 Validation Accuracy: 0.635400\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:   0.021905 Validation Accuracy: 0.641400\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:   0.009756 Validation Accuracy: 0.643800\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:   0.008914 Validation Accuracy: 0.650000\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:   0.007749 Validation Accuracy: 0.656200\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:   0.035034 Validation Accuracy: 0.638000\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:   0.022764 Validation Accuracy: 0.646200\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:   0.002182 Validation Accuracy: 0.650000\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:   0.013674 Validation Accuracy: 0.647800\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:   0.007102 Validation Accuracy: 0.654000\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:   0.033492 Validation Accuracy: 0.637600\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:   0.016480 Validation Accuracy: 0.638200\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:   0.004797 Validation Accuracy: 0.650000\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:   0.008966 Validation Accuracy: 0.648400\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:   0.018089 Validation Accuracy: 0.652600\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:   0.026940 Validation Accuracy: 0.634600\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:   0.021046 Validation Accuracy: 0.648000\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:   0.006603 Validation Accuracy: 0.651000\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:   0.006712 Validation Accuracy: 0.645600\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:   0.006724 Validation Accuracy: 0.652200\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:   0.018422 Validation Accuracy: 0.638200\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:   0.023053 Validation Accuracy: 0.648600\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:   0.004108 Validation Accuracy: 0.648600\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:   0.010271 Validation Accuracy: 0.636200\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:   0.011617 Validation Accuracy: 0.651400\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:   0.036829 Validation Accuracy: 0.627400\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:   0.025733 Validation Accuracy: 0.643200\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:   0.003569 Validation Accuracy: 0.651000\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:   0.012360 Validation Accuracy: 0.649600\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:   0.005307 Validation Accuracy: 0.653800\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:   0.028023 Validation Accuracy: 0.637800\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:   0.026718 Validation Accuracy: 0.642400\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:   0.001772 Validation Accuracy: 0.650600\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:   0.005915 Validation Accuracy: 0.649000\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss:   0.009346 Validation Accuracy: 0.650400\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:   0.025370 Validation Accuracy: 0.639000\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:   0.031801 Validation Accuracy: 0.636400\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:   0.002924 Validation Accuracy: 0.644200\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:   0.007433 Validation Accuracy: 0.642800\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:   0.005991 Validation Accuracy: 0.653600\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:   0.022883 Validation Accuracy: 0.642200\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:   0.017874 Validation Accuracy: 0.639000\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:   0.006040 Validation Accuracy: 0.649800\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:   0.006462 Validation Accuracy: 0.639600\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:   0.006561 Validation Accuracy: 0.652600\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:   0.026256 Validation Accuracy: 0.637400\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:   0.026602 Validation Accuracy: 0.636200\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss:   0.002894 Validation Accuracy: 0.648800\n",
      "Epoch 301, CIFAR-10 Batch 4:  Loss:   0.005303 Validation Accuracy: 0.637200\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:   0.007399 Validation Accuracy: 0.650200\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:   0.030639 Validation Accuracy: 0.642400\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:   0.014001 Validation Accuracy: 0.641000\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:   0.003859 Validation Accuracy: 0.654200\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:   0.008680 Validation Accuracy: 0.652200\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:   0.012461 Validation Accuracy: 0.647600\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:   0.033753 Validation Accuracy: 0.646800\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:   0.018690 Validation Accuracy: 0.638800\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:   0.003477 Validation Accuracy: 0.644400\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:   0.013040 Validation Accuracy: 0.645000\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:   0.016911 Validation Accuracy: 0.649800\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:   0.021837 Validation Accuracy: 0.650800\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:   0.015566 Validation Accuracy: 0.637200\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:   0.005103 Validation Accuracy: 0.654000\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:   0.009079 Validation Accuracy: 0.648200\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:   0.005286 Validation Accuracy: 0.651200\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:   0.024329 Validation Accuracy: 0.650200\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:   0.031539 Validation Accuracy: 0.635800\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:   0.004405 Validation Accuracy: 0.656200\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:   0.007055 Validation Accuracy: 0.645400\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:   0.008959 Validation Accuracy: 0.648000\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:   0.047844 Validation Accuracy: 0.635200\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:   0.016816 Validation Accuracy: 0.644600\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:   0.004251 Validation Accuracy: 0.651200\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:   0.008222 Validation Accuracy: 0.642800\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:   0.006447 Validation Accuracy: 0.648000\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:   0.027620 Validation Accuracy: 0.650600\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:   0.020761 Validation Accuracy: 0.638200\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:   0.004138 Validation Accuracy: 0.650000\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:   0.011665 Validation Accuracy: 0.651400\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:   0.012636 Validation Accuracy: 0.641400\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:   0.025941 Validation Accuracy: 0.649400\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:   0.024016 Validation Accuracy: 0.645000\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:   0.002360 Validation Accuracy: 0.655000\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:   0.009184 Validation Accuracy: 0.642200\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:   0.013758 Validation Accuracy: 0.646000\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:   0.025710 Validation Accuracy: 0.650600\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:   0.016286 Validation Accuracy: 0.644800\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:   0.003577 Validation Accuracy: 0.650600\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:   0.009453 Validation Accuracy: 0.647400\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:   0.019628 Validation Accuracy: 0.652400\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:   0.031647 Validation Accuracy: 0.641400\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:   0.013754 Validation Accuracy: 0.637000\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:   0.001715 Validation Accuracy: 0.661000\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:   0.007326 Validation Accuracy: 0.643200\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:   0.007614 Validation Accuracy: 0.649800\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:   0.028432 Validation Accuracy: 0.646000\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:   0.011197 Validation Accuracy: 0.643800\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:   0.002601 Validation Accuracy: 0.656800\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:   0.014944 Validation Accuracy: 0.640800\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:   0.009789 Validation Accuracy: 0.650000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:   0.025450 Validation Accuracy: 0.644200\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:   0.013973 Validation Accuracy: 0.632200\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:   0.003240 Validation Accuracy: 0.645000\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:   0.013493 Validation Accuracy: 0.638200\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:   0.008094 Validation Accuracy: 0.647800\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:   0.046185 Validation Accuracy: 0.647400\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:   0.012970 Validation Accuracy: 0.644800\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:   0.005167 Validation Accuracy: 0.649600\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:   0.009103 Validation Accuracy: 0.640400\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:   0.018176 Validation Accuracy: 0.638200\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:   0.026352 Validation Accuracy: 0.651000\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:   0.022881 Validation Accuracy: 0.645600\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:   0.003117 Validation Accuracy: 0.645200\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:   0.005352 Validation Accuracy: 0.640800\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:   0.022039 Validation Accuracy: 0.639000\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:   0.026856 Validation Accuracy: 0.651800\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:   0.024080 Validation Accuracy: 0.643400\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:   0.002834 Validation Accuracy: 0.646000\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:   0.008052 Validation Accuracy: 0.650600\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:   0.019089 Validation Accuracy: 0.636400\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:   0.022436 Validation Accuracy: 0.646600\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:   0.010587 Validation Accuracy: 0.640200\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:   0.001960 Validation Accuracy: 0.653200\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:   0.013760 Validation Accuracy: 0.639000\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:   0.007930 Validation Accuracy: 0.643200\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:   0.035143 Validation Accuracy: 0.645000\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:   0.009668 Validation Accuracy: 0.648800\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:   0.003099 Validation Accuracy: 0.654800\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:   0.011408 Validation Accuracy: 0.647800\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:   0.012283 Validation Accuracy: 0.645200\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:   0.032837 Validation Accuracy: 0.654800\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:   0.018437 Validation Accuracy: 0.645400\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:   0.000928 Validation Accuracy: 0.652000\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:   0.008115 Validation Accuracy: 0.638200\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:   0.006229 Validation Accuracy: 0.640600\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:   0.031953 Validation Accuracy: 0.644800\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:   0.009591 Validation Accuracy: 0.640600\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:   0.005296 Validation Accuracy: 0.650800\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:   0.005376 Validation Accuracy: 0.650600\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:   0.009870 Validation Accuracy: 0.643200\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:   0.026950 Validation Accuracy: 0.653000\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:   0.022210 Validation Accuracy: 0.644400\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:   0.002747 Validation Accuracy: 0.652800\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:   0.005465 Validation Accuracy: 0.640600\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:   0.007472 Validation Accuracy: 0.642800\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:   0.027222 Validation Accuracy: 0.655400\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:   0.018530 Validation Accuracy: 0.639400\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:   0.002816 Validation Accuracy: 0.652000\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:   0.006460 Validation Accuracy: 0.645800\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:   0.007781 Validation Accuracy: 0.634600\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:   0.026904 Validation Accuracy: 0.648800\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:   0.009936 Validation Accuracy: 0.648200\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:   0.002806 Validation Accuracy: 0.657200\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:   0.008693 Validation Accuracy: 0.643800\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss:   0.007775 Validation Accuracy: 0.642000\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:   0.030680 Validation Accuracy: 0.654400\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:   0.014056 Validation Accuracy: 0.647400\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:   0.003249 Validation Accuracy: 0.651000\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:   0.005507 Validation Accuracy: 0.647000\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:   0.011862 Validation Accuracy: 0.639200\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:   0.040606 Validation Accuracy: 0.648400\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:   0.027368 Validation Accuracy: 0.646000\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:   0.002354 Validation Accuracy: 0.659600\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:   0.010143 Validation Accuracy: 0.646400\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:   0.008479 Validation Accuracy: 0.630200\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:   0.032662 Validation Accuracy: 0.652600\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:   0.008821 Validation Accuracy: 0.646000\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:   0.008524 Validation Accuracy: 0.642400\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:   0.005467 Validation Accuracy: 0.650800\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:   0.007502 Validation Accuracy: 0.643400\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:   0.043842 Validation Accuracy: 0.650200\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:   0.044997 Validation Accuracy: 0.646400\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:   0.004635 Validation Accuracy: 0.654800\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:   0.006133 Validation Accuracy: 0.647000\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:   0.016620 Validation Accuracy: 0.638600\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:   0.033640 Validation Accuracy: 0.647000\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:   0.015292 Validation Accuracy: 0.646600\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:   0.003933 Validation Accuracy: 0.655800\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:   0.005688 Validation Accuracy: 0.648400\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:   0.013330 Validation Accuracy: 0.644400\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:   0.028184 Validation Accuracy: 0.647000\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:   0.010177 Validation Accuracy: 0.646200\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:   0.002937 Validation Accuracy: 0.657000\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:   0.004636 Validation Accuracy: 0.650400\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:   0.004636 Validation Accuracy: 0.642400\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:   0.024386 Validation Accuracy: 0.644800\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:   0.012224 Validation Accuracy: 0.653400\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:   0.001367 Validation Accuracy: 0.652600\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:   0.008825 Validation Accuracy: 0.642600\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:   0.006448 Validation Accuracy: 0.640800\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:   0.021326 Validation Accuracy: 0.649200\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:   0.020019 Validation Accuracy: 0.648600\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:   0.001705 Validation Accuracy: 0.652200\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:   0.006077 Validation Accuracy: 0.645400\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:   0.005218 Validation Accuracy: 0.643400\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:   0.029992 Validation Accuracy: 0.649600\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:   0.009543 Validation Accuracy: 0.650600\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:   0.006185 Validation Accuracy: 0.657800\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:   0.006689 Validation Accuracy: 0.647000\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:   0.006247 Validation Accuracy: 0.643800\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:   0.025509 Validation Accuracy: 0.647200\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:   0.012124 Validation Accuracy: 0.651600\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:   0.003716 Validation Accuracy: 0.657000\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:   0.008374 Validation Accuracy: 0.651400\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:   0.006811 Validation Accuracy: 0.644600\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:   0.041006 Validation Accuracy: 0.642000\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:   0.032798 Validation Accuracy: 0.647000\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:   0.009868 Validation Accuracy: 0.651000\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:   0.007713 Validation Accuracy: 0.642000\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:   0.008500 Validation Accuracy: 0.641000\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:   0.031390 Validation Accuracy: 0.644600\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:   0.017607 Validation Accuracy: 0.644600\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:   0.004351 Validation Accuracy: 0.651200\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:   0.007469 Validation Accuracy: 0.645800\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:   0.004710 Validation Accuracy: 0.645600\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:   0.029027 Validation Accuracy: 0.638800\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:   0.017806 Validation Accuracy: 0.649200\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:   0.002181 Validation Accuracy: 0.659800\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:   0.015264 Validation Accuracy: 0.647200\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:   0.008378 Validation Accuracy: 0.648200\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:   0.023307 Validation Accuracy: 0.641400\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:   0.010144 Validation Accuracy: 0.647200\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:   0.001921 Validation Accuracy: 0.653200\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:   0.005362 Validation Accuracy: 0.653200\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:   0.010922 Validation Accuracy: 0.645400\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:   0.033485 Validation Accuracy: 0.642000\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:   0.013014 Validation Accuracy: 0.649200\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:   0.002541 Validation Accuracy: 0.653800\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:   0.007713 Validation Accuracy: 0.647000\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:   0.006828 Validation Accuracy: 0.651800\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:   0.022655 Validation Accuracy: 0.648000\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:   0.012133 Validation Accuracy: 0.648200\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:   0.005994 Validation Accuracy: 0.655600\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:   0.007024 Validation Accuracy: 0.654200\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:   0.002716 Validation Accuracy: 0.643000\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:   0.031683 Validation Accuracy: 0.637200\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:   0.010749 Validation Accuracy: 0.647800\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:   0.002955 Validation Accuracy: 0.655000\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:   0.015344 Validation Accuracy: 0.641400\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:   0.007096 Validation Accuracy: 0.653200\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:   0.027048 Validation Accuracy: 0.639000\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:   0.008368 Validation Accuracy: 0.651800\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:   0.002699 Validation Accuracy: 0.658600\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:   0.006270 Validation Accuracy: 0.652200\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:   0.005908 Validation Accuracy: 0.644800\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:   0.035046 Validation Accuracy: 0.634600\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss:   0.011351 Validation Accuracy: 0.648800\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:   0.010974 Validation Accuracy: 0.655000\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:   0.007767 Validation Accuracy: 0.649000\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:   0.003945 Validation Accuracy: 0.650000\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:   0.029946 Validation Accuracy: 0.648200\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:   0.009315 Validation Accuracy: 0.649800\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:   0.007739 Validation Accuracy: 0.654400\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:   0.003679 Validation Accuracy: 0.650400\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:   0.004531 Validation Accuracy: 0.650800\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:   0.020190 Validation Accuracy: 0.643800\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:   0.005862 Validation Accuracy: 0.644600\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:   0.005054 Validation Accuracy: 0.653400\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:   0.005225 Validation Accuracy: 0.655400\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:   0.001851 Validation Accuracy: 0.652200\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:   0.030446 Validation Accuracy: 0.649600\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss:   0.025257 Validation Accuracy: 0.647000\n",
      "Epoch 344, CIFAR-10 Batch 3:  Loss:   0.004628 Validation Accuracy: 0.655200\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:   0.010167 Validation Accuracy: 0.649400\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:   0.003154 Validation Accuracy: 0.643000\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:   0.022963 Validation Accuracy: 0.648400\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:   0.005750 Validation Accuracy: 0.645200\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:   0.004623 Validation Accuracy: 0.652400\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:   0.006999 Validation Accuracy: 0.645200\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:   0.005874 Validation Accuracy: 0.647600\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:   0.037637 Validation Accuracy: 0.650800\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:   0.009775 Validation Accuracy: 0.642400\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:   0.003351 Validation Accuracy: 0.647400\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:   0.006910 Validation Accuracy: 0.647000\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:   0.012160 Validation Accuracy: 0.650000\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:   0.025547 Validation Accuracy: 0.654600\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:   0.007161 Validation Accuracy: 0.646600\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:   0.006327 Validation Accuracy: 0.651800\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:   0.007879 Validation Accuracy: 0.648400\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:   0.005510 Validation Accuracy: 0.650200\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:   0.025537 Validation Accuracy: 0.645600\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:   0.006891 Validation Accuracy: 0.642200\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:   0.003068 Validation Accuracy: 0.656000\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:   0.005021 Validation Accuracy: 0.652600\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:   0.007509 Validation Accuracy: 0.642200\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:   0.039172 Validation Accuracy: 0.644800\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:   0.008384 Validation Accuracy: 0.646200\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:   0.006456 Validation Accuracy: 0.648800\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:   0.008045 Validation Accuracy: 0.654600\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:   0.005766 Validation Accuracy: 0.653600\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:   0.033720 Validation Accuracy: 0.647200\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:   0.006148 Validation Accuracy: 0.650400\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:   0.001451 Validation Accuracy: 0.656600\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:   0.004898 Validation Accuracy: 0.648600\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:   0.006350 Validation Accuracy: 0.643200\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:   0.029759 Validation Accuracy: 0.649600\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:   0.008740 Validation Accuracy: 0.645400\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:   0.002870 Validation Accuracy: 0.657400\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:   0.005620 Validation Accuracy: 0.655000\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:   0.007995 Validation Accuracy: 0.646000\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:   0.034983 Validation Accuracy: 0.648200\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:   0.005555 Validation Accuracy: 0.650000\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:   0.006992 Validation Accuracy: 0.658800\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:   0.003435 Validation Accuracy: 0.654400\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:   0.005218 Validation Accuracy: 0.646800\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:   0.034065 Validation Accuracy: 0.647400\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:   0.008162 Validation Accuracy: 0.643000\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:   0.003628 Validation Accuracy: 0.654000\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:   0.006980 Validation Accuracy: 0.655400\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:   0.009268 Validation Accuracy: 0.647600\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:   0.025741 Validation Accuracy: 0.648200\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:   0.009220 Validation Accuracy: 0.644400\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:   0.005045 Validation Accuracy: 0.646600\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:   0.007048 Validation Accuracy: 0.652800\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:   0.006579 Validation Accuracy: 0.652600\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:   0.022046 Validation Accuracy: 0.651800\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:   0.011526 Validation Accuracy: 0.649400\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:   0.002474 Validation Accuracy: 0.651200\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:   0.005779 Validation Accuracy: 0.657800\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:   0.002859 Validation Accuracy: 0.646000\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:   0.022548 Validation Accuracy: 0.650000\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:   0.007948 Validation Accuracy: 0.647400\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:   0.001998 Validation Accuracy: 0.656200\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:   0.005083 Validation Accuracy: 0.655200\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:   0.004737 Validation Accuracy: 0.652800\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:   0.022411 Validation Accuracy: 0.644600\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:   0.008122 Validation Accuracy: 0.637000\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:   0.004135 Validation Accuracy: 0.657200\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:   0.004708 Validation Accuracy: 0.650800\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:   0.009694 Validation Accuracy: 0.651400\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:   0.034281 Validation Accuracy: 0.647000\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:   0.006914 Validation Accuracy: 0.638400\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:   0.006883 Validation Accuracy: 0.656600\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:   0.005954 Validation Accuracy: 0.649400\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:   0.006295 Validation Accuracy: 0.647000\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:   0.020312 Validation Accuracy: 0.653200\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:   0.006801 Validation Accuracy: 0.637400\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:   0.005531 Validation Accuracy: 0.654200\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:   0.004424 Validation Accuracy: 0.650800\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:   0.008666 Validation Accuracy: 0.652200\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:   0.023037 Validation Accuracy: 0.645200\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:   0.009426 Validation Accuracy: 0.642800\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:   0.002389 Validation Accuracy: 0.654800\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:   0.006269 Validation Accuracy: 0.655400\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:   0.011499 Validation Accuracy: 0.646200\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:   0.027673 Validation Accuracy: 0.642800\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:   0.010975 Validation Accuracy: 0.642600\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:   0.006816 Validation Accuracy: 0.655200\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:   0.005288 Validation Accuracy: 0.651600\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:   0.005275 Validation Accuracy: 0.648400\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:   0.025157 Validation Accuracy: 0.643400\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:   0.011837 Validation Accuracy: 0.645400\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:   0.006506 Validation Accuracy: 0.655200\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:   0.004117 Validation Accuracy: 0.647600\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:   0.012633 Validation Accuracy: 0.648400\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:   0.028769 Validation Accuracy: 0.643800\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:   0.006939 Validation Accuracy: 0.638200\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:   0.006594 Validation Accuracy: 0.643400\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:   0.006639 Validation Accuracy: 0.647800\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:   0.007078 Validation Accuracy: 0.651400\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:   0.028490 Validation Accuracy: 0.648800\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:   0.012183 Validation Accuracy: 0.644200\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:   0.001575 Validation Accuracy: 0.654800\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:   0.004259 Validation Accuracy: 0.653600\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:   0.009245 Validation Accuracy: 0.648200\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:   0.019579 Validation Accuracy: 0.651200\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:   0.003759 Validation Accuracy: 0.642200\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:   0.002626 Validation Accuracy: 0.652600\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss:   0.008388 Validation Accuracy: 0.651000\n",
      "Epoch 365, CIFAR-10 Batch 5:  Loss:   0.005470 Validation Accuracy: 0.653200\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:   0.029070 Validation Accuracy: 0.655000\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:   0.005480 Validation Accuracy: 0.644400\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:   0.002824 Validation Accuracy: 0.655000\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:   0.003939 Validation Accuracy: 0.652400\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:   0.007154 Validation Accuracy: 0.647800\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:   0.019197 Validation Accuracy: 0.651600\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:   0.003549 Validation Accuracy: 0.644400\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:   0.008506 Validation Accuracy: 0.651800\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:   0.009738 Validation Accuracy: 0.650200\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:   0.005928 Validation Accuracy: 0.648600\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:   0.016281 Validation Accuracy: 0.650400\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:   0.006995 Validation Accuracy: 0.636400\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:   0.003433 Validation Accuracy: 0.652400\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:   0.009793 Validation Accuracy: 0.653200\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:   0.005590 Validation Accuracy: 0.641600\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:   0.043412 Validation Accuracy: 0.646400\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:   0.007036 Validation Accuracy: 0.638000\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:   0.012761 Validation Accuracy: 0.652600\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:   0.007439 Validation Accuracy: 0.655400\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:   0.004710 Validation Accuracy: 0.645600\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:   0.022192 Validation Accuracy: 0.648400\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:   0.016090 Validation Accuracy: 0.630200\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:   0.001940 Validation Accuracy: 0.655600\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:   0.008685 Validation Accuracy: 0.653800\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:   0.006533 Validation Accuracy: 0.647000\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:   0.016731 Validation Accuracy: 0.645000\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:   0.015977 Validation Accuracy: 0.641400\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:   0.007135 Validation Accuracy: 0.645200\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:   0.006668 Validation Accuracy: 0.659000\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:   0.004762 Validation Accuracy: 0.647800\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:   0.017857 Validation Accuracy: 0.651000\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:   0.007990 Validation Accuracy: 0.642600\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:   0.005643 Validation Accuracy: 0.652000\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:   0.006578 Validation Accuracy: 0.650200\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:   0.010661 Validation Accuracy: 0.646200\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:   0.018725 Validation Accuracy: 0.650200\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:   0.004100 Validation Accuracy: 0.640200\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:   0.000992 Validation Accuracy: 0.655600\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:   0.008282 Validation Accuracy: 0.654400\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:   0.005482 Validation Accuracy: 0.646800\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:   0.019916 Validation Accuracy: 0.651400\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:   0.007754 Validation Accuracy: 0.643200\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:   0.003113 Validation Accuracy: 0.654000\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:   0.006637 Validation Accuracy: 0.644600\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:   0.004306 Validation Accuracy: 0.647400\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:   0.017942 Validation Accuracy: 0.649200\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:   0.011513 Validation Accuracy: 0.634600\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:   0.003803 Validation Accuracy: 0.658800\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:   0.003903 Validation Accuracy: 0.649000\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:   0.003005 Validation Accuracy: 0.644400\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:   0.018800 Validation Accuracy: 0.651400\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:   0.008569 Validation Accuracy: 0.642200\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:   0.003113 Validation Accuracy: 0.645000\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:   0.006259 Validation Accuracy: 0.651000\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:   0.004231 Validation Accuracy: 0.642200\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:   0.014305 Validation Accuracy: 0.652400\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:   0.008862 Validation Accuracy: 0.637000\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:   0.001034 Validation Accuracy: 0.640600\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:   0.005390 Validation Accuracy: 0.655600\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:   0.005272 Validation Accuracy: 0.652000\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:   0.017804 Validation Accuracy: 0.655000\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:   0.007618 Validation Accuracy: 0.645600\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:   0.006099 Validation Accuracy: 0.648400\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:   0.010736 Validation Accuracy: 0.651800\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:   0.002373 Validation Accuracy: 0.650400\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:   0.022897 Validation Accuracy: 0.647800\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:   0.012567 Validation Accuracy: 0.641400\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:   0.002618 Validation Accuracy: 0.652200\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:   0.004505 Validation Accuracy: 0.656600\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:   0.008017 Validation Accuracy: 0.635200\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:   0.013798 Validation Accuracy: 0.646200\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:   0.007612 Validation Accuracy: 0.640200\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:   0.001191 Validation Accuracy: 0.654800\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:   0.003570 Validation Accuracy: 0.651400\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:   0.008359 Validation Accuracy: 0.639200\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:   0.017237 Validation Accuracy: 0.656000\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:   0.011397 Validation Accuracy: 0.636000\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:   0.001241 Validation Accuracy: 0.649400\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:   0.007214 Validation Accuracy: 0.653000\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:   0.003594 Validation Accuracy: 0.642400\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:   0.013045 Validation Accuracy: 0.649200\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:   0.027019 Validation Accuracy: 0.636200\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:   0.002347 Validation Accuracy: 0.649000\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:   0.003193 Validation Accuracy: 0.655200\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:   0.007753 Validation Accuracy: 0.639800\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:   0.016440 Validation Accuracy: 0.651800\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:   0.004738 Validation Accuracy: 0.637000\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:   0.000575 Validation Accuracy: 0.653400\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss:   0.003854 Validation Accuracy: 0.653400\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:   0.003787 Validation Accuracy: 0.645600\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:   0.021328 Validation Accuracy: 0.650800\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:   0.009379 Validation Accuracy: 0.637400\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:   0.001098 Validation Accuracy: 0.648800\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:   0.002415 Validation Accuracy: 0.653400\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:   0.005576 Validation Accuracy: 0.648000\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:   0.025490 Validation Accuracy: 0.650600\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:   0.004199 Validation Accuracy: 0.636400\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:   0.002408 Validation Accuracy: 0.653400\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:   0.002502 Validation Accuracy: 0.650800\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:   0.003243 Validation Accuracy: 0.644400\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:   0.019503 Validation Accuracy: 0.653000\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:   0.010913 Validation Accuracy: 0.643800\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:   0.003387 Validation Accuracy: 0.650800\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:   0.003614 Validation Accuracy: 0.653200\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:   0.005793 Validation Accuracy: 0.643400\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:   0.020649 Validation Accuracy: 0.652400\n",
      "Epoch 387, CIFAR-10 Batch 2:  Loss:   0.007731 Validation Accuracy: 0.638200\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:   0.004583 Validation Accuracy: 0.644000\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:   0.001735 Validation Accuracy: 0.655000\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss:   0.004468 Validation Accuracy: 0.650400\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:   0.028682 Validation Accuracy: 0.654600\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss:   0.008230 Validation Accuracy: 0.631800\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss:   0.002904 Validation Accuracy: 0.646800\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss:   0.002987 Validation Accuracy: 0.647600\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss:   0.004209 Validation Accuracy: 0.643800\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:   0.016145 Validation Accuracy: 0.646200\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss:   0.011670 Validation Accuracy: 0.627600\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss:   0.001330 Validation Accuracy: 0.646400\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss:   0.002542 Validation Accuracy: 0.647400\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss:   0.007829 Validation Accuracy: 0.645200\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:   0.020383 Validation Accuracy: 0.650000\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss:   0.009208 Validation Accuracy: 0.631400\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss:   0.002558 Validation Accuracy: 0.652200\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss:   0.002554 Validation Accuracy: 0.651800\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss:   0.011810 Validation Accuracy: 0.636200\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:   0.025626 Validation Accuracy: 0.652600\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss:   0.008240 Validation Accuracy: 0.638600\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss:   0.002133 Validation Accuracy: 0.656400\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss:   0.003895 Validation Accuracy: 0.653200\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss:   0.008415 Validation Accuracy: 0.643200\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:   0.016337 Validation Accuracy: 0.649800\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss:   0.006137 Validation Accuracy: 0.632600\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss:   0.003857 Validation Accuracy: 0.648800\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss:   0.006639 Validation Accuracy: 0.651600\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss:   0.009283 Validation Accuracy: 0.641800\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:   0.016491 Validation Accuracy: 0.640600\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss:   0.006927 Validation Accuracy: 0.639200\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss:   0.002510 Validation Accuracy: 0.651600\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss:   0.004746 Validation Accuracy: 0.653000\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss:   0.011425 Validation Accuracy: 0.641600\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:   0.022625 Validation Accuracy: 0.647000\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss:   0.012304 Validation Accuracy: 0.639400\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss:   0.005312 Validation Accuracy: 0.651400\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss:   0.005648 Validation Accuracy: 0.649000\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss:   0.005699 Validation Accuracy: 0.640600\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:   0.019320 Validation Accuracy: 0.649800\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss:   0.002452 Validation Accuracy: 0.642600\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss:   0.000685 Validation Accuracy: 0.643400\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss:   0.002026 Validation Accuracy: 0.648000\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss:   0.011476 Validation Accuracy: 0.639800\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:   0.016862 Validation Accuracy: 0.647800\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss:   0.005015 Validation Accuracy: 0.646200\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss:   0.001315 Validation Accuracy: 0.647200\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss:   0.006636 Validation Accuracy: 0.648200\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss:   0.006646 Validation Accuracy: 0.643200\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:   0.020832 Validation Accuracy: 0.657000\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss:   0.007946 Validation Accuracy: 0.640800\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss:   0.000842 Validation Accuracy: 0.651400\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss:   0.007533 Validation Accuracy: 0.648200\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss:   0.011737 Validation Accuracy: 0.642200\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:   0.018342 Validation Accuracy: 0.655800\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss:   0.008798 Validation Accuracy: 0.643800\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss:   0.001610 Validation Accuracy: 0.652600\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss:   0.004154 Validation Accuracy: 0.641600\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss:   0.008934 Validation Accuracy: 0.635600\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:   0.020415 Validation Accuracy: 0.657200\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss:   0.007718 Validation Accuracy: 0.638400\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss:   0.000625 Validation Accuracy: 0.650800\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss:   0.004948 Validation Accuracy: 0.645800\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss:   0.020325 Validation Accuracy: 0.636400\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:   0.025428 Validation Accuracy: 0.652800\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss:   0.004592 Validation Accuracy: 0.639600\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss:   0.000743 Validation Accuracy: 0.649800\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss:   0.006943 Validation Accuracy: 0.643800\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss:   0.011286 Validation Accuracy: 0.630200\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:   0.017939 Validation Accuracy: 0.652000\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss:   0.006314 Validation Accuracy: 0.638600\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss:   0.000759 Validation Accuracy: 0.655600\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss:   0.001368 Validation Accuracy: 0.647600\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss:   0.009377 Validation Accuracy: 0.639000\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:   0.017524 Validation Accuracy: 0.655600\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss:   0.007474 Validation Accuracy: 0.642200\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss:   0.003083 Validation Accuracy: 0.652600\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss:   0.001687 Validation Accuracy: 0.645800\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss:   0.003887 Validation Accuracy: 0.630600\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:   0.014234 Validation Accuracy: 0.653200\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss:   0.008370 Validation Accuracy: 0.639800\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss:   0.001279 Validation Accuracy: 0.644400\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss:   0.001669 Validation Accuracy: 0.648600\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss:   0.006554 Validation Accuracy: 0.650200\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:   0.027369 Validation Accuracy: 0.650000\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss:   0.011095 Validation Accuracy: 0.650000\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss:   0.001339 Validation Accuracy: 0.644800\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss:   0.002914 Validation Accuracy: 0.650400\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss:   0.005153 Validation Accuracy: 0.641000\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:   0.021095 Validation Accuracy: 0.653400\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss:   0.004617 Validation Accuracy: 0.643600\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss:   0.001251 Validation Accuracy: 0.647800\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss:   0.004019 Validation Accuracy: 0.639800\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss:   0.009207 Validation Accuracy: 0.638400\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:   0.022548 Validation Accuracy: 0.654400\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss:   0.004144 Validation Accuracy: 0.652000\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss:   0.003501 Validation Accuracy: 0.646400\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss:   0.001826 Validation Accuracy: 0.644400\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss:   0.006566 Validation Accuracy: 0.648400\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:   0.012415 Validation Accuracy: 0.655600\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss:   0.004399 Validation Accuracy: 0.646200\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss:   0.003792 Validation Accuracy: 0.643800\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss:   0.002849 Validation Accuracy: 0.642000\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss:   0.006041 Validation Accuracy: 0.639800\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:   0.036111 Validation Accuracy: 0.650600\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss:   0.009113 Validation Accuracy: 0.640600\n",
      "Epoch 408, CIFAR-10 Batch 3:  Loss:   0.001208 Validation Accuracy: 0.640200\n",
      "Epoch 408, CIFAR-10 Batch 4:  Loss:   0.002530 Validation Accuracy: 0.651400\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss:   0.004968 Validation Accuracy: 0.646400\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:   0.024888 Validation Accuracy: 0.651200\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss:   0.005125 Validation Accuracy: 0.641600\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss:   0.001424 Validation Accuracy: 0.645400\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss:   0.004928 Validation Accuracy: 0.647200\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss:   0.011713 Validation Accuracy: 0.640000\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:   0.021641 Validation Accuracy: 0.646200\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss:   0.010365 Validation Accuracy: 0.642400\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss:   0.001011 Validation Accuracy: 0.652200\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss:   0.006396 Validation Accuracy: 0.650800\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss:   0.004499 Validation Accuracy: 0.645600\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:   0.018618 Validation Accuracy: 0.649600\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss:   0.009055 Validation Accuracy: 0.637200\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss:   0.003139 Validation Accuracy: 0.649600\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss:   0.003643 Validation Accuracy: 0.650600\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss:   0.007095 Validation Accuracy: 0.639200\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:   0.016777 Validation Accuracy: 0.652600\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss:   0.010721 Validation Accuracy: 0.641200\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss:   0.001201 Validation Accuracy: 0.646200\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss:   0.002262 Validation Accuracy: 0.646600\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss:   0.012294 Validation Accuracy: 0.641400\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:   0.021510 Validation Accuracy: 0.652000\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss:   0.005963 Validation Accuracy: 0.647200\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss:   0.003540 Validation Accuracy: 0.648800\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss:   0.002355 Validation Accuracy: 0.645000\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss:   0.007814 Validation Accuracy: 0.644400\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:   0.021547 Validation Accuracy: 0.644400\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss:   0.010753 Validation Accuracy: 0.646200\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss:   0.000424 Validation Accuracy: 0.650600\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss:   0.002267 Validation Accuracy: 0.646400\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss:   0.005997 Validation Accuracy: 0.650400\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:   0.023115 Validation Accuracy: 0.648400\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss:   0.004949 Validation Accuracy: 0.651200\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss:   0.001469 Validation Accuracy: 0.644400\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss:   0.002234 Validation Accuracy: 0.648200\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss:   0.013502 Validation Accuracy: 0.647200\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:   0.019488 Validation Accuracy: 0.657400\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss:   0.007452 Validation Accuracy: 0.650800\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss:   0.002172 Validation Accuracy: 0.657200\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss:   0.000861 Validation Accuracy: 0.652800\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss:   0.002988 Validation Accuracy: 0.639800\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:   0.024206 Validation Accuracy: 0.656400\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss:   0.004843 Validation Accuracy: 0.646400\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss:   0.001928 Validation Accuracy: 0.649400\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss:   0.001634 Validation Accuracy: 0.651800\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss:   0.002594 Validation Accuracy: 0.643000\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:   0.022958 Validation Accuracy: 0.650600\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss:   0.003321 Validation Accuracy: 0.646600\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss:   0.003875 Validation Accuracy: 0.651000\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss:   0.002494 Validation Accuracy: 0.640800\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss:   0.002649 Validation Accuracy: 0.642000\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:   0.029872 Validation Accuracy: 0.653600\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss:   0.019039 Validation Accuracy: 0.641200\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss:   0.002007 Validation Accuracy: 0.648800\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss:   0.001386 Validation Accuracy: 0.641400\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss:   0.003314 Validation Accuracy: 0.650200\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:   0.022473 Validation Accuracy: 0.654000\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss:   0.011723 Validation Accuracy: 0.648000\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss:   0.001173 Validation Accuracy: 0.651800\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss:   0.002119 Validation Accuracy: 0.644400\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss:   0.004423 Validation Accuracy: 0.644600\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:   0.018681 Validation Accuracy: 0.653600\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss:   0.003153 Validation Accuracy: 0.642400\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss:   0.000945 Validation Accuracy: 0.651800\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss:   0.001915 Validation Accuracy: 0.650600\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss:   0.005218 Validation Accuracy: 0.646600\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:   0.020124 Validation Accuracy: 0.651200\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss:   0.002971 Validation Accuracy: 0.647600\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss:   0.001162 Validation Accuracy: 0.653000\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss:   0.005939 Validation Accuracy: 0.648400\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss:   0.006852 Validation Accuracy: 0.646400\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:   0.019385 Validation Accuracy: 0.652800\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss:   0.002868 Validation Accuracy: 0.647800\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss:   0.002761 Validation Accuracy: 0.643600\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss:   0.002488 Validation Accuracy: 0.640400\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss:   0.003219 Validation Accuracy: 0.646200\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:   0.016281 Validation Accuracy: 0.656600\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss:   0.009867 Validation Accuracy: 0.644000\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss:   0.003606 Validation Accuracy: 0.645800\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss:   0.003233 Validation Accuracy: 0.647800\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss:   0.004972 Validation Accuracy: 0.647400\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:   0.017426 Validation Accuracy: 0.649800\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss:   0.008026 Validation Accuracy: 0.641400\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss:   0.001436 Validation Accuracy: 0.650800\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss:   0.003879 Validation Accuracy: 0.649000\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss:   0.014926 Validation Accuracy: 0.647400\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:   0.020400 Validation Accuracy: 0.648400\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss:   0.002404 Validation Accuracy: 0.640000\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss:   0.001627 Validation Accuracy: 0.646600\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss:   0.003605 Validation Accuracy: 0.652200\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss:   0.003274 Validation Accuracy: 0.650600\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:   0.021687 Validation Accuracy: 0.654000\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss:   0.015387 Validation Accuracy: 0.644000\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss:   0.004068 Validation Accuracy: 0.651400\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss:   0.004169 Validation Accuracy: 0.651600\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss:   0.005859 Validation Accuracy: 0.645600\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:   0.021574 Validation Accuracy: 0.650400\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss:   0.008731 Validation Accuracy: 0.653200\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss:   0.001583 Validation Accuracy: 0.649600\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss:   0.009129 Validation Accuracy: 0.640600\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss:   0.007552 Validation Accuracy: 0.645200\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:   0.015856 Validation Accuracy: 0.650000\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss:   0.012975 Validation Accuracy: 0.649600\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss:   0.000631 Validation Accuracy: 0.656800\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss:   0.001253 Validation Accuracy: 0.639800\n",
      "Epoch 429, CIFAR-10 Batch 5:  Loss:   0.003291 Validation Accuracy: 0.653000\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:   0.014483 Validation Accuracy: 0.652600\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss:   0.002875 Validation Accuracy: 0.648000\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss:   0.001849 Validation Accuracy: 0.650400\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss:   0.001192 Validation Accuracy: 0.646200\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss:   0.002362 Validation Accuracy: 0.653800\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:   0.014635 Validation Accuracy: 0.655800\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss:   0.005549 Validation Accuracy: 0.648200\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss:   0.003196 Validation Accuracy: 0.645000\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss:   0.001783 Validation Accuracy: 0.643000\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss:   0.004280 Validation Accuracy: 0.639000\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:   0.014722 Validation Accuracy: 0.654800\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss:   0.010681 Validation Accuracy: 0.640400\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss:   0.001061 Validation Accuracy: 0.656000\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss:   0.002400 Validation Accuracy: 0.644000\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss:   0.005955 Validation Accuracy: 0.648600\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:   0.016395 Validation Accuracy: 0.653400\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss:   0.004618 Validation Accuracy: 0.646800\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss:   0.001249 Validation Accuracy: 0.652000\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss:   0.001556 Validation Accuracy: 0.642200\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss:   0.002397 Validation Accuracy: 0.644200\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:   0.015355 Validation Accuracy: 0.651800\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss:   0.001544 Validation Accuracy: 0.649800\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss:   0.003402 Validation Accuracy: 0.644000\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss:   0.003502 Validation Accuracy: 0.648400\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss:   0.007908 Validation Accuracy: 0.647000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:   0.020052 Validation Accuracy: 0.651000\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss:   0.003935 Validation Accuracy: 0.641600\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss:   0.001494 Validation Accuracy: 0.650200\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss:   0.004363 Validation Accuracy: 0.641000\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss:   0.005702 Validation Accuracy: 0.645400\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:   0.013877 Validation Accuracy: 0.654600\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss:   0.007111 Validation Accuracy: 0.642400\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss:   0.002024 Validation Accuracy: 0.653000\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss:   0.001263 Validation Accuracy: 0.654600\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss:   0.002650 Validation Accuracy: 0.644600\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:   0.013498 Validation Accuracy: 0.657200\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss:   0.002696 Validation Accuracy: 0.647400\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss:   0.004233 Validation Accuracy: 0.654000\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss:   0.001415 Validation Accuracy: 0.640400\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss:   0.006850 Validation Accuracy: 0.650600\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:   0.015730 Validation Accuracy: 0.650600\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss:   0.014121 Validation Accuracy: 0.644000\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss:   0.001868 Validation Accuracy: 0.648600\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss:   0.002418 Validation Accuracy: 0.650000\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss:   0.003489 Validation Accuracy: 0.643800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:   0.019606 Validation Accuracy: 0.652400\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss:   0.003932 Validation Accuracy: 0.647200\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss:   0.003248 Validation Accuracy: 0.644600\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss:   0.005743 Validation Accuracy: 0.644600\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss:   0.005134 Validation Accuracy: 0.648400\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:   0.011087 Validation Accuracy: 0.656200\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss:   0.005413 Validation Accuracy: 0.647000\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss:   0.010029 Validation Accuracy: 0.651200\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss:   0.005335 Validation Accuracy: 0.645000\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss:   0.002251 Validation Accuracy: 0.651200\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:   0.014535 Validation Accuracy: 0.648000\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss:   0.003564 Validation Accuracy: 0.645600\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss:   0.000828 Validation Accuracy: 0.643400\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss:   0.000606 Validation Accuracy: 0.646400\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss:   0.003013 Validation Accuracy: 0.646600\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:   0.019914 Validation Accuracy: 0.651600\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss:   0.004124 Validation Accuracy: 0.644400\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss:   0.001012 Validation Accuracy: 0.649400\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss:   0.001805 Validation Accuracy: 0.639600\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss:   0.006795 Validation Accuracy: 0.647000\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:   0.016288 Validation Accuracy: 0.648600\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss:   0.003597 Validation Accuracy: 0.639800\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss:   0.001402 Validation Accuracy: 0.649800\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss:   0.004316 Validation Accuracy: 0.649600\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss:   0.005293 Validation Accuracy: 0.647200\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:   0.018752 Validation Accuracy: 0.651800\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss:   0.002885 Validation Accuracy: 0.645600\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss:   0.000712 Validation Accuracy: 0.650000\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss:   0.001641 Validation Accuracy: 0.645000\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss:   0.006008 Validation Accuracy: 0.645800\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:   0.014056 Validation Accuracy: 0.653200\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss:   0.003020 Validation Accuracy: 0.646000\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss:   0.002904 Validation Accuracy: 0.643800\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss:   0.002253 Validation Accuracy: 0.641200\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss:   0.004803 Validation Accuracy: 0.650800\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:   0.023557 Validation Accuracy: 0.651400\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss:   0.002978 Validation Accuracy: 0.642200\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss:   0.003261 Validation Accuracy: 0.648000\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss:   0.001136 Validation Accuracy: 0.641000\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss:   0.004717 Validation Accuracy: 0.645000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:   0.022014 Validation Accuracy: 0.648800\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss:   0.004936 Validation Accuracy: 0.637600\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss:   0.001182 Validation Accuracy: 0.658200\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss:   0.001463 Validation Accuracy: 0.646000\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss:   0.006982 Validation Accuracy: 0.643000\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:   0.014394 Validation Accuracy: 0.653800\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss:   0.004076 Validation Accuracy: 0.641800\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss:   0.003954 Validation Accuracy: 0.639000\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss:   0.008505 Validation Accuracy: 0.629000\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss:   0.013432 Validation Accuracy: 0.648600\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:   0.010980 Validation Accuracy: 0.647000\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss:   0.004273 Validation Accuracy: 0.642200\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss:   0.000895 Validation Accuracy: 0.640200\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss:   0.003716 Validation Accuracy: 0.633200\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss:   0.004030 Validation Accuracy: 0.643800\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:   0.024813 Validation Accuracy: 0.649200\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss:   0.008025 Validation Accuracy: 0.643000\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss:   0.003243 Validation Accuracy: 0.645600\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss:   0.001404 Validation Accuracy: 0.646200\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss:   0.002434 Validation Accuracy: 0.650400\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:   0.014435 Validation Accuracy: 0.653600\n",
      "Epoch 451, CIFAR-10 Batch 2:  Loss:   0.008654 Validation Accuracy: 0.646400\n",
      "Epoch 451, CIFAR-10 Batch 3:  Loss:   0.004074 Validation Accuracy: 0.643000\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss:   0.002187 Validation Accuracy: 0.640600\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss:   0.008938 Validation Accuracy: 0.643000\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:   0.020507 Validation Accuracy: 0.651400\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss:   0.002250 Validation Accuracy: 0.646200\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss:   0.003875 Validation Accuracy: 0.649200\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss:   0.003283 Validation Accuracy: 0.644600\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss:   0.005002 Validation Accuracy: 0.647800\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:   0.016842 Validation Accuracy: 0.649800\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss:   0.005002 Validation Accuracy: 0.635800\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss:   0.003578 Validation Accuracy: 0.645800\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss:   0.006363 Validation Accuracy: 0.629400\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss:   0.004926 Validation Accuracy: 0.646800\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:   0.012953 Validation Accuracy: 0.647200\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss:   0.003469 Validation Accuracy: 0.634200\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss:   0.001226 Validation Accuracy: 0.645000\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss:   0.005468 Validation Accuracy: 0.641400\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss:   0.007743 Validation Accuracy: 0.639000\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:   0.029262 Validation Accuracy: 0.650800\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss:   0.004875 Validation Accuracy: 0.638800\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss:   0.002709 Validation Accuracy: 0.644600\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss:   0.001341 Validation Accuracy: 0.639400\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss:   0.009150 Validation Accuracy: 0.648200\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:   0.011998 Validation Accuracy: 0.651000\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss:   0.004884 Validation Accuracy: 0.638000\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss:   0.000749 Validation Accuracy: 0.648400\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss:   0.001534 Validation Accuracy: 0.635200\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss:   0.007359 Validation Accuracy: 0.646800\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:   0.011309 Validation Accuracy: 0.652400\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss:   0.010251 Validation Accuracy: 0.640600\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss:   0.004405 Validation Accuracy: 0.641600\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss:   0.004578 Validation Accuracy: 0.634200\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss:   0.003845 Validation Accuracy: 0.647000\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:   0.015562 Validation Accuracy: 0.655800\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss:   0.003526 Validation Accuracy: 0.637600\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss:   0.005524 Validation Accuracy: 0.639600\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss:   0.001772 Validation Accuracy: 0.637400\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss:   0.004858 Validation Accuracy: 0.646800\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:   0.010014 Validation Accuracy: 0.651000\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss:   0.003631 Validation Accuracy: 0.646600\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss:   0.001761 Validation Accuracy: 0.643000\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss:   0.006726 Validation Accuracy: 0.632600\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss:   0.004644 Validation Accuracy: 0.651000\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:   0.014115 Validation Accuracy: 0.653400\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss:   0.005430 Validation Accuracy: 0.643800\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss:   0.007381 Validation Accuracy: 0.637000\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss:   0.001696 Validation Accuracy: 0.637000\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss:   0.010571 Validation Accuracy: 0.644400\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:   0.014975 Validation Accuracy: 0.643200\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss:   0.007770 Validation Accuracy: 0.643600\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss:   0.004928 Validation Accuracy: 0.646400\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss:   0.002075 Validation Accuracy: 0.633800\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss:   0.006751 Validation Accuracy: 0.649600\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:   0.011188 Validation Accuracy: 0.653000\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss:   0.002488 Validation Accuracy: 0.645200\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss:   0.007900 Validation Accuracy: 0.637600\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss:   0.002096 Validation Accuracy: 0.639600\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss:   0.002312 Validation Accuracy: 0.644800\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:   0.023753 Validation Accuracy: 0.648800\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss:   0.002534 Validation Accuracy: 0.646800\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss:   0.002943 Validation Accuracy: 0.644000\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss:   0.002003 Validation Accuracy: 0.629600\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss:   0.003001 Validation Accuracy: 0.646800\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:   0.012056 Validation Accuracy: 0.650200\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss:   0.003113 Validation Accuracy: 0.643000\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss:   0.002447 Validation Accuracy: 0.642600\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss:   0.003904 Validation Accuracy: 0.641400\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss:   0.002340 Validation Accuracy: 0.649000\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:   0.016902 Validation Accuracy: 0.656800\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss:   0.002975 Validation Accuracy: 0.641800\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss:   0.009990 Validation Accuracy: 0.643200\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss:   0.003763 Validation Accuracy: 0.633400\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss:   0.002996 Validation Accuracy: 0.649600\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:   0.017324 Validation Accuracy: 0.648600\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss:   0.004222 Validation Accuracy: 0.653000\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss:   0.001955 Validation Accuracy: 0.647000\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss:   0.004324 Validation Accuracy: 0.623000\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss:   0.003205 Validation Accuracy: 0.647200\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:   0.008970 Validation Accuracy: 0.647000\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss:   0.003056 Validation Accuracy: 0.644800\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss:   0.005847 Validation Accuracy: 0.643400\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss:   0.000602 Validation Accuracy: 0.635800\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss:   0.006717 Validation Accuracy: 0.643000\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:   0.016137 Validation Accuracy: 0.649200\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss:   0.003069 Validation Accuracy: 0.649600\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss:   0.000871 Validation Accuracy: 0.651800\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss:   0.002062 Validation Accuracy: 0.633000\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss:   0.010803 Validation Accuracy: 0.642800\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:   0.014367 Validation Accuracy: 0.650200\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss:   0.002926 Validation Accuracy: 0.650200\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss:   0.000711 Validation Accuracy: 0.653400\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss:   0.010017 Validation Accuracy: 0.634800\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss:   0.013768 Validation Accuracy: 0.648600\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:   0.012882 Validation Accuracy: 0.645800\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss:   0.007001 Validation Accuracy: 0.643400\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss:   0.001344 Validation Accuracy: 0.644200\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss:   0.004428 Validation Accuracy: 0.633800\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss:   0.007557 Validation Accuracy: 0.643200\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:   0.012228 Validation Accuracy: 0.651600\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss:   0.003082 Validation Accuracy: 0.640800\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss:   0.001284 Validation Accuracy: 0.647600\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss:   0.002457 Validation Accuracy: 0.635200\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss:   0.006922 Validation Accuracy: 0.649000\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:   0.013799 Validation Accuracy: 0.653000\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss:   0.005098 Validation Accuracy: 0.642800\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss:   0.001215 Validation Accuracy: 0.643200\n",
      "Epoch 472, CIFAR-10 Batch 4:  Loss:   0.002771 Validation Accuracy: 0.635800\n",
      "Epoch 472, CIFAR-10 Batch 5:  Loss:   0.004492 Validation Accuracy: 0.645600\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:   0.013270 Validation Accuracy: 0.653600\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss:   0.003229 Validation Accuracy: 0.641600\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss:   0.006193 Validation Accuracy: 0.648200\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss:   0.002088 Validation Accuracy: 0.635000\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss:   0.003794 Validation Accuracy: 0.646800\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:   0.020625 Validation Accuracy: 0.651400\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss:   0.003072 Validation Accuracy: 0.644400\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss:   0.006541 Validation Accuracy: 0.646000\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss:   0.002448 Validation Accuracy: 0.632000\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss:   0.005764 Validation Accuracy: 0.641600\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:   0.012053 Validation Accuracy: 0.644800\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss:   0.001452 Validation Accuracy: 0.646200\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss:   0.001618 Validation Accuracy: 0.650000\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss:   0.003600 Validation Accuracy: 0.635200\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss:   0.002710 Validation Accuracy: 0.648600\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:   0.024277 Validation Accuracy: 0.653800\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss:   0.002903 Validation Accuracy: 0.644600\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss:   0.001790 Validation Accuracy: 0.646800\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss:   0.003295 Validation Accuracy: 0.627800\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss:   0.002785 Validation Accuracy: 0.647000\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:   0.010370 Validation Accuracy: 0.649400\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss:   0.001987 Validation Accuracy: 0.646600\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss:   0.000892 Validation Accuracy: 0.648400\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss:   0.002395 Validation Accuracy: 0.627600\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss:   0.004333 Validation Accuracy: 0.644400\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:   0.015716 Validation Accuracy: 0.645600\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss:   0.010150 Validation Accuracy: 0.639800\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss:   0.002875 Validation Accuracy: 0.649600\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss:   0.004760 Validation Accuracy: 0.631200\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss:   0.008047 Validation Accuracy: 0.648200\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:   0.014258 Validation Accuracy: 0.642600\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss:   0.008050 Validation Accuracy: 0.647000\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss:   0.000621 Validation Accuracy: 0.647200\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss:   0.003791 Validation Accuracy: 0.620000\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss:   0.008945 Validation Accuracy: 0.642600\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:   0.017909 Validation Accuracy: 0.643200\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss:   0.006915 Validation Accuracy: 0.645600\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss:   0.000934 Validation Accuracy: 0.646800\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss:   0.003820 Validation Accuracy: 0.636200\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss:   0.003532 Validation Accuracy: 0.645200\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:   0.011714 Validation Accuracy: 0.648800\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss:   0.003634 Validation Accuracy: 0.646800\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss:   0.001091 Validation Accuracy: 0.647200\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss:   0.001407 Validation Accuracy: 0.634000\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss:   0.009386 Validation Accuracy: 0.649400\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:   0.011839 Validation Accuracy: 0.646000\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss:   0.005134 Validation Accuracy: 0.654000\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss:   0.002824 Validation Accuracy: 0.646400\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss:   0.003743 Validation Accuracy: 0.632600\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss:   0.006730 Validation Accuracy: 0.645400\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:   0.012370 Validation Accuracy: 0.648400\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss:   0.004005 Validation Accuracy: 0.645400\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss:   0.002020 Validation Accuracy: 0.646200\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss:   0.000980 Validation Accuracy: 0.634800\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss:   0.003308 Validation Accuracy: 0.641000\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:   0.008844 Validation Accuracy: 0.646400\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss:   0.005313 Validation Accuracy: 0.645600\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss:   0.002345 Validation Accuracy: 0.649800\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss:   0.002394 Validation Accuracy: 0.639200\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss:   0.009097 Validation Accuracy: 0.644200\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:   0.016213 Validation Accuracy: 0.648200\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss:   0.005749 Validation Accuracy: 0.645200\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss:   0.002712 Validation Accuracy: 0.645600\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss:   0.001905 Validation Accuracy: 0.634200\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss:   0.004584 Validation Accuracy: 0.642200\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:   0.014687 Validation Accuracy: 0.646200\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss:   0.009503 Validation Accuracy: 0.638200\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss:   0.001426 Validation Accuracy: 0.645600\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss:   0.003181 Validation Accuracy: 0.626600\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss:   0.001765 Validation Accuracy: 0.643200\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:   0.010907 Validation Accuracy: 0.645800\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss:   0.003600 Validation Accuracy: 0.640600\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss:   0.001168 Validation Accuracy: 0.646400\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss:   0.010173 Validation Accuracy: 0.635800\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss:   0.004854 Validation Accuracy: 0.639000\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:   0.013896 Validation Accuracy: 0.646400\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss:   0.006865 Validation Accuracy: 0.642800\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss:   0.001219 Validation Accuracy: 0.650400\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss:   0.009116 Validation Accuracy: 0.628800\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss:   0.004611 Validation Accuracy: 0.645800\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:   0.012946 Validation Accuracy: 0.646600\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss:   0.008534 Validation Accuracy: 0.638400\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss:   0.001232 Validation Accuracy: 0.649000\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss:   0.005468 Validation Accuracy: 0.639400\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss:   0.002832 Validation Accuracy: 0.644800\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:   0.014990 Validation Accuracy: 0.645800\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss:   0.005113 Validation Accuracy: 0.640800\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss:   0.002063 Validation Accuracy: 0.645600\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss:   0.005287 Validation Accuracy: 0.640200\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss:   0.007957 Validation Accuracy: 0.646600\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:   0.010772 Validation Accuracy: 0.650600\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss:   0.008232 Validation Accuracy: 0.644600\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss:   0.001735 Validation Accuracy: 0.650600\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss:   0.001897 Validation Accuracy: 0.635000\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss:   0.007656 Validation Accuracy: 0.645800\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:   0.012005 Validation Accuracy: 0.646200\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss:   0.004815 Validation Accuracy: 0.644800\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss:   0.001915 Validation Accuracy: 0.651400\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss:   0.001652 Validation Accuracy: 0.641600\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss:   0.003614 Validation Accuracy: 0.640200\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:   0.010786 Validation Accuracy: 0.650400\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss:   0.003857 Validation Accuracy: 0.645200\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss:   0.001522 Validation Accuracy: 0.649600\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss:   0.001525 Validation Accuracy: 0.644200\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss:   0.009874 Validation Accuracy: 0.643000\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:   0.014500 Validation Accuracy: 0.650000\n",
      "Epoch 494, CIFAR-10 Batch 2:  Loss:   0.005333 Validation Accuracy: 0.649800\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss:   0.001726 Validation Accuracy: 0.648000\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss:   0.001713 Validation Accuracy: 0.637200\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss:   0.007857 Validation Accuracy: 0.643000\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:   0.016168 Validation Accuracy: 0.647400\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss:   0.006467 Validation Accuracy: 0.648000\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss:   0.002633 Validation Accuracy: 0.647000\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss:   0.001751 Validation Accuracy: 0.639400\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss:   0.004190 Validation Accuracy: 0.644800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:   0.013629 Validation Accuracy: 0.645800\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss:   0.002438 Validation Accuracy: 0.641600\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss:   0.002763 Validation Accuracy: 0.652000\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss:   0.001556 Validation Accuracy: 0.633600\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss:   0.002656 Validation Accuracy: 0.649800\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:   0.012927 Validation Accuracy: 0.646800\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss:   0.003820 Validation Accuracy: 0.643600\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss:   0.000433 Validation Accuracy: 0.646600\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss:   0.002101 Validation Accuracy: 0.642600\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss:   0.005262 Validation Accuracy: 0.644400\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:   0.020238 Validation Accuracy: 0.646600\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss:   0.004121 Validation Accuracy: 0.640800\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss:   0.000711 Validation Accuracy: 0.645600\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss:   0.002377 Validation Accuracy: 0.636000\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss:   0.001725 Validation Accuracy: 0.635200\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:   0.016957 Validation Accuracy: 0.641200\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss:   0.003597 Validation Accuracy: 0.644400\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss:   0.000749 Validation Accuracy: 0.644800\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss:   0.001186 Validation Accuracy: 0.631800\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss:   0.005098 Validation Accuracy: 0.644600\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:   0.012495 Validation Accuracy: 0.643200\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss:   0.014489 Validation Accuracy: 0.641600\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss:   0.000684 Validation Accuracy: 0.646400\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss:   0.001726 Validation Accuracy: 0.644800\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss:   0.004150 Validation Accuracy: 0.639600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.64873046875\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIpMmxiIiIiEikybGIiIiISPT/AZ2B7lAu3TaiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06de46dbe0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
